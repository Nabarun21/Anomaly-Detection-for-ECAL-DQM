Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
Using TensorFlow backend.
2017-11-22 09:52:14.261839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:02:00.0
Total memory: 10.91GiB
Free memory: 239.38MiB
2017-11-22 09:52:14.538687: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5159c50 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-22 09:52:14.539614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:03:00.0
Total memory: 10.91GiB
Free memory: 400.38MiB
2017-11-22 09:52:14.836676: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5153ad0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-22 09:52:14.837410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:82:00.0
Total memory: 10.91GiB
Free memory: 400.38MiB
2017-11-22 09:52:15.119387: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5334830 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-22 09:52:15.120082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:83:00.0
Total memory: 10.91GiB
Free memory: 400.38MiB
2017-11-22 09:52:15.120453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-11-22 09:52:15.120490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-11-22 09:52:15.120516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-11-22 09:52:15.120530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-11-22 09:52:15.120543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-11-22 09:52:15.120556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-11-22 09:52:15.120630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-11-22 09:52:15.120647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-11-22 09:52:15.120709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-11-22 09:52:15.120720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y N N 
2017-11-22 09:52:15.120728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y N N 
2017-11-22 09:52:15.120735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y Y 
2017-11-22 09:52:15.120742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N Y Y 
2017-11-22 09:52:15.120758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0)
2017-11-22 09:52:15.120767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0)
2017-11-22 09:52:15.120775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0)
2017-11-22 09:52:15.120783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0)
2017-11-22 09:52:26.036721: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB.  Current allocation summary follows.
2017-11-22 09:52:26.036818: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.036857: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.036895: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.036921: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.036940: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.036958: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.036977: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037024: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037044: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037063: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037081: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037098: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037116: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037134: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037152: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037170: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037189: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037206: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037224: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037242: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037260: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.037279: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 2.2KiB was 2.0KiB, Chunk State: 
2017-11-22 09:52:26.037298: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:26.037313: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:26.037328: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:26.037343: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:26.037358: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:26.037386: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:26.037402: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:26.037417: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:26.037433: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:26.037448: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:26.037463: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:26.037477: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:26.037492: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:26.037506: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:26.037521: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:26.037535: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:26.037549: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:26.037564: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:26.037578: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:26.037592: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:26.037607: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:26.037621: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:26.037635: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:26.037650: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:26.037664: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:26.037678: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:52:26.037693: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:26.037707: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:26.037721: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:26.037735: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:26.037750: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:26.037764: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:26.037778: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:26.037792: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:26.037806: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:26.037820: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:26.037835: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:26.037849: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:26.037863: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:26.037903: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:26.037920: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:26.037935: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:26.037949: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:26.037965: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:26.037980: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:26.037994: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:26.038008: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:26.038023: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:26.038037: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:26.038052: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:26.038066: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:26.038080: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:26.038094: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:26.038109: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:26.038123: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:26.038138: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:26.038152: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:26.038166: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:26.038181: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:26.038197: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:26.038212: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:26.038233: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:52:26.038250: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:26.038267: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:26.038285: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:26.038301: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:26.038317: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:26.038333: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:26.038350: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:52:26.038371: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      65
MaxAllocSize:              7690240

2017-11-22 09:52:26.038397: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:26.038428: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,8]
2017-11-22 09:52:26.038460: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 120B.  Current allocation summary follows.
2017-11-22 09:52:26.038519: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038543: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038563: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038582: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038600: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038621: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038641: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038661: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038680: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038700: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038720: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038739: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038759: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038778: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038798: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038817: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038858: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038894: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038922: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038941: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038959: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.038976: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:52:26.038994: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:26.039011: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:26.039026: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:26.039041: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:26.039056: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:26.039071: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:26.039086: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:26.039111: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:26.039126: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:26.039141: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:26.039155: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:26.039169: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:26.039183: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:26.039197: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:26.039211: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:26.039225: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:26.039238: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:26.039252: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:26.039266: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:26.039285: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:26.039299: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:26.039313: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:26.039327: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:26.039362: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:26.039378: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:26.039392: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:52:26.039406: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:26.039420: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:26.039434: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:26.039448: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:26.039462: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:26.039476: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:26.039490: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:26.039504: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:26.039518: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:26.039532: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:26.039548: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:26.039562: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:26.039577: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:26.039591: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:26.039605: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:26.039618: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:26.039632: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:26.039646: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:26.039660: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:26.039674: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:26.039687: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:26.039701: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:26.039715: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:26.039729: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:26.039744: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:26.039757: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:26.039771: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:26.039785: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:26.039799: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:26.039812: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:26.039826: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:26.039840: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:26.039866: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:26.039887: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:26.039906: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:26.039925: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:52:26.039942: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:26.039957: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:26.039974: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:26.039990: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:26.040006: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:26.040021: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:26.040037: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:52:26.040056: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      65
MaxAllocSize:              7690240

2017-11-22 09:52:26.040079: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:26.040106: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[30]
2017-11-22 09:52:26.040165: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 56.03MiB.  Current allocation summary follows.
2017-11-22 09:52:26.040224: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 1, Chunks in use: 0 256B allocated for chunks. 30B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040247: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040265: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040283: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040301: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040319: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040337: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040355: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040393: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040413: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040431: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040449: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040467: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040484: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040502: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040520: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040537: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040556: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040575: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040593: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040611: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.040631: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 56.03MiB was 32.00MiB, Chunk State: 
2017-11-22 09:52:26.040649: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:26.040664: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:26.040679: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:26.040693: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:26.040707: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:26.040722: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:26.040736: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:26.040763: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:26.040779: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:26.040794: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:26.040809: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:26.040824: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:26.040838: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:26.040852: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:26.040867: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:26.040896: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:26.040918: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:26.040934: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:26.040948: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:26.040962: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:26.040977: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:26.040991: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:26.041005: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:26.041019: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:26.041034: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:26.041048: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:26.041063: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:26.041077: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:26.041091: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:26.041106: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:26.041120: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:26.041134: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:26.041149: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:26.041163: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:26.041177: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:26.041191: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:26.041206: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:26.041220: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:26.041234: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:26.041249: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:26.041263: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:26.041278: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:26.041304: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:26.041319: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:26.041334: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:26.041349: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:26.041363: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:26.041377: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:26.041392: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:26.041406: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:26.041420: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:26.041435: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:26.041450: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:26.041464: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:26.041478: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:26.041492: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:26.041507: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:26.041522: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:26.041538: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:26.041553: I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x10835803a00 of size 256
2017-11-22 09:52:26.041568: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:26.041586: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 38 Chunks of size 256 totalling 9.5KiB
2017-11-22 09:52:26.041604: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:26.041620: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:26.041637: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:26.041653: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:26.041669: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:26.041685: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:26.041702: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.37MiB
2017-11-22 09:52:26.041722: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073024
MaxInUse:                 15073280
NumAllocs:                      65
MaxAllocSize:              7690240

2017-11-22 09:52:26.041748: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:26.041778: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[30,170,360,8]
2017-11-22 09:52:26.041859: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.
2017-11-22 09:52:26.041957: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.041983: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042001: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042019: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042037: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042055: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042073: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042091: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042109: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042128: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042146: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042164: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042182: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042200: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042218: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042236: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042254: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042285: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042304: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042323: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042341: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:26.042357: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:52:26.042375: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:26.042390: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:26.042406: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:26.042421: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:26.042435: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:26.042450: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:26.042464: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:26.042479: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:26.042494: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:26.042509: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:26.042524: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:26.042539: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:26.042553: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:26.042568: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:26.042583: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:26.042598: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:26.042612: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:26.042627: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:26.042641: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:26.042656: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:26.042670: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:26.042685: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:26.042699: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:26.042713: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:26.042728: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:26.042742: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:52:26.042772: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:26.042788: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:26.042802: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:26.042817: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:26.042831: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:26.042846: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:26.042860: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:26.042875: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:26.042901: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:26.042916: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:26.042931: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:26.042945: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:26.042960: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:26.042974: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:26.042989: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:26.043004: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:26.043018: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:26.043033: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:26.043047: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:26.043062: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:26.043076: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:26.043091: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:26.043105: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:26.043120: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:26.043134: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:26.043149: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:26.043163: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:26.043178: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:26.043192: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:26.043207: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:26.043221: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:26.043236: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:26.043251: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:26.043266: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:26.043295: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:26.043316: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:52:26.043334: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:26.043350: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:26.043368: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:26.043385: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:26.043401: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:26.043417: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:26.043435: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:52:26.043454: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:52:26.043479: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:26.043507: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]
2017-11-22 09:52:36.043635: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB.  Current allocation summary follows.
2017-11-22 09:52:36.043745: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043769: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043788: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043806: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043824: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043845: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043863: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043897: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043932: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043950: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.043991: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044013: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044040: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044058: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044075: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044094: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044112: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044129: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044148: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044166: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044183: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:36.044202: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 2.2KiB was 2.0KiB, Chunk State: 
2017-11-22 09:52:36.044220: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:36.044236: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:36.044251: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:36.044265: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:36.044280: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:36.044294: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:36.044308: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:36.044322: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:36.044337: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:36.044351: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:36.044384: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:36.044400: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:36.044414: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:36.044429: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:36.044449: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:36.044467: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:36.044481: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:36.044496: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:36.044511: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:36.044525: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:36.044540: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:36.044554: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:36.044568: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:36.044582: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:36.044597: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:36.044611: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:52:36.044625: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:36.044640: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:36.044654: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:36.044668: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:36.044682: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:36.044697: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:36.044711: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:36.044725: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:36.044739: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:36.044762: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:36.044780: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:36.044800: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:36.044814: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:36.044828: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:36.044842: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:36.044856: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:36.044871: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:36.044896: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:36.044929: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:36.044944: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:36.044959: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:36.044973: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:36.044987: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:36.045002: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:36.045017: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:36.045031: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:36.045046: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:36.045060: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:36.045074: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:36.045088: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:36.045106: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:36.045121: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:36.045142: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:36.045166: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:36.045181: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:36.045200: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:52:36.045217: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:36.045233: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:36.045251: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:36.045267: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:36.045283: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:36.045299: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:36.045316: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:52:36.045337: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:52:36.045362: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:36.045390: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,8]
2017-11-22 09:52:46.045559: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:52:46.045642: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045663: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045699: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045716: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045730: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045745: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045759: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045774: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045788: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045802: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045816: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045830: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045845: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045859: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045873: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045904: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045920: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045934: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045949: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045974: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.045990: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:46.046003: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:52:46.046018: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:46.046030: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:46.046043: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:46.046055: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:46.046066: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:46.046078: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:46.046090: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:46.046102: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:46.046114: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:46.046126: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:46.046138: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:46.046150: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:46.046161: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:46.046173: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:46.046185: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:46.046196: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:46.046208: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:46.046220: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:46.046232: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:46.046243: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:46.046255: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:46.046266: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:46.046278: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:46.046289: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:46.046301: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:46.046312: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:52:46.046324: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:46.046335: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:46.046357: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:46.046370: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:46.046382: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:46.046394: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:46.046405: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:46.046417: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:46.046428: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:46.046440: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:46.046451: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:46.046463: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:46.046476: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:46.046488: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:46.046499: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:46.046511: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:46.046522: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:46.046535: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:46.046547: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:46.046558: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:46.046570: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:46.046582: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:46.046593: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:46.046605: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:46.046616: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:46.046628: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:46.046640: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:46.046651: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:46.046663: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:46.046674: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:46.046686: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:46.046698: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:46.046710: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:46.046722: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:46.046734: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:46.046756: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:52:46.046770: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:46.046794: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:46.046810: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:46.046823: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:46.046837: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:46.046850: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:46.046863: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:52:46.046887: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:52:46.046911: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:46.046935: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:52:56.047129: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB.  Current allocation summary follows.
2017-11-22 09:52:56.047248: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047267: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047280: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047293: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047313: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047326: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047338: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047359: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047372: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047395: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047408: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047442: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047456: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047469: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047483: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047495: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047511: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047524: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047537: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047550: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047562: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:52:56.047576: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 2.2KiB was 2.0KiB, Chunk State: 
2017-11-22 09:52:56.047590: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:52:56.047601: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:52:56.047618: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:52:56.047629: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:52:56.047639: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:52:56.047649: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:52:56.047660: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:52:56.047681: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:52:56.047702: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:52:56.047712: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:52:56.047722: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:52:56.047733: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:52:56.047753: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:52:56.047766: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:52:56.047776: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:52:56.047787: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:52:56.047797: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:52:56.047811: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:52:56.047822: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:52:56.047832: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:52:56.047843: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:52:56.047853: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:52:56.047863: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:52:56.047873: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:52:56.047900: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:52:56.047911: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:52:56.047922: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:52:56.047940: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:52:56.047950: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:52:56.047960: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:52:56.047970: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:52:56.047980: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:52:56.047990: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:52:56.048001: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:52:56.048011: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:52:56.048021: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:52:56.048031: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:52:56.048041: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:52:56.048052: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:52:56.048062: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:52:56.048073: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:52:56.048082: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:52:56.048093: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:52:56.048103: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:52:56.048122: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:52:56.048132: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:52:56.048150: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:52:56.048174: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:52:56.048186: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:52:56.048197: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:52:56.048208: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:52:56.048218: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:52:56.048229: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:52:56.048249: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:52:56.048259: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:52:56.048272: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:52:56.048293: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:52:56.048304: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:52:56.048315: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:52:56.048325: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:52:56.048338: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:52:56.048352: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:52:56.048365: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:52:56.048377: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:52:56.048399: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:52:56.048410: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:52:56.048422: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:52:56.048433: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:52:56.048446: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:52:56.048480: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:52:56.048499: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:52:56.048524: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,8]
2017-11-22 09:53:06.048698: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:53:06.048789: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048813: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048830: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048867: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048906: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048926: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048942: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048959: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048975: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.048991: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049008: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049024: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049040: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049057: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049073: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049090: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049106: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049122: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049139: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049155: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049184: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:06.049201: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:53:06.049218: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:53:06.049233: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:53:06.049247: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:53:06.049260: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:53:06.049274: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:53:06.049288: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:53:06.049302: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:53:06.049317: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:53:06.049331: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:53:06.049345: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:53:06.049358: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:53:06.049372: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:53:06.049386: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:53:06.049399: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:53:06.049412: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:53:06.049426: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:53:06.049440: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:53:06.049453: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:53:06.049466: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:53:06.049480: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:53:06.049493: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:53:06.049506: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:53:06.049520: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:53:06.049533: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:53:06.049546: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:53:06.049560: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:53:06.049573: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:53:06.049586: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:53:06.049600: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:53:06.049613: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:53:06.049626: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:53:06.049650: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:53:06.049664: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:53:06.049678: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:53:06.049692: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:53:06.049705: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:53:06.049718: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:53:06.049732: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:53:06.049746: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:53:06.049759: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:53:06.049773: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:53:06.049786: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:53:06.049800: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:53:06.049814: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:53:06.049828: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:53:06.049841: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:53:06.049854: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:53:06.049868: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:53:06.049888: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:53:06.049905: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:53:06.049919: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:53:06.049932: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:53:06.049946: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:53:06.049959: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:53:06.049973: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:53:06.049986: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:53:06.050000: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:53:06.050013: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:53:06.050026: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:53:06.050040: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:53:06.050055: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:53:06.050077: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:53:06.050094: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:53:06.050109: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:53:06.050126: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:53:06.050152: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:53:06.050168: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:53:06.050183: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:53:06.050199: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:53:06.050219: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:53:06.050242: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:53:06.050270: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:53:16.050442: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 288B.  Current allocation summary follows.
2017-11-22 09:53:16.050545: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050566: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050581: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050595: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050610: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050625: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050639: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050654: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050668: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050682: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050697: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050711: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050758: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050775: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050789: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050803: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050818: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050832: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050847: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050862: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050876: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:16.050913: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 512B was 512B, Chunk State: 
2017-11-22 09:53:16.050930: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:53:16.050943: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:53:16.050954: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:53:16.050966: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:53:16.050978: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:53:16.050989: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:53:16.051001: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:53:16.051012: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:53:16.051025: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:53:16.051036: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:53:16.051050: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:53:16.051062: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:53:16.051074: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:53:16.051085: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:53:16.051098: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:53:16.051126: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:53:16.051139: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:53:16.051151: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:53:16.051177: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:53:16.051192: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:53:16.051206: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:53:16.051221: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:53:16.051236: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:53:16.051250: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:53:16.051264: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:53:16.051279: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:53:16.051293: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:53:16.051308: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:53:16.051322: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:53:16.051336: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:53:16.051351: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:53:16.051365: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:53:16.051379: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:53:16.051394: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:53:16.051408: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:53:16.051422: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:53:16.051437: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:53:16.051451: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:53:16.051465: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:53:16.051480: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:53:16.051494: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:53:16.051508: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:53:16.051523: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:53:16.051537: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:53:16.051552: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:53:16.051566: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:53:16.051580: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:53:16.051595: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:53:16.051609: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:53:16.051624: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:53:16.051655: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:53:16.051671: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:53:16.051686: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:53:16.051701: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:53:16.051716: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:53:16.051730: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:53:16.051745: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:53:16.051760: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:53:16.051775: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:53:16.051790: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:53:16.051806: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:53:16.051829: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:53:16.051847: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:53:16.051865: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:53:16.051902: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:53:16.051923: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:53:16.051939: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:53:16.051956: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:53:16.051973: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:53:16.051994: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:53:16.052019: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:53:16.052047: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,1]
2017-11-22 09:53:26.052211: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.
2017-11-22 09:53:26.052299: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052323: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052340: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052357: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052395: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052414: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052431: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052447: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052463: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052479: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052496: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052512: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052528: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052545: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052562: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052578: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052594: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052611: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052628: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052644: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052661: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:26.052689: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:53:26.052707: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:53:26.052721: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:53:26.052735: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:53:26.052748: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:53:26.052762: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:53:26.052775: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:53:26.052789: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:53:26.052802: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:53:26.052816: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:53:26.053969: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:53:26.053992: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:53:26.054007: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:53:26.054022: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:53:26.054036: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:53:26.054051: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:53:26.054065: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:53:26.054080: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:53:26.054094: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:53:26.054109: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:53:26.054123: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:53:26.054137: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:53:26.054152: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:53:26.054166: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:53:26.054180: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:53:26.054195: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:53:26.054209: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:53:26.054224: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:53:26.054238: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:53:26.054252: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:53:26.054267: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:53:26.054281: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:53:26.054295: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:53:26.054310: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:53:26.054324: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:53:26.054353: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:53:26.054369: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:53:26.054383: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:53:26.054398: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:53:26.054413: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:53:26.054428: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:53:26.054443: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:53:26.054457: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:53:26.054472: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:53:26.054487: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:53:26.054501: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:53:26.054516: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:53:26.054530: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:53:26.054545: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:53:26.054560: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:53:26.054574: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:53:26.054588: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:53:26.054603: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:53:26.054617: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:53:26.054632: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:53:26.054646: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:53:26.054661: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:53:26.054675: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:53:26.054689: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:53:26.054704: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:53:26.054720: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:53:26.054735: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:53:26.054760: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:53:26.054778: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:53:26.054794: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:53:26.054812: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:53:26.054828: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:53:26.054845: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:53:26.054861: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:53:26.054905: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:53:26.054932: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:53:26.054959: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:53:26.054986: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1]
2017-11-22 09:53:36.055207: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.
2017-11-22 09:53:36.055310: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055339: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055358: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055377: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055395: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055413: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055431: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055449: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055472: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055501: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055518: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055535: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055553: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055591: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055609: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055626: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055643: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055659: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055677: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055693: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055710: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:36.055726: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:53:36.055747: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:53:36.055762: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:53:36.055776: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:53:36.055789: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:53:36.055803: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:53:36.055816: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:53:36.055829: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:53:36.055842: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:53:36.055869: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:53:36.055914: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:53:36.055931: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:53:36.055944: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:53:36.055958: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:53:36.055971: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:53:36.055986: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:53:36.056012: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:53:36.056026: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:53:36.056041: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:53:36.056078: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:53:36.056095: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:53:36.056110: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:53:36.056125: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:53:36.056140: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:53:36.056155: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:53:36.056170: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:53:36.056185: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:53:36.056200: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:53:36.056217: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:53:36.056232: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:53:36.056247: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:53:36.056262: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:53:36.056278: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:53:36.056293: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:53:36.056308: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:53:36.056323: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:53:36.056338: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:53:36.056352: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:53:36.056367: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:53:36.056381: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:53:36.056396: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:53:36.056410: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:53:36.056425: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:53:36.056439: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:53:36.056454: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:53:36.056468: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:53:36.056483: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:53:36.056497: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:53:36.056512: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:53:36.056526: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:53:36.056541: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:53:36.056556: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:53:36.056571: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:53:36.056597: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:53:36.056613: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:53:36.056628: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:53:36.056645: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:53:36.056659: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:53:36.056674: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:53:36.056689: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:53:36.056704: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:53:36.056720: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:53:36.056743: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:53:36.056761: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:53:36.056777: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:53:36.056796: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:53:36.056812: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:53:36.056828: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:53:36.056844: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:53:36.056862: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:53:36.056890: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:53:36.056920: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:53:36.056947: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]
2017-11-22 09:53:46.057192: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 288B.  Current allocation summary follows.
2017-11-22 09:53:46.057316: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057344: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057364: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057382: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057400: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057418: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057457: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057478: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057496: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057514: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057532: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057550: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057568: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057586: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057604: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057622: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057640: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057658: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057676: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057694: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057712: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:46.057729: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 512B was 512B, Chunk State: 
2017-11-22 09:53:46.057751: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:53:46.057769: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:53:46.057796: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:53:46.057812: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:53:46.057827: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:53:46.057842: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:53:46.057857: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:53:46.057872: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:53:46.057914: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:53:46.057931: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:53:46.057946: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:53:46.057961: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:53:46.057975: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:53:46.057990: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:53:46.058005: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:53:46.058019: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:53:46.058034: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:53:46.058048: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:53:46.058063: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:53:46.058077: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:53:46.058091: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:53:46.058106: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:53:46.058120: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:53:46.058134: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:53:46.058149: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:53:46.058163: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:53:46.058178: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:53:46.058192: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:53:46.058206: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:53:46.058221: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:53:46.058235: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:53:46.058250: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:53:46.058264: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:53:46.058278: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:53:46.058293: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:53:46.058307: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:53:46.058333: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:53:46.058350: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:53:46.058364: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:53:46.058390: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:53:46.058415: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:53:46.058429: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:53:46.058442: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:53:46.058456: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:53:46.058470: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:53:46.058483: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:53:46.058497: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:53:46.058510: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:53:46.058523: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:53:46.058537: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:53:46.058550: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:53:46.058564: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:53:46.058577: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:53:46.058590: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:53:46.058604: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:53:46.058617: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:53:46.058630: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:53:46.058644: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:53:46.058657: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:53:46.058671: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:53:46.058685: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:53:46.058708: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:53:46.058725: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:53:46.058740: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:53:46.058757: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:53:46.058772: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:53:46.058787: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:53:46.058802: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:53:46.058818: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:53:46.058837: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:53:46.058870: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:53:46.058908: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,1,8]
2017-11-22 09:53:56.059118: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:53:56.059220: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059244: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059263: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059280: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059298: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059316: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059334: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059352: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059370: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059387: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059405: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059423: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059441: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059469: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059485: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059521: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059539: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059555: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059571: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059587: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059602: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:53:56.059617: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:53:56.059633: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:53:56.059646: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:53:56.059659: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:53:56.059671: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:53:56.059684: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:53:56.059697: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:53:56.059709: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:53:56.059722: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:53:56.059735: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:53:56.059747: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:53:56.059760: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:53:56.059772: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:53:56.059785: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:53:56.059798: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:53:56.059811: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:53:56.059824: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:53:56.059837: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:53:56.059849: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:53:56.059861: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:53:56.059874: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:53:56.059925: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:53:56.059940: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:53:56.059953: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:53:56.059965: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:53:56.059978: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:53:56.059991: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:53:56.060003: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:53:56.060016: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:53:56.060028: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:53:56.060040: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:53:56.060064: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:53:56.060078: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:53:56.060093: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:53:56.060108: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:53:56.060122: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:53:56.060136: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:53:56.060151: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:53:56.060166: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:53:56.060180: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:53:56.060195: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:53:56.060209: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:53:56.060224: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:53:56.060238: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:53:56.060253: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:53:56.060267: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:53:56.060282: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:53:56.060296: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:53:56.060310: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:53:56.060325: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:53:56.060339: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:53:56.060354: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:53:56.060369: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:53:56.060384: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:53:56.060398: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:53:56.060412: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:53:56.060438: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:53:56.060454: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:53:56.060468: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:53:56.060483: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:53:56.060498: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:53:56.060513: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:53:56.060537: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:53:56.060554: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:53:56.060571: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:53:56.060589: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:53:56.060605: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:53:56.060621: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:53:56.060637: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:53:56.060655: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:53:56.060675: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:53:56.060700: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:53:56.060727: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:54:06.061004: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB.  Current allocation summary follows.
2017-11-22 09:54:06.061128: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061155: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061174: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061193: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061211: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061229: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061247: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061286: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061309: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061317: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061325: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061333: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061341: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061348: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061356: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061364: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061372: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061379: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061387: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061395: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061403: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:06.061411: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 2.2KiB was 2.0KiB, Chunk State: 
2017-11-22 09:54:06.061422: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:54:06.061429: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:54:06.061451: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:54:06.061458: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:54:06.061472: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:54:06.061480: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:54:06.061488: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:54:06.061495: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:54:06.061502: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:54:06.061509: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:54:06.061516: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:54:06.061523: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:54:06.061530: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:54:06.061537: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:54:06.061544: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:54:06.061551: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:54:06.061572: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:54:06.061578: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:54:06.061585: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:54:06.061591: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:54:06.061597: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:54:06.061604: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:54:06.061610: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:54:06.061617: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:54:06.061623: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:54:06.061629: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:54:06.061636: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:54:06.061642: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:54:06.061649: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:54:06.061655: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:54:06.061661: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:54:06.061668: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:54:06.061674: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:54:06.061681: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:54:06.061687: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:54:06.061693: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:54:06.061700: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:54:06.061706: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:54:06.061713: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:54:06.061726: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:54:06.061733: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:54:06.061740: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:54:06.061746: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:54:06.061753: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:54:06.061760: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:54:06.061766: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:54:06.061773: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:54:06.061779: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:54:06.061785: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:54:06.061792: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:54:06.061798: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:54:06.061805: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:54:06.061811: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:54:06.061818: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:54:06.061824: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:54:06.061830: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:54:06.061837: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:54:06.061844: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:54:06.061850: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:54:06.061857: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:54:06.061864: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:54:06.061873: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:54:06.061911: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:54:06.061920: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:54:06.061929: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:54:06.061937: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:54:06.061944: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:54:06.061952: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:54:06.061960: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:54:06.061971: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:54:06.061983: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:54:06.062009: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,8]
2017-11-22 09:54:16.062193: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:54:16.062298: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062320: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062337: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062353: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062369: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062385: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062402: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062417: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062433: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062449: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062465: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062483: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062499: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062514: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062530: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062546: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062581: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062599: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062616: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062632: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062648: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:16.062662: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:54:16.062678: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:54:16.062692: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:54:16.062705: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:54:16.062718: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:54:16.062731: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:54:16.062744: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:54:16.062756: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:54:16.062769: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:54:16.062783: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:54:16.062795: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:54:16.062809: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:54:16.062821: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:54:16.062834: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:54:16.062847: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:54:16.062861: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:54:16.062874: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:54:16.062910: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:54:16.062924: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:54:16.062937: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:54:16.062950: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:54:16.062963: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:54:16.062976: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:54:16.062988: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:54:16.063013: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:54:16.063026: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:54:16.063039: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:54:16.063052: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:54:16.063065: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:54:16.063078: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:54:16.063090: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:54:16.063103: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:54:16.063116: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:54:16.063128: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:54:16.063141: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:54:16.063153: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:54:16.063166: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:54:16.063179: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:54:16.063191: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:54:16.063204: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:54:16.063216: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:54:16.063229: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:54:16.063241: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:54:16.063254: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:54:16.063266: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:54:16.063279: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:54:16.063291: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:54:16.063304: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:54:16.063316: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:54:16.063329: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:54:16.063341: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:54:16.063354: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:54:16.063367: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:54:16.063379: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:54:16.063403: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:54:16.063417: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:54:16.063432: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:54:16.063446: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:54:16.063472: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:54:16.063488: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:54:16.063503: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:54:16.063519: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:54:16.063542: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:54:16.063560: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:54:16.063577: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:54:16.063595: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:54:16.063611: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:54:16.063627: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:54:16.063643: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:54:16.063661: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:54:16.063681: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:54:16.063706: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:54:16.063734: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:54:26.063962: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB.  Current allocation summary follows.
2017-11-22 09:54:26.064071: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064099: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064118: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064136: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064154: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064172: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064190: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064208: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064247: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064267: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064286: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064304: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064321: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064339: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064357: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064374: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064392: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064410: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064428: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064446: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064464: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:26.064483: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 2.2KiB was 2.0KiB, Chunk State: 
2017-11-22 09:54:26.064506: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:54:26.064522: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:54:26.064537: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:54:26.064552: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:54:26.064566: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:54:26.064581: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:54:26.064596: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:54:26.064623: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:54:26.064640: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:54:26.064655: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:54:26.064670: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:54:26.064685: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:54:26.064699: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:54:26.064714: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:54:26.064728: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:54:26.064743: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:54:26.064758: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:54:26.064772: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:54:26.064786: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:54:26.064801: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:54:26.064815: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:54:26.064830: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:54:26.064844: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:54:26.064858: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:54:26.064873: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:54:26.064905: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:54:26.064921: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:54:26.064936: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:54:26.064950: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:54:26.064965: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:54:26.064979: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:54:26.064994: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:54:26.065008: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:54:26.065023: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:54:26.065037: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:54:26.065052: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:54:26.065066: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:54:26.065080: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:54:26.065095: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:54:26.065110: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:54:26.065125: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:54:26.065152: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:54:26.065168: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:54:26.065183: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:54:26.065198: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:54:26.065213: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:54:26.065227: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:54:26.065242: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:54:26.065256: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:54:26.065271: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:54:26.065285: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:54:26.065300: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:54:26.065314: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:54:26.065329: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:54:26.065343: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:54:26.065357: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:54:26.065372: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:54:26.065386: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:54:26.065401: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:54:26.065416: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:54:26.065431: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:54:26.065452: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:54:26.065469: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:54:26.065486: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:54:26.065504: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:54:26.065520: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:54:26.065536: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:54:26.065553: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:54:26.065570: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:54:26.065590: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:54:26.065615: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:54:26.065643: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,8]
2017-11-22 09:54:36.065868: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:54:36.066018: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066046: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066063: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066080: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066097: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066113: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066130: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066147: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066164: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066180: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066197: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066214: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066230: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066247: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066264: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066281: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066297: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066327: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066345: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066362: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066379: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:36.066395: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:54:36.066416: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:54:36.066431: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:54:36.066445: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:54:36.066459: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:54:36.066472: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:54:36.066486: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:54:36.066499: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:54:36.066512: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:54:36.066528: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:54:36.066542: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:54:36.066556: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:54:36.066570: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:54:36.066584: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:54:36.066598: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:54:36.066612: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:54:36.066626: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:54:36.066639: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:54:36.066653: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:54:36.066667: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:54:36.066681: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:54:36.066695: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:54:36.066708: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:54:36.066722: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:54:36.066736: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:54:36.066749: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:54:36.066773: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:54:36.066788: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:54:36.066801: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:54:36.066815: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:54:36.066828: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:54:36.066842: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:54:36.066855: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:54:36.066869: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:54:36.066894: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:54:36.066913: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:54:36.066927: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:54:36.066940: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:54:36.066954: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:54:36.066967: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:54:36.066980: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:54:36.066994: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:54:36.067007: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:54:36.067020: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:54:36.067034: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:54:36.067047: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:54:36.067060: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:54:36.067074: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:54:36.067087: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:54:36.067101: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:54:36.067114: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:54:36.067128: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:54:36.067141: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:54:36.067155: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:54:36.067168: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:54:36.067181: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:54:36.067194: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:54:36.067208: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:54:36.067221: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:54:36.067235: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:54:36.067249: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:54:36.067273: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:54:36.067297: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:54:36.067314: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:54:36.067329: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:54:36.067346: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:54:36.067361: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:54:36.067376: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:54:36.067391: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:54:36.067407: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:54:36.067427: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:54:36.067450: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:54:36.067480: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:54:46.067699: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.2KiB.  Current allocation summary follows.
2017-11-22 09:54:46.067788: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067811: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067827: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067841: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067856: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067871: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067904: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067920: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067935: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067968: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067984: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.067999: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068014: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068028: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068042: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068056: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068071: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068085: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068099: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068114: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068128: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:46.068144: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 2.2KiB was 2.0KiB, Chunk State: 
2017-11-22 09:54:46.068166: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:54:46.068180: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:54:46.068192: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:54:46.068204: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:54:46.068216: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:54:46.068235: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:54:46.068248: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:54:46.068260: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:54:46.068277: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:54:46.068317: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:54:46.068332: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:54:46.068344: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:54:46.068356: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:54:46.068368: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:54:46.068380: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:54:46.068393: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:54:46.068404: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:54:46.068416: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:54:46.068428: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:54:46.068440: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:54:46.068452: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:54:46.068463: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:54:46.068475: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:54:46.068487: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:54:46.068498: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:54:46.068510: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:54:46.068524: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:54:46.068537: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:54:46.068549: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:54:46.068561: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:54:46.068573: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:54:46.068590: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:54:46.068602: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:54:46.068614: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:54:46.068626: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:54:46.068638: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:54:46.068649: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:54:46.068661: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:54:46.068673: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:54:46.068685: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:54:46.068697: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:54:46.068709: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:54:46.068721: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:54:46.068732: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:54:46.068758: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:54:46.068771: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:54:46.068783: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:54:46.068795: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:54:46.068807: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:54:46.068820: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:54:46.068832: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:54:46.068845: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:54:46.068857: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:54:46.068869: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:54:46.068887: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:54:46.068903: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:54:46.068916: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:54:46.068929: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:54:46.068941: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:54:46.068954: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:54:46.068967: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:54:46.068984: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:54:46.068998: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:54:46.069012: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:54:46.069026: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:54:46.069040: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:54:46.069053: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:54:46.069066: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:54:46.069080: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:54:46.069097: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:54:46.069121: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:54:46.069147: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,8]
2017-11-22 09:54:56.069322: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:54:56.069400: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069415: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069443: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069456: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069467: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069478: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069489: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069507: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069518: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069529: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069540: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069551: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069562: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069573: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069585: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069596: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069607: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069619: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069630: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069649: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069661: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:54:56.069672: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:54:56.069684: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:54:56.069694: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:54:56.069703: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:54:56.069712: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:54:56.069721: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:54:56.069730: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:54:56.069739: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:54:56.069748: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:54:56.069758: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:54:56.069767: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:54:56.069776: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:54:56.069785: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:54:56.069795: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:54:56.069804: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:54:56.069814: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:54:56.069823: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:54:56.069832: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:54:56.069841: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:54:56.069851: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:54:56.069860: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:54:56.069869: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:54:56.069890: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:54:56.069903: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:54:56.069913: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:54:56.069922: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:54:56.069931: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:54:56.069940: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:54:56.069949: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:54:56.069967: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:54:56.069977: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:54:56.069986: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:54:56.069995: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:54:56.070004: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:54:56.070013: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:54:56.070022: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:54:56.070031: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:54:56.070057: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:54:56.070072: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:54:56.070087: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:54:56.070102: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:54:56.070116: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:54:56.070131: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:54:56.070146: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:54:56.070160: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:54:56.070175: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:54:56.070189: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:54:56.070204: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:54:56.070219: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:54:56.070233: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:54:56.070249: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:54:56.070263: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:54:56.070278: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:54:56.070293: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:54:56.070307: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:54:56.070322: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:54:56.070336: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:54:56.070351: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:54:56.070366: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:54:56.070381: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:54:56.070396: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:54:56.070412: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:54:56.070435: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:54:56.070452: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:54:56.070482: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:54:56.070501: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:54:56.070518: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:54:56.070534: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:54:56.070551: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:54:56.070568: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:54:56.070589: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:54:56.070619: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:54:56.070658: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:55:06.070899: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 288B.  Current allocation summary follows.
2017-11-22 09:55:06.070991: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071011: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071025: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071038: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071052: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071066: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071080: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071093: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071107: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071121: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071135: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071167: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071182: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071196: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071218: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071243: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071257: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071270: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071284: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071297: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071310: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:06.071323: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 512B was 512B, Chunk State: 
2017-11-22 09:55:06.071337: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:55:06.071349: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:55:06.071360: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:55:06.071371: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:55:06.071383: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:55:06.071395: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:55:06.071406: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:55:06.071418: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:55:06.071430: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:55:06.071441: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:55:06.071452: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:55:06.071463: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:55:06.071483: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:55:06.071495: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:55:06.071507: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:55:06.071518: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:55:06.071530: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:55:06.071540: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:55:06.071551: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:55:06.071562: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:55:06.071578: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:55:06.071589: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:55:06.071600: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:55:06.071611: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:55:06.071622: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:55:06.071633: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:55:06.071644: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:55:06.071655: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:55:06.071666: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:55:06.071677: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:55:06.071688: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:55:06.071699: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:55:06.071710: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:55:06.071721: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:55:06.071732: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:55:06.071742: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:55:06.071753: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:55:06.071764: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:55:06.071776: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:55:06.071787: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:55:06.071798: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:55:06.071809: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:55:06.071820: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:55:06.071831: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:55:06.071842: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:55:06.071853: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:55:06.071864: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:55:06.071921: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:55:06.071935: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:55:06.071946: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:55:06.071958: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:55:06.071969: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:55:06.071981: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:55:06.071992: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:55:06.072004: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:55:06.072015: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:55:06.072027: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:55:06.072038: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:55:06.072050: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:55:06.072062: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:55:06.072075: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:55:06.072095: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:55:06.072110: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:55:06.072123: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:55:06.072136: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:55:06.072149: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:55:06.072161: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:55:06.072174: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:55:06.072187: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:55:06.072203: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:55:06.072223: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:55:06.072246: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,8,1]
2017-11-22 09:55:16.072466: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.
2017-11-22 09:55:16.072576: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072602: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072619: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072657: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072676: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072693: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072709: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072726: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072744: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072760: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072777: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072793: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072820: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072836: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072855: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072871: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072911: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072930: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072946: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072963: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.072992: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:16.073009: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:55:16.073030: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:55:16.073046: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:55:16.073061: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:55:16.073075: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:55:16.073088: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:55:16.073101: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:55:16.073115: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:55:16.073128: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:55:16.073142: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:55:16.073156: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:55:16.073170: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:55:16.073183: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:55:16.073198: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:55:16.073211: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:55:16.073225: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:55:16.073239: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:55:16.073252: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:55:16.073278: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:55:16.073293: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:55:16.073308: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:55:16.073322: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:55:16.073337: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:55:16.073351: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:55:16.073366: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:55:16.073380: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:55:16.073395: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:55:16.073409: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:55:16.073424: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:55:16.073445: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:55:16.073459: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:55:16.073474: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:55:16.073499: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:55:16.073515: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:55:16.073532: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:55:16.073547: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:55:16.073561: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:55:16.073576: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:55:16.073590: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:55:16.073605: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:55:16.073619: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:55:16.073634: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:55:16.073649: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:55:16.073663: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:55:16.073678: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:55:16.073692: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:55:16.073707: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:55:16.073721: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:55:16.073736: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:55:16.073750: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:55:16.073766: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:55:16.073781: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:55:16.073795: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:55:16.073810: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:55:16.073824: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:55:16.073842: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:55:16.073856: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:55:16.073871: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:55:16.073895: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:55:16.073918: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:55:16.073934: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:55:16.073954: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:55:16.073977: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:55:16.073995: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:55:16.074012: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:55:16.074030: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:55:16.074058: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:55:16.074076: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:55:16.074092: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:55:16.074109: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:55:16.074130: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:55:16.074155: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:55:16.074183: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[1]
2017-11-22 09:55:26.074412: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.
2017-11-22 09:55:26.074511: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074532: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074548: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074563: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074577: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074592: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074607: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074621: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074635: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074650: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074664: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074679: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074713: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074730: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074744: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074759: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074773: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074787: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074802: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074816: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074831: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:26.074845: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:55:26.074859: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:55:26.074872: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:55:26.074912: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:55:26.074925: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:55:26.074940: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:55:26.074952: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:55:26.074964: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:55:26.074977: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:55:26.074990: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:55:26.075002: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:55:26.075014: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:55:26.075026: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:55:26.075037: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:55:26.075049: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:55:26.075061: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:55:26.075084: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:55:26.075097: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:55:26.075109: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:55:26.075121: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:55:26.075133: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:55:26.075145: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:55:26.075157: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:55:26.075168: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:55:26.075180: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:55:26.075192: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:55:26.075204: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:55:26.075216: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:55:26.075227: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:55:26.075240: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:55:26.075251: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:55:26.075263: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:55:26.075275: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:55:26.075287: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:55:26.075299: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:55:26.075310: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:55:26.075322: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:55:26.075334: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:55:26.075346: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:55:26.075359: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:55:26.075370: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:55:26.075382: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:55:26.075394: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:55:26.075406: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:55:26.075418: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:55:26.075430: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:55:26.075441: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:55:26.075453: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:55:26.075465: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:55:26.075477: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:55:26.075498: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:55:26.075511: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:55:26.075523: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:55:26.075535: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:55:26.075547: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:55:26.075558: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:55:26.075570: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:55:26.075582: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:55:26.075594: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:55:26.075606: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:55:26.075619: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:55:26.075631: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:55:26.075651: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:55:26.075665: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:55:26.075678: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:55:26.075693: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:55:26.075706: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:55:26.075719: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:55:26.075732: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:55:26.075746: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:55:26.075763: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:55:26.075783: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:55:26.075805: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]
2017-11-22 09:55:36.076042: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 288B.  Current allocation summary follows.
2017-11-22 09:55:36.076157: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076186: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076203: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076221: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076257: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076276: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076293: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076315: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076331: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076348: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076364: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076380: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076397: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076414: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076431: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076447: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076472: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076490: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076506: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076523: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076539: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:36.076575: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 512B was 512B, Chunk State: 
2017-11-22 09:55:36.076598: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:55:36.076614: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:55:36.076628: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:55:36.076651: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:55:36.076665: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:55:36.076679: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:55:36.076693: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:55:36.076707: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:55:36.076723: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:55:36.076738: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:55:36.076752: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:55:36.076767: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:55:36.076782: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:55:36.076796: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:55:36.076810: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:55:36.076825: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:55:36.076839: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:55:36.076853: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:55:36.076866: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:55:36.076899: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:55:36.076919: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:55:36.076933: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:55:36.076946: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:55:36.076960: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:55:36.076973: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:55:36.076986: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:55:36.076999: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:55:36.077013: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:55:36.077026: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:55:36.077039: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:55:36.077053: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:55:36.077077: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:55:36.077102: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:55:36.077138: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:55:36.077154: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:55:36.077168: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:55:36.077189: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:55:36.077203: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:55:36.077218: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:55:36.077232: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:55:36.077247: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:55:36.077261: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:55:36.077276: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:55:36.077290: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:55:36.077304: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:55:36.077319: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:55:36.077334: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:55:36.077348: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:55:36.077363: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:55:36.077377: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:55:36.077392: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:55:36.077411: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:55:36.077426: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:55:36.077442: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:55:36.077461: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:55:36.077476: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:55:36.077490: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:55:36.077504: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:55:36.077519: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:55:36.077534: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:55:36.077559: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:55:36.077583: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:55:36.077600: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:55:36.077617: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:55:36.077635: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:55:36.077651: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:55:36.077668: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:55:36.077684: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:55:36.077713: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:55:36.077746: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:55:36.077771: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:55:36.077799: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[3,3,1,8]
2017-11-22 09:55:46.077996: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 32B.  Current allocation summary follows.
2017-11-22 09:55:46.078120: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078144: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078161: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078178: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078195: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078211: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078228: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078244: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078261: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078278: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078294: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078311: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078328: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078395: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078414: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078431: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078448: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078472: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078499: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078515: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078532: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:46.078549: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:55:46.078566: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:55:46.078581: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:55:46.078595: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:55:46.078609: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:55:46.078624: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:55:46.078639: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:55:46.078661: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:55:46.078676: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:55:46.078690: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:55:46.078703: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:55:46.078717: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:55:46.078730: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:55:46.078743: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:55:46.078756: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:55:46.078780: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:55:46.078794: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:55:46.078807: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:55:46.078831: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:55:46.078846: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:55:46.078859: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:55:46.078873: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:55:46.078919: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:55:46.078934: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:55:46.078947: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:55:46.078961: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:55:46.078974: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:55:46.078987: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:55:46.079001: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:55:46.079014: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:55:46.079027: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:55:46.079040: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:55:46.079054: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:55:46.079067: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:55:46.079081: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:55:46.079094: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:55:46.079117: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:55:46.079130: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:55:46.079145: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:55:46.079160: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:55:46.079173: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:55:46.079187: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:55:46.079200: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:55:46.079219: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:55:46.079232: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:55:46.079245: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:55:46.079259: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:55:46.079272: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:55:46.079285: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:55:46.079298: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:55:46.079312: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:55:46.079325: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:55:46.079339: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:55:46.079363: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:55:46.079377: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:55:46.079391: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:55:46.079404: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:55:46.079417: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:55:46.079431: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:55:46.079453: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:55:46.079472: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:55:46.079486: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:55:46.079508: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:55:46.079524: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:55:46.079539: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:55:46.079556: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:55:46.079576: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:55:46.079602: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:55:46.079617: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:55:46.079633: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:55:46.079652: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:55:46.079675: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:55:46.079700: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[8]
2017-11-22 09:55:56.079914: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4B.  Current allocation summary follows.
2017-11-22 09:55:56.080021: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080046: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080065: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080083: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080101: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4096): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080118: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8192): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080159: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16384): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080179: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (32768): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080197: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (65536): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080215: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (131072): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080233: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (262144): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080250: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (524288): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080268: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080286: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080310: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080328: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080346: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080364: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080382: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080400: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080417: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-11-22 09:55:56.080434: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 256B was 256B, Chunk State: 
2017-11-22 09:55:56.080453: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800000 of size 1280
2017-11-22 09:55:56.080480: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800500 of size 256
2017-11-22 09:55:56.080496: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800600 of size 256
2017-11-22 09:55:56.080512: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800700 of size 256
2017-11-22 09:55:56.080526: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800800 of size 256
2017-11-22 09:55:56.080541: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800900 of size 256
2017-11-22 09:55:56.080555: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800a00 of size 256
2017-11-22 09:55:56.080570: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800b00 of size 256
2017-11-22 09:55:56.080585: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800c00 of size 512
2017-11-22 09:55:56.080599: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800e00 of size 256
2017-11-22 09:55:56.080614: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835800f00 of size 2304
2017-11-22 09:55:56.080629: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801800 of size 512
2017-11-22 09:55:56.080643: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801a00 of size 256
2017-11-22 09:55:56.080658: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801b00 of size 256
2017-11-22 09:55:56.080672: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835801c00 of size 2816
2017-11-22 09:55:56.080688: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835802700 of size 2304
2017-11-22 09:55:56.080702: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803000 of size 512
2017-11-22 09:55:56.080717: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803200 of size 256
2017-11-22 09:55:56.080731: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803300 of size 256
2017-11-22 09:55:56.080746: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803400 of size 256
2017-11-22 09:55:56.080760: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803500 of size 256
2017-11-22 09:55:56.080774: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803600 of size 256
2017-11-22 09:55:56.080791: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803700 of size 256
2017-11-22 09:55:56.080805: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803800 of size 256
2017-11-22 09:55:56.080819: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803900 of size 256
2017-11-22 09:55:56.080833: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803a00 of size 256
2017-11-22 09:55:56.080848: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803b00 of size 256
2017-11-22 09:55:56.080862: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803c00 of size 256
2017-11-22 09:55:56.080877: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803d00 of size 256
2017-11-22 09:55:56.080912: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803e00 of size 256
2017-11-22 09:55:56.080927: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835803f00 of size 256
2017-11-22 09:55:56.080942: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804000 of size 256
2017-11-22 09:55:56.080956: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804100 of size 512
2017-11-22 09:55:56.080971: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804300 of size 256
2017-11-22 09:55:56.080985: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804400 of size 256
2017-11-22 09:55:56.080999: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804500 of size 256
2017-11-22 09:55:56.081025: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804600 of size 256
2017-11-22 09:55:56.081041: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804700 of size 256
2017-11-22 09:55:56.081056: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835804800 of size 2304
2017-11-22 09:55:56.081070: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805100 of size 256
2017-11-22 09:55:56.081085: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805200 of size 2304
2017-11-22 09:55:56.081099: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805b00 of size 256
2017-11-22 09:55:56.081114: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835805c00 of size 2304
2017-11-22 09:55:56.081128: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806500 of size 256
2017-11-22 09:55:56.081143: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806600 of size 512
2017-11-22 09:55:56.081157: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806800 of size 256
2017-11-22 09:55:56.081173: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806900 of size 512
2017-11-22 09:55:56.081187: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806b00 of size 256
2017-11-22 09:55:56.081202: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835806c00 of size 2304
2017-11-22 09:55:56.081216: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807500 of size 256
2017-11-22 09:55:56.081230: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807600 of size 2304
2017-11-22 09:55:56.081245: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835807f00 of size 256
2017-11-22 09:55:56.081260: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808000 of size 2304
2017-11-22 09:55:56.081274: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808900 of size 256
2017-11-22 09:55:56.081289: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808a00 of size 512
2017-11-22 09:55:56.081303: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808c00 of size 256
2017-11-22 09:55:56.081318: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808d00 of size 512
2017-11-22 09:55:56.081332: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835808f00 of size 2304
2017-11-22 09:55:56.081347: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835809800 of size 7344128
2017-11-22 09:55:56.081362: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x10835f0a800 of size 7690240
2017-11-22 09:55:56.081377: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
2017-11-22 09:55:56.081407: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 39 Chunks of size 256 totalling 9.8KiB
2017-11-22 09:55:56.081425: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 512 totalling 4.0KiB
2017-11-22 09:55:56.081441: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 1280 totalling 1.2KiB
2017-11-22 09:55:56.081459: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 9 Chunks of size 2304 totalling 20.2KiB
2017-11-22 09:55:56.081475: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2816 totalling 2.8KiB
2017-11-22 09:55:56.081491: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7344128 totalling 7.00MiB
2017-11-22 09:55:56.081508: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 7690240 totalling 7.33MiB
2017-11-22 09:55:56.081525: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 14.38MiB
2017-11-22 09:55:56.081546: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                    15073280
InUse:                    15073280
MaxInUse:                 15073280
NumAllocs:                      66
MaxAllocSize:              7690240

2017-11-22 09:55:56.081583: W tensorflow/core/common_runtime/bfc_allocator.cc:277] **************************************************************************************************xx
2017-11-22 09:55:56.081611: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[]
Train on 450 samples, validate on 150 samples
Epoch 1/1
Traceback (most recent call last):
  File "/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/scripts/autoencoder_v01.py", line 225, in <module>
    autoencoder.fit(batch,batch,epochs=1,batch_size=30,shuffle=True,validation_split=0.25,callbacks=[training_history,early_stopping])
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/engine/training.py", line 1595, in fit
    validation_steps=validation_steps)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/engine/training.py", line 1182, in _fit_loop
    outs = f(ins_batch)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py", line 2270, in __call__
    **self.session_kwargs)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[3,3,8,8]
	 [[Node: training/Adam/mul_11 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"](Adam/beta_1/read, training/Adam/Variable_2/read)]]
	 [[Node: loss/mul/_37 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_1033_loss/mul", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

Caused by op u'training/Adam/mul_11', defined at:
  File "/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/scripts/autoencoder_v01.py", line 225, in <module>
    autoencoder.fit(batch,batch,epochs=1,batch_size=30,shuffle=True,validation_split=0.25,callbacks=[training_history,early_stopping])
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/engine/training.py", line 1576, in fit
    self._make_train_function()
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/engine/training.py", line 960, in _make_train_function
    loss=self.total_loss)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 87, in wrapper
    return func(*args, **kwargs)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/keras/optimizers.py", line 432, in get_updates
    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/ops/variables.py", line 705, in _run_op
    return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py", line 865, in binary_op_wrapper
    return func(x, y, name=name)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py", line 1088, in _mul_dispatch
    return gen_math_ops._mul(x, y, name=name)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py", line 1449, in _mul
    result = _op_def_lib.apply_op("Mul", x=x, y=y, name=name)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/afs/crc.nd.edu/x86_64_linux/t/tensorflow/1.3/gpu/python2/build/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[3,3,8,8]
	 [[Node: training/Adam/mul_11 = Mul[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"](Adam/beta_1/read, training/Adam/Variable_2/read)]]
	 [[Node: loss/mul/_37 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_1033_loss/mul", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

Using TensorFlow backend.
2017-11-22 09:56:27.823312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:02:00.0
Total memory: 10.91GiB
Free memory: 239.38MiB
2017-11-22 09:56:28.121137: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4f297e0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-22 09:56:28.121915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:03:00.0
Total memory: 10.91GiB
Free memory: 400.38MiB
Using TensorFlow backend.
2017-11-22 11:21:38.735150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:02:00.0
Total memory: 10.91GiB
Free memory: 10.34GiB
2017-11-22 11:21:39.059022: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x44932a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
20/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:03:00.0
Total memory: 10.91GiB
Free memory: 10.76GiB
2017-11-22 11:21:39.431559: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5eba5b0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-22 11:21:39.433893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:82:00.0
Total memory: 10.91GiB
Free memory: 10.76GiB
2017-11-22 11:21:39.785584: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5e22760 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2017-11-22 11:21:39.790010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties: 
name: GeForce GTX 1080 Ti
major: 6 minor: 1 memoryClockRate (GHz) 1.582
pciBusID 0000:83:00.0
Total memory: 10.91GiB
Free memory: 10.76GiB
2017-11-22 11:21:39.791941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 2
2017-11-22 11:21:39.791990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 0 and 3
2017-11-22 11:21:39.792034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 2
2017-11-22 11:21:39.792057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 1 and 3
2017-11-22 11:21:39.792078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 0
2017-11-22 11:21:39.792099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 2 and 1
2017-11-22 11:21:39.793525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 0
2017-11-22 11:21:39.793563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:847] Peer access not supported between device ordinals 3 and 1
2017-11-22 11:21:39.793673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3 
2017-11-22 11:21:39.793692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y N N 
2017-11-22 11:21:39.793706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y N N 
2017-11-22 11:21:39.793718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   N N Y Y 
2017-11-22 11:21:39.793730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   N N Y Y 
2017-11-22 11:21:39.793756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0)
2017-11-22 11:21:39.793772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0)
2017-11-22 11:21:39.793786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0)
2017-11-22 11:21:39.793799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0)
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 49s - loss: 0.2500 60/450 [===>..........................] - ETA: 24s - loss: 0.2497 90/450 [=====>........................] - ETA: 16s - loss: 0.2493120/450 [=======>......................] - ETA: 11s - loss: 0.2489150/450 [=========>....................] - ETA: 9s - loss: 0.2485 180/450 [===========>..................] - ETA: 7s - loss: 0.2480210/450 [=============>................] - ETA: 5s - loss: 0.2475240/450 [===============>..............] - ETA: 4s - loss: 0.2470270/450 [=================>............] - ETA: 3s - loss: 0.2464300/450 [===================>..........] - ETA: 2s - loss: 0.2458330/450 [=====================>........] - ETA: 2s - loss: 0.2452360/450 [=======================>......] - ETA: 1s - loss: 0.2446390/450 [=========================>....] - ETA: 0s - loss: 0.2439420/450 [===========================>..] - ETA: 0s - loss: 0.2431450/450 [==============================] - 7s - loss: 0.2424 - val_loss: 0.2291
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 0.2291 60/450 [===>..........................] - ETA: 3s - loss: 0.2278 90/450 [=====>........................] - ETA: 2s - loss: 0.2265120/450 [=======>......................] - ETA: 2s - loss: 0.2251150/450 [=========>....................] - ETA: 2s - loss: 0.2236180/450 [===========>..................] - ETA: 2s - loss: 0.2220210/450 [=============>................] - ETA: 1s - loss: 0.2203240/450 [===============>..............] - ETA: 1s - loss: 0.2185270/450 [=================>............] - ETA: 1s - loss: 0.2166300/450 [===================>..........] - ETA: 1s - loss: 0.2146330/450 [=====================>........] - ETA: 0s - loss: 0.2125360/450 [=======================>......] - ETA: 0s - loss: 0.2103390/450 [=========================>....] - ETA: 0s - loss: 0.2080420/450 [===========================>..] - ETA: 0s - loss: 0.2055450/450 [==============================] - 3s - loss: 0.2029 - val_loss: 0.1596
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 0.1596 60/450 [===>..........................] - ETA: 3s - loss: 0.1558 90/450 [=====>........................] - ETA: 2s - loss: 0.1518120/450 [=======>......................] - ETA: 2s - loss: 0.1478150/450 [=========>....................] - ETA: 2s - loss: 0.1436180/450 [===========>..................] - ETA: 2s - loss: 0.1393210/450 [=============>................] - ETA: 1s - loss: 0.1349240/450 [===============>..............] - ETA: 1s - loss: 0.1305270/450 [=================>............] - ETA: 1s - loss: 0.1259300/450 [===================>..........] - ETA: 1s - loss: 0.1214330/450 [=====================>........] - ETA: 0s - loss: 0.1168360/450 [=======================>......] - ETA: 0s - loss: 0.1123390/450 [=========================>....] - ETA: 0s - loss: 0.1078420/450 [===========================>..] - ETA: 0s - loss: 0.1034450/450 [==============================] - 3s - loss: 0.0991 - val_loss: 0.0325
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 0.0325 60/450 [===>..........................] - ETA: 3s - loss: 0.0296 90/450 [=====>........................] - ETA: 2s - loss: 0.0270120/450 [=======>......................] - ETA: 2s - loss: 0.0247150/450 [=========>....................] - ETA: 2s - loss: 0.0226180/450 [===========>..................] - ETA: 2s - loss: 0.0207210/450 [=============>................] - ETA: 1s - loss: 0.0191240/450 [===============>..............] - ETA: 1s - loss: 0.0176270/450 [=================>............] - ETA: 1s - loss: 0.0163300/450 [===================>..........] - ETA: 1s - loss: 0.0152330/450 [=====================>........] - ETA: 0s - loss: 0.0142360/450 [=======================>......] - ETA: 0s - loss: 0.0133390/450 [=========================>....] - ETA: 0s - loss: 0.0125420/450 [===========================>..] - ETA: 0s - loss: 0.0118450/450 [==============================] - 3s - loss: 0.0111 - val_loss: 0.0019
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 0.0019 60/450 [===>..........................] - ETA: 3s - loss: 0.0018 90/450 [=====>........................] - ETA: 2s - loss: 0.0017120/450 [=======>......................] - ETA: 2s - loss: 0.0016150/450 [=========>....................] - ETA: 2s - loss: 0.0015180/450 [===========>..................] - ETA: 2s - loss: 0.0015210/450 [=============>................] - ETA: 1s - loss: 0.0014240/450 [===============>..............] - ETA: 1s - loss: 0.0013270/450 [=================>............] - ETA: 1s - loss: 0.0013300/450 [===================>..........] - ETA: 1s - loss: 0.0012330/450 [=====================>........] - ETA: 0s - loss: 0.0012360/450 [=======================>......] - ETA: 0s - loss: 0.0012390/450 [=========================>....] - ETA: 0s - loss: 0.0011420/450 [===========================>..] - ETA: 0s - loss: 0.0011450/450 [==============================] - 3s - loss: 0.0011 - val_loss: 6.0015e-04
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.0015e-04 60/450 [===>..........................] - ETA: 3s - loss: 5.8689e-04 90/450 [=====>........................] - ETA: 2s - loss: 5.7431e-04120/450 [=======>......................] - ETA: 2s - loss: 5.6242e-04150/450 [=========>....................] - ETA: 2s - loss: 5.5113e-04180/450 [===========>..................] - ETA: 2s - loss: 5.4009e-04210/450 [=============>................] - ETA: 1s - loss: 5.2935e-04240/450 [===============>..............] - ETA: 1s - loss: 5.1893e-04270/450 [=================>............] - ETA: 1s - loss: 5.0883e-04300/450 [===================>..........] - ETA: 1s - loss: 4.9905e-04330/450 [=====================>........] - ETA: 0s - loss: 4.8956e-04360/450 [=======================>......] - ETA: 0s - loss: 4.8034e-04390/450 [=========================>....] - ETA: 0s - loss: 4.7140e-04420/450 [===========================>..] - ETA: 0s - loss: 4.6270e-04450/450 [==============================] - 3s - loss: 4.5424e-04 - val_loss: 3.2244e-04
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.2244e-04 60/450 [===>..........................] - ETA: 3s - loss: 3.1601e-04 90/450 [=====>........................] - ETA: 2s - loss: 3.0973e-04120/450 [=======>......................] - ETA: 2s - loss: 3.0359e-04150/450 [=========>....................] - ETA: 2s - loss: 2.9760e-04180/450 [===========>..................] - ETA: 2s - loss: 2.9173e-04210/450 [=============>................] - ETA: 1s - loss: 2.8599e-04240/450 [===============>..............] - ETA: 1s - loss: 2.8039e-04270/450 [=================>............] - ETA: 1s - loss: 2.7489e-04300/450 [===================>..........] - ETA: 1s - loss: 2.6952e-04330/450 [=====================>........] - ETA: 0s - loss: 2.6426e-04360/450 [=======================>......] - ETA: 0s - loss: 2.5912e-04390/450 [=========================>....] - ETA: 0s - loss: 2.5409e-04420/450 [===========================>..] - ETA: 0s - loss: 2.4917e-04450/450 [==============================] - 3s - loss: 2.4435e-04 - val_loss: 1.6911e-04
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6911e-04 60/450 [===>..........................] - ETA: 3s - loss: 1.6532e-04 90/450 [=====>........................] - ETA: 2s - loss: 1.6163e-04120/450 [=======>......................] - ETA: 2s - loss: 1.5803e-04150/450 [=========>....................] - ETA: 2s - loss: 1.5454e-04180/450 [===========>..................] - ETA: 2s - loss: 1.5114e-04210/450 [=============>................] - ETA: 1s - loss: 1.4783e-04240/450 [===============>..............] - ETA: 1s - loss: 1.4461e-04270/450 [=================>............] - ETA: 1s - loss: 1.4149e-04300/450 [===================>..........] - ETA: 1s - loss: 1.3845e-04330/450 [=====================>........] - ETA: 0s - loss: 1.3551e-04360/450 [=======================>......] - ETA: 0s - loss: 1.3265e-04390/450 [=========================>....] - ETA: 0s - loss: 1.2987e-04420/450 [===========================>..] - ETA: 0s - loss: 1.2717e-04450/450 [==============================] - 3s - loss: 1.2456e-04 - val_loss: 8.3953e-05
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.3950e-05 60/450 [===>..........................] - ETA: 3s - loss: 8.2059e-05 90/450 [=====>........................] - ETA: 2s - loss: 8.0234e-05120/450 [=======>......................] - ETA: 2s - loss: 7.8470e-05150/450 [=========>....................] - ETA: 2s - loss: 7.6766e-05180/450 [===========>..................] - ETA: 2s - loss: 7.5120e-05210/450 [=============>................] - ETA: 1s - loss: 7.3531e-05240/450 [===============>..............] - ETA: 1s - loss: 7.1996e-05270/450 [=================>............] - ETA: 1s - loss: 7.0513e-05300/450 [===================>..........] - ETA: 1s - loss: 6.9081e-05330/450 [=====================>........] - ETA: 0s - loss: 6.7697e-05360/450 [=======================>......] - ETA: 0s - loss: 6.6360e-05390/450 [=========================>....] - ETA: 0s - loss: 6.5068e-05420/450 [===========================>..] - ETA: 0s - loss: 6.3820e-05450/450 [==============================] - 3s - loss: 6.2613e-05 - val_loss: 4.3945e-05
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.3947e-05 60/450 [===>..........................] - ETA: 3s - loss: 4.3109e-05 90/450 [=====>........................] - ETA: 2s - loss: 4.2300e-05120/450 [=======>......................] - ETA: 2s - loss: 4.1519e-05150/450 [=========>....................] - ETA: 2s - loss: 4.0765e-05180/450 [===========>..................] - ETA: 2s - loss: 4.0038e-05210/450 [=============>................] - ETA: 1s - loss: 3.9336e-05240/450 [===============>..............] - ETA: 1s - loss: 3.8657e-05270/450 [=================>............] - ETA: 1s - loss: 3.8001e-05300/450 [===================>..........] - ETA: 1s - loss: 3.7367e-05330/450 [=====================>........] - ETA: 0s - loss: 3.6754e-05360/450 [=======================>......] - ETA: 0s - loss: 3.6161e-05390/450 [=========================>....] - ETA: 0s - loss: 3.5587e-05420/450 [===========================>..] - ETA: 0s - loss: 3.5031e-05450/450 [==============================] - 3s - loss: 3.4493e-05 - val_loss: 2.6153e-05
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.6153e-05 60/450 [===>..........................] - ETA: 3s - loss: 2.5769e-05 90/450 [=====>........................] - ETA: 2s - loss: 2.5396e-05120/450 [=======>......................] - ETA: 2s - loss: 2.5036e-05150/450 [=========>....................] - ETA: 2s - loss: 2.4686e-05180/450 [===========>..................] - ETA: 2s - loss: 2.4347e-05210/450 [=============>................] - ETA: 1s - loss: 2.4018e-05240/450 [===============>..............] - ETA: 1s - loss: 2.3699e-05270/450 [=================>............] - ETA: 1s - loss: 2.3389e-05300/450 [===================>..........] - ETA: 1s - loss: 2.3088e-05330/450 [=====================>........] - ETA: 0s - loss: 2.2796e-05360/450 [=======================>......] - ETA: 0s - loss: 2.2512e-05390/450 [=========================>....] - ETA: 0s - loss: 2.2235e-05420/450 [===========================>..] - ETA: 0s - loss: 2.1967e-05450/450 [==============================] - 3s - loss: 2.1705e-05 - val_loss: 1.7635e-05
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7634e-05 60/450 [===>..........................] - ETA: 3s - loss: 1.7437e-05 90/450 [=====>........................] - ETA: 2s - loss: 1.7245e-05120/450 [=======>......................] - ETA: 2s - loss: 1.7057e-05150/450 [=========>....................] - ETA: 2s - loss: 1.6875e-05180/450 [===========>..................] - ETA: 2s - loss: 1.6697e-05210/450 [=============>................] - ETA: 1s - loss: 1.6523e-05240/450 [===============>..............] - ETA: 1s - loss: 1.6354e-05270/450 [=================>............] - ETA: 1s - loss: 1.6189e-05300/450 [===================>..........] - ETA: 1s - loss: 1.6027e-05330/450 [=====================>........] - ETA: 0s - loss: 1.5870e-05360/450 [=======================>......] - ETA: 0s - loss: 1.5716e-05390/450 [=========================>....] - ETA: 0s - loss: 1.5565e-05420/450 [===========================>..] - ETA: 0s - loss: 1.5418e-05450/450 [==============================] - 3s - loss: 1.5274e-05 - val_loss: 1.3025e-05
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 2s - loss: 1.3025e-05 60/450 [===>..........................] - ETA: 2s - loss: 1.2911e-05 90/450 [=====>........................] - ETA: 2s - loss: 1.2799e-05120/450 [=======>......................] - ETA: 2s - loss: 1.2689e-05150/450 [=========>....................] - ETA: 2s - loss: 1.2580e-05180/450 [===========>..................] - ETA: 1s - loss: 1.2474e-05210/450 [=============>................] - ETA: 1s - loss: 1.2370e-05240/450 [===============>..............] - ETA: 1s - loss: 1.2269e-05270/450 [=================>............] - ETA: 1s - loss: 1.2169e-05300/450 [===================>..........] - ETA: 1s - loss: 1.2070e-05330/450 [=====================>........] - ETA: 0s - loss: 1.1974e-05360/450 [=======================>......] - ETA: 0s - loss: 1.1880e-05390/450 [=========================>....] - ETA: 0s - loss: 1.1787e-05420/450 [===========================>..] - ETA: 0s - loss: 1.1696e-05450/450 [==============================] - 3s - loss: 1.1607e-05 - val_loss: 1.0204e-05
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0204e-05 60/450 [===>..........................] - ETA: 3s - loss: 1.0130e-05 90/450 [=====>........................] - ETA: 2s - loss: 1.0056e-05120/450 [=======>......................] - ETA: 2s - loss: 9.9846e-06150/450 [=========>....................] - ETA: 2s - loss: 9.9140e-06180/450 [===========>..................] - ETA: 2s - loss: 9.8447e-06210/450 [=============>................] - ETA: 1s - loss: 9.7765e-06240/450 [===============>..............] - ETA: 1s - loss: 9.7095e-06270/450 [=================>............] - ETA: 1s - loss: 9.6435e-06300/450 [===================>..........] - ETA: 1s - loss: 9.5786e-06330/450 [=====================>........] - ETA: 0s - loss: 9.5148e-06360/450 [=======================>......] - ETA: 0s - loss: 9.4520e-06390/450 [=========================>....] - ETA: 0s - loss: 9.3902e-06420/450 [===========================>..] - ETA: 0s - loss: 9.3294e-06450/450 [==============================] - 3s - loss: 9.2695e-06 - val_loss: 8.3264e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.3265e-06 60/450 [===>..........................] - ETA: 3s - loss: 8.2752e-06 90/450 [=====>........................] - ETA: 2s - loss: 8.2247e-06120/450 [=======>......................] - ETA: 2s - loss: 8.1749e-06150/450 [=========>....................] - ETA: 2s - loss: 8.1258e-06180/450 [===========>..................] - ETA: 2s - loss: 8.0775e-06210/450 [=============>................] - ETA: 1s - loss: 8.0298e-06240/450 [===============>..............] - ETA: 1s - loss: 7.9829e-06270/450 [=================>............] - ETA: 1s - loss: 7.9366e-06300/450 [===================>..........] - ETA: 1s - loss: 7.8910e-06330/450 [=====================>........] - ETA: 0s - loss: 7.8461e-06360/450 [=======================>......] - ETA: 0s - loss: 7.8017e-06390/450 [=========================>....] - ETA: 0s - loss: 7.7580e-06420/450 [===========================>..] - ETA: 0s - loss: 7.7148e-06450/450 [==============================] - 3s - loss: 7.6722e-06 - val_loss: 7.0002e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.0000e-06 60/450 [===>..........................] - ETA: 3s - loss: 6.9627e-06 90/450 [=====>........................] - ETA: 2s - loss: 6.9260e-06120/450 [=======>......................] - ETA: 2s - loss: 6.8897e-06150/450 [=========>....................] - ETA: 2s - loss: 6.8538e-06180/450 [===========>..................] - ETA: 2s - loss: 6.8184e-06210/450 [=============>................] - ETA: 1s - loss: 6.7835e-06240/450 [===============>..............] - ETA: 1s - loss: 6.7490e-06270/450 [=================>............] - ETA: 1s - loss: 6.7149e-06300/450 [===================>..........] - ETA: 1s - loss: 6.6812e-06330/450 [=====================>........] - ETA: 0s - loss: 6.6480e-06360/450 [=======================>......] - ETA: 0s - loss: 6.6151e-06390/450 [=========================>....] - ETA: 0s - loss: 6.5827e-06420/450 [===========================>..] - ETA: 0s - loss: 6.5506e-06450/450 [==============================] - 3s - loss: 6.5189e-06 - val_loss: 6.0174e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.0179e-06 60/450 [===>..........................] - ETA: 3s - loss: 5.9897e-06 90/450 [=====>........................] - ETA: 2s - loss: 5.9618e-06120/450 [=======>......................] - ETA: 2s - loss: 5.9343e-06150/450 [=========>....................] - ETA: 2s - loss: 5.9070e-06180/450 [===========>..................] - ETA: 2s - loss: 5.8801e-06210/450 [=============>................] - ETA: 1s - loss: 5.8534e-06240/450 [===============>..............] - ETA: 1s - loss: 5.8270e-06270/450 [=================>............] - ETA: 1s - loss: 5.8009e-06300/450 [===================>..........] - ETA: 1s - loss: 5.7751e-06330/450 [=====================>........] - ETA: 0s - loss: 5.7496e-06360/450 [=======================>......] - ETA: 0s - loss: 5.7243e-06390/450 [=========================>....] - ETA: 0s - loss: 5.6994e-06420/450 [===========================>..] - ETA: 0s - loss: 5.6747e-06450/450 [==============================] - 3s - loss: 5.6503e-06 - val_loss: 5.2635e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.2635e-06 60/450 [===>..........................] - ETA: 3s - loss: 5.2415e-06 90/450 [=====>........................] - ETA: 2s - loss: 5.2196e-06120/450 [=======>......................] - ETA: 2s - loss: 5.1980e-06150/450 [=========>....................] - ETA: 2s - loss: 5.1766e-06180/450 [===========>..................] - ETA: 2s - loss: 5.1555e-06210/450 [=============>................] - ETA: 1s - loss: 5.1345e-06240/450 [===============>..............] - ETA: 1s - loss: 5.1138e-06270/450 [=================>............] - ETA: 1s - loss: 5.0933e-06300/450 [===================>..........] - ETA: 1s - loss: 5.0729e-06330/450 [=====================>........] - ETA: 0s - loss: 5.0528e-06360/450 [=======================>......] - ETA: 0s - loss: 5.0328e-06390/450 [=========================>....] - ETA: 0s - loss: 5.0131e-06420/450 [===========================>..] - ETA: 0s - loss: 4.9935e-06450/450 [==============================] - 3s - loss: 4.9741e-06 - val_loss: 4.6670e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.6670e-06 60/450 [===>..........................] - ETA: 3s - loss: 4.6493e-06 90/450 [=====>........................] - ETA: 2s - loss: 4.6317e-06120/450 [=======>......................] - ETA: 2s - loss: 4.6144e-06150/450 [=========>....................] - ETA: 2s - loss: 4.5972e-06180/450 [===========>..................] - ETA: 2s - loss: 4.5802e-06210/450 [=============>................] - ETA: 1s - loss: 4.5633e-06240/450 [===============>..............] - ETA: 1s - loss: 4.5466e-06270/450 [=================>............] - ETA: 1s - loss: 4.5300e-06300/450 [===================>..........] - ETA: 1s - loss: 4.5136e-06330/450 [=====================>........] - ETA: 0s - loss: 4.4973e-06360/450 [=======================>......] - ETA: 0s - loss: 4.4812e-06390/450 [=========================>....] - ETA: 0s - loss: 4.4652e-06420/450 [===========================>..] - ETA: 0s - loss: 4.4493e-06450/450 [==============================] - 3s - loss: 4.4336e-06 - val_loss: 4.1844e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.1845e-06 60/450 [===>..........................] - ETA: 3s - loss: 4.1700e-06 90/450 [=====>........................] - ETA: 2s - loss: 4.1556e-06120/450 [=======>......................] - ETA: 2s - loss: 4.1414e-06150/450 [=========>....................] - ETA: 2s - loss: 4.1273e-06180/450 [===========>..................] - ETA: 2s - loss: 4.1134e-06210/450 [=============>................] - ETA: 1s - loss: 4.0995e-06240/450 [===============>..............] - ETA: 1s - loss: 4.0857e-06270/450 [=================>............] - ETA: 1s - loss: 4.0721e-06300/450 [===================>..........] - ETA: 1s - loss: 4.0586e-06330/450 [=====================>........] - ETA: 0s - loss: 4.0452e-06360/450 [=======================>......] - ETA: 0s - loss: 4.0318e-06390/450 [=========================>....] - ETA: 0s - loss: 4.0186e-06420/450 [===========================>..] - ETA: 0s - loss: 4.0055e-06450/450 [==============================] - 3s - loss: 3.9925e-06 - val_loss: 3.7863e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.7861e-06 60/450 [===>..........................] - ETA: 3s - loss: 3.7740e-06 90/450 [=====>........................] - ETA: 2s - loss: 3.7621e-06120/450 [=======>......................] - ETA: 2s - loss: 3.7502e-06150/450 [=========>....................] - ETA: 2s - loss: 3.7385e-06180/450 [===========>..................] - ETA: 2s - loss: 3.7268e-06210/450 [=============>................] - ETA: 1s - loss: 3.7152e-06240/450 [===============>..............] - ETA: 1s - loss: 3.7037e-06270/450 [=================>............] - ETA: 1s - loss: 3.6923e-06300/450 [===================>..........] - ETA: 1s - loss: 3.6810e-06330/450 [=====================>........] - ETA: 0s - loss: 3.6697e-06360/450 [=======================>......] - ETA: 0s - loss: 3.6586e-06390/450 [=========================>....] - ETA: 0s - loss: 3.6475e-06420/450 [===========================>..] - ETA: 0s - loss: 3.6365e-06450/450 [==============================] - 3s - loss: 3.6256e-06 - val_loss: 3.4524e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.4524e-06 60/450 [===>..........................] - ETA: 3s - loss: 3.4423e-06 90/450 [=====>........................] - ETA: 2s - loss: 3.4321e-06120/450 [=======>......................] - ETA: 2s - loss: 3.4221e-06150/450 [=========>....................] - ETA: 2s - loss: 3.4122e-06180/450 [===========>..................] - ETA: 2s - loss: 3.4023e-06210/450 [=============>................] - ETA: 1s - loss: 3.3925e-06240/450 [===============>..............] - ETA: 1s - loss: 3.3827e-06270/450 [=================>............] - ETA: 1s - loss: 3.3730e-06300/450 [===================>..........] - ETA: 1s - loss: 3.3634e-06330/450 [=====================>........] - ETA: 0s - loss: 3.3539e-06360/450 [=======================>......] - ETA: 0s - loss: 3.3444e-06390/450 [=========================>....] - ETA: 0s - loss: 3.3350e-06420/450 [===========================>..] - ETA: 0s - loss: 3.3256e-06450/450 [==============================] - 3s - loss: 3.3163e-06 - val_loss: 3.1686e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.1687e-06 60/450 [===>..........................] - ETA: 3s - loss: 3.1599e-06 90/450 [=====>........................] - ETA: 2s - loss: 3.1513e-06120/450 [=======>......................] - ETA: 2s - loss: 3.1427e-06150/450 [=========>....................] - ETA: 2s - loss: 3.1342e-06180/450 [===========>..................] - ETA: 2s - loss: 3.1257e-06210/450 [=============>................] - ETA: 1s - loss: 3.1173e-06240/450 [===============>..............] - ETA: 1s - loss: 3.1089e-06270/450 [=================>............] - ETA: 1s - loss: 3.1006e-06300/450 [===================>..........] - ETA: 1s - loss: 3.0923e-06330/450 [=====================>........] - ETA: 0s - loss: 3.0841e-06360/450 [=======================>......] - ETA: 0s - loss: 3.0760e-06390/450 [=========================>....] - ETA: 0s - loss: 3.0678e-06420/450 [===========================>..] - ETA: 0s - loss: 3.0598e-06450/450 [==============================] - 3s - loss: 3.0518e-06 - val_loss: 2.9245e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.9245e-06 60/450 [===>..........................] - ETA: 3s - loss: 2.9170e-06 90/450 [=====>........................] - ETA: 2s - loss: 2.9095e-06120/450 [=======>......................] - ETA: 2s - loss: 2.9020e-06150/450 [=========>....................] - ETA: 2s - loss: 2.8947e-06180/450 [===========>..................] - ETA: 2s - loss: 2.8873e-06210/450 [=============>................] - ETA: 1s - loss: 2.8800e-06240/450 [===============>..............] - ETA: 1s - loss: 2.8727e-06270/450 [=================>............] - ETA: 1s - loss: 2.8655e-06300/450 [===================>..........] - ETA: 1s - loss: 2.8583e-06330/450 [=====================>........] - ETA: 0s - loss: 2.8512e-06360/450 [=======================>......] - ETA: 0s - loss: 2.8441e-06390/450 [=========================>....] - ETA: 0s - loss: 2.8371e-06420/450 [===========================>..] - ETA: 0s - loss: 2.8301e-06450/450 [==============================] - 3s - loss: 2.8231e-06 - val_loss: 2.7124e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.7124e-06 60/450 [===>..........................] - ETA: 3s - loss: 2.7058e-06 90/450 [=====>........................] - ETA: 2s - loss: 2.6992e-06120/450 [=======>......................] - ETA: 2s - loss: 2.6928e-06150/450 [=========>....................] - ETA: 2s - loss: 2.6863e-06180/450 [===========>..................] - ETA: 2s - loss: 2.6799e-06210/450 [=============>................] - ETA: 1s - loss: 2.6735e-06240/450 [===============>..............] - ETA: 1s - loss: 2.6671e-06270/450 [=================>............] - ETA: 1s - loss: 2.6608e-06300/450 [===================>..........] - ETA: 1s - loss: 2.6545e-06330/450 [=====================>........] - ETA: 0s - loss: 2.6482e-06360/450 [=======================>......] - ETA: 0s - loss: 2.6420e-06390/450 [=========================>....] - ETA: 0s - loss: 2.6358e-06420/450 [===========================>..] - ETA: 0s - loss: 2.6297e-06450/450 [==============================] - 3s - loss: 2.6236e-06 - val_loss: 2.5263e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.5263e-06 60/450 [===>..........................] - ETA: 3s - loss: 2.5205e-06 90/450 [=====>........................] - ETA: 2s - loss: 2.5147e-06120/450 [=======>......................] - ETA: 2s - loss: 2.5090e-06150/450 [=========>....................] - ETA: 2s - loss: 2.5033e-06180/450 [===========>..................] - ETA: 2s - loss: 2.4976e-06210/450 [=============>................] - ETA: 1s - loss: 2.4920e-06240/450 [===============>..............] - ETA: 1s - loss: 2.4863e-06270/450 [=================>............] - ETA: 1s - loss: 2.4808e-06300/450 [===================>..........] - ETA: 1s - loss: 2.4752e-06330/450 [=====================>........] - ETA: 0s - loss: 2.4697e-06360/450 [=======================>......] - ETA: 0s - loss: 2.4642e-06390/450 [=========================>....] - ETA: 0s - loss: 2.4587e-06420/450 [===========================>..] - ETA: 0s - loss: 2.4533e-06450/450 [==============================] - 3s - loss: 2.4479e-06 - val_loss: 2.3618e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.3618e-06 60/450 [===>..........................] - ETA: 3s - loss: 2.3566e-06 90/450 [=====>........................] - ETA: 2s - loss: 2.3515e-06120/450 [=======>......................] - ETA: 2s - loss: 2.3464e-06150/450 [=========>....................] - ETA: 2s - loss: 2.3413e-06180/450 [===========>..................] - ETA: 2s - loss: 2.3363e-06210/450 [=============>................] - ETA: 1s - loss: 2.3313e-06240/450 [===============>..............] - ETA: 1s - loss: 2.3263e-06270/450 [=================>............] - ETA: 1s - loss: 2.3213e-06300/450 [===================>..........] - ETA: 1s - loss: 2.3164e-06330/450 [=====================>........] - ETA: 0s - loss: 2.3115e-06360/450 [=======================>......] - ETA: 0s - loss: 2.3066e-06390/450 [=========================>....] - ETA: 0s - loss: 2.3017e-06420/450 [===========================>..] - ETA: 0s - loss: 2.2969e-06450/450 [==============================] - 3s - loss: 2.2920e-06 - val_loss: 2.2153e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2152e-06 60/450 [===>..........................] - ETA: 3s - loss: 2.2105e-06 90/450 [=====>........................] - ETA: 2s - loss: 2.2060e-06120/450 [=======>......................] - ETA: 2s - loss: 2.2014e-06150/450 [=========>....................] - ETA: 2s - loss: 2.1969e-06180/450 [===========>..................] - ETA: 2s - loss: 2.1924e-06210/450 [=============>................] - ETA: 1s - loss: 2.1879e-06240/450 [===============>..............] - ETA: 1s - loss: 2.1834e-06270/450 [=================>............] - ETA: 1s - loss: 2.1790e-06300/450 [===================>..........] - ETA: 1s - loss: 2.1745e-06330/450 [=====================>........] - ETA: 0s - loss: 2.1701e-06360/450 [=======================>......] - ETA: 0s - loss: 2.1658e-06390/450 [=========================>....] - ETA: 0s - loss: 2.1614e-06420/450 [===========================>..] - ETA: 0s - loss: 2.1571e-06450/450 [==============================] - 3s - loss: 2.1527e-06 - val_loss: 2.0838e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0839e-06 60/450 [===>..........................] - ETA: 3s - loss: 2.0797e-06 90/450 [=====>........................] - ETA: 2s - loss: 2.0756e-06120/450 [=======>......................] - ETA: 2s - loss: 2.0715e-06150/450 [=========>....................] - ETA: 2s - loss: 2.0674e-06180/450 [===========>..................] - ETA: 2s - loss: 2.0633e-06210/450 [=============>................] - ETA: 1s - loss: 2.0593e-06240/450 [===============>..............] - ETA: 1s - loss: 2.0553e-06270/450 [=================>............] - ETA: 1s - loss: 2.0513e-06300/450 [===================>..........] - ETA: 1s - loss: 2.0473e-06330/450 [=====================>........] - ETA: 0s - loss: 2.0433e-06360/450 [=======================>......] - ETA: 0s - loss: 2.0393e-06390/450 [=========================>....] - ETA: 0s - loss: 2.0354e-06420/450 [===========================>..] - ETA: 0s - loss: 2.0315e-06450/450 [==============================] - 3s - loss: 2.0276e-06 - val_loss: 1.9655e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9657e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.9619e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.9581e-06120/450 [=======>......................] - ETA: 2s - loss: 1.9544e-06150/450 [=========>....................] - ETA: 2s - loss: 1.9507e-06180/450 [===========>..................] - ETA: 2s - loss: 1.9471e-06210/450 [=============>................] - ETA: 1s - loss: 1.9434e-06240/450 [===============>..............] - ETA: 1s - loss: 1.9398e-06270/450 [=================>............] - ETA: 1s - loss: 1.9361e-06300/450 [===================>..........] - ETA: 1s - loss: 1.9325e-06330/450 [=====================>........] - ETA: 0s - loss: 1.9289e-06360/450 [=======================>......] - ETA: 0s - loss: 1.9253e-06390/450 [=========================>....] - ETA: 0s - loss: 1.9218e-06420/450 [===========================>..] - ETA: 0s - loss: 1.9182e-06450/450 [==============================] - 3s - loss: 1.9147e-06 - val_loss: 1.8584e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8584e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.8550e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.8516e-06120/450 [=======>......................] - ETA: 2s - loss: 1.8483e-06150/450 [=========>....................] - ETA: 2s - loss: 1.8449e-06180/450 [===========>..................] - ETA: 2s - loss: 1.8416e-06210/450 [=============>................] - ETA: 1s - loss: 1.8383e-06240/450 [===============>..............] - ETA: 1s - loss: 1.8350e-06270/450 [=================>............] - ETA: 1s - loss: 1.8317e-06300/450 [===================>..........] - ETA: 1s - loss: 1.8284e-06330/450 [=====================>........] - ETA: 0s - loss: 1.8251e-06360/450 [=======================>......] - ETA: 0s - loss: 1.8219e-06390/450 [=========================>....] - ETA: 0s - loss: 1.8186e-06420/450 [===========================>..] - ETA: 0s - loss: 1.8154e-06450/450 [==============================] - 3s - loss: 1.8122e-06 - val_loss: 1.7609e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7609e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.7577e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.7547e-06120/450 [=======>......................] - ETA: 2s - loss: 1.7516e-06150/450 [=========>....................] - ETA: 2s - loss: 1.7486e-06180/450 [===========>..................] - ETA: 2s - loss: 1.7455e-06210/450 [=============>................] - ETA: 1s - loss: 1.7425e-06240/450 [===============>..............] - ETA: 1s - loss: 1.7394e-06270/450 [=================>............] - ETA: 1s - loss: 1.7364e-06300/450 [===================>..........] - ETA: 1s - loss: 1.7334e-06330/450 [=====================>........] - ETA: 0s - loss: 1.7304e-06360/450 [=======================>......] - ETA: 0s - loss: 1.7275e-06390/450 [=========================>....] - ETA: 0s - loss: 1.7245e-06420/450 [===========================>..] - ETA: 0s - loss: 1.7215e-06450/450 [==============================] - 3s - loss: 1.7186e-06 - val_loss: 1.6717e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6716e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.6688e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.6660e-06120/450 [=======>......................] - ETA: 2s - loss: 1.6632e-06150/450 [=========>....................] - ETA: 2s - loss: 1.6603e-06180/450 [===========>..................] - ETA: 2s - loss: 1.6575e-06210/450 [=============>................] - ETA: 1s - loss: 1.6548e-06240/450 [===============>..............] - ETA: 1s - loss: 1.6520e-06270/450 [=================>............] - ETA: 1s - loss: 1.6492e-06300/450 [===================>..........] - ETA: 1s - loss: 1.6465e-06330/450 [=====================>........] - ETA: 0s - loss: 1.6437e-06360/450 [=======================>......] - ETA: 0s - loss: 1.6410e-06390/450 [=========================>....] - ETA: 0s - loss: 1.6382e-06420/450 [===========================>..] - ETA: 0s - loss: 1.6355e-06450/450 [==============================] - 3s - loss: 1.6328e-06 - val_loss: 1.5897e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5898e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.5872e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.5846e-06120/450 [=======>......................] - ETA: 2s - loss: 1.5820e-06150/450 [=========>....................] - ETA: 2s - loss: 1.5794e-06180/450 [===========>..................] - ETA: 2s - loss: 1.5768e-06210/450 [=============>................] - ETA: 1s - loss: 1.5743e-06240/450 [===============>..............] - ETA: 1s - loss: 1.5717e-06270/450 [=================>............] - ETA: 1s - loss: 1.5692e-06300/450 [===================>..........] - ETA: 1s - loss: 1.5666e-06330/450 [=====================>........] - ETA: 0s - loss: 1.5641e-06360/450 [=======================>......] - ETA: 0s - loss: 1.5616e-06390/450 [=========================>....] - ETA: 0s - loss: 1.5591e-06420/450 [===========================>..] - ETA: 0s - loss: 1.5566e-06450/450 [==============================] - 3s - loss: 1.5541e-06 - val_loss: 1.5143e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5144e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.5120e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.5096e-06120/450 [=======>......................] - ETA: 2s - loss: 1.5072e-06150/450 [=========>....................] - ETA: 2s - loss: 1.5048e-06180/450 [===========>..................] - ETA: 2s - loss: 1.5024e-06210/450 [=============>................] - ETA: 1s - loss: 1.5000e-06240/450 [===============>..............] - ETA: 1s - loss: 1.4977e-06270/450 [=================>............] - ETA: 1s - loss: 1.4953e-06300/450 [===================>..........] - ETA: 1s - loss: 1.4930e-06330/450 [=====================>........] - ETA: 0s - loss: 1.4907e-06360/450 [=======================>......] - ETA: 0s - loss: 1.4883e-06390/450 [=========================>....] - ETA: 0s - loss: 1.4860e-06420/450 [===========================>..] - ETA: 0s - loss: 1.4837e-06450/450 [==============================] - 3s - loss: 1.4814e-06 - val_loss: 1.4446e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4446e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.4424e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.4401e-06120/450 [=======>......................] - ETA: 2s - loss: 1.4379e-06150/450 [=========>....................] - ETA: 2s - loss: 1.4357e-06180/450 [===========>..................] - ETA: 2s - loss: 1.4335e-06210/450 [=============>................] - ETA: 1s - loss: 1.4313e-06240/450 [===============>..............] - ETA: 1s - loss: 1.4292e-06270/450 [=================>............] - ETA: 1s - loss: 1.4270e-06300/450 [===================>..........] - ETA: 1s - loss: 1.4248e-06330/450 [=====================>........] - ETA: 0s - loss: 1.4226e-06360/450 [=======================>......] - ETA: 0s - loss: 1.4205e-06390/450 [=========================>....] - ETA: 0s - loss: 1.4183e-06420/450 [===========================>..] - ETA: 0s - loss: 1.4162e-06450/450 [==============================] - 3s - loss: 1.4141e-06 - val_loss: 1.3800e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3800e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.3780e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.3759e-06120/450 [=======>......................] - ETA: 2s - loss: 1.3738e-06150/450 [=========>....................] - ETA: 2s - loss: 1.3718e-06180/450 [===========>..................] - ETA: 2s - loss: 1.3697e-06210/450 [=============>................] - ETA: 1s - loss: 1.3677e-06240/450 [===============>..............] - ETA: 1s - loss: 1.3657e-06270/450 [=================>............] - ETA: 1s - loss: 1.3636e-06300/450 [===================>..........] - ETA: 1s - loss: 1.3616e-06330/450 [=====================>........] - ETA: 0s - loss: 1.3596e-06360/450 [=======================>......] - ETA: 0s - loss: 1.3576e-06390/450 [=========================>....] - ETA: 0s - loss: 1.3556e-06420/450 [===========================>..] - ETA: 0s - loss: 1.3536e-06450/450 [==============================] - 3s - loss: 1.3516e-06 - val_loss: 1.3199e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3199e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.3180e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.3161e-06120/450 [=======>......................] - ETA: 2s - loss: 1.3142e-06150/450 [=========>....................] - ETA: 2s - loss: 1.3123e-06180/450 [===========>..................] - ETA: 2s - loss: 1.3104e-06210/450 [=============>................] - ETA: 1s - loss: 1.3085e-06240/450 [===============>..............] - ETA: 1s - loss: 1.3066e-06270/450 [=================>............] - ETA: 1s - loss: 1.3047e-06300/450 [===================>..........] - ETA: 1s - loss: 1.3028e-06330/450 [=====================>........] - ETA: 0s - loss: 1.3009e-06360/450 [=======================>......] - ETA: 0s - loss: 1.2991e-06390/450 [=========================>....] - ETA: 0s - loss: 1.2972e-06420/450 [===========================>..] - ETA: 0s - loss: 1.2953e-06450/450 [==============================] - 3s - loss: 1.2935e-06 - val_loss: 1.2640e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2640e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.2622e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.2603e-06120/450 [=======>......................] - ETA: 2s - loss: 1.2586e-06150/450 [=========>....................] - ETA: 2s - loss: 1.2568e-06180/450 [===========>..................] - ETA: 2s - loss: 1.2550e-06210/450 [=============>................] - ETA: 1s - loss: 1.2532e-06240/450 [===============>..............] - ETA: 1s - loss: 1.2515e-06270/450 [=================>............] - ETA: 1s - loss: 1.2497e-06300/450 [===================>..........] - ETA: 1s - loss: 1.2479e-06330/450 [=====================>........] - ETA: 0s - loss: 1.2462e-06360/450 [=======================>......] - ETA: 0s - loss: 1.2444e-06390/450 [=========================>....] - ETA: 0s - loss: 1.2427e-06420/450 [===========================>..] - ETA: 0s - loss: 1.2410e-06450/450 [==============================] - 3s - loss: 1.2392e-06 - val_loss: 1.2116e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2116e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.2099e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.2083e-06120/450 [=======>......................] - ETA: 2s - loss: 1.2066e-06150/450 [=========>....................] - ETA: 2s - loss: 1.2049e-06180/450 [===========>..................] - ETA: 2s - loss: 1.2033e-06210/450 [=============>................] - ETA: 1s - loss: 1.2016e-06240/450 [===============>..............] - ETA: 1s - loss: 1.1999e-06270/450 [=================>............] - ETA: 1s - loss: 1.1983e-06300/450 [===================>..........] - ETA: 1s - loss: 1.1967e-06330/450 [=====================>........] - ETA: 0s - loss: 1.1950e-06360/450 [=======================>......] - ETA: 0s - loss: 1.1934e-06390/450 [=========================>....] - ETA: 0s - loss: 1.1918e-06420/450 [===========================>..] - ETA: 0s - loss: 1.1901e-06450/450 [==============================] - 3s - loss: 1.1885e-06 - val_loss: 1.1626e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1627e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.1611e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.1595e-06120/450 [=======>......................] - ETA: 2s - loss: 1.1579e-06150/450 [=========>....................] - ETA: 2s - loss: 1.1564e-06180/450 [===========>..................] - ETA: 2s - loss: 1.1548e-06210/450 [=============>................] - ETA: 1s - loss: 1.1533e-06240/450 [===============>..............] - ETA: 1s - loss: 1.1517e-06270/450 [=================>............] - ETA: 1s - loss: 1.1502e-06300/450 [===================>..........] - ETA: 1s - loss: 1.1486e-06330/450 [=====================>........] - ETA: 0s - loss: 1.1471e-06360/450 [=======================>......] - ETA: 0s - loss: 1.1455e-06390/450 [=========================>....] - ETA: 0s - loss: 1.1440e-06420/450 [===========================>..] - ETA: 0s - loss: 1.1425e-06450/450 [==============================] - 3s - loss: 1.1410e-06 - val_loss: 1.1167e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1168e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.1153e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.1139e-06120/450 [=======>......................] - ETA: 2s - loss: 1.1125e-06150/450 [=========>....................] - ETA: 2s - loss: 1.1110e-06180/450 [===========>..................] - ETA: 2s - loss: 1.1096e-06210/450 [=============>................] - ETA: 1s - loss: 1.1081e-06240/450 [===============>..............] - ETA: 1s - loss: 1.1066e-06270/450 [=================>............] - ETA: 1s - loss: 1.1052e-06300/450 [===================>..........] - ETA: 1s - loss: 1.1037e-06330/450 [=====================>........] - ETA: 0s - loss: 1.1024e-06360/450 [=======================>......] - ETA: 0s - loss: 1.1010e-06390/450 [=========================>....] - ETA: 0s - loss: 1.0995e-06420/450 [===========================>..] - ETA: 0s - loss: 1.0981e-06450/450 [==============================] - 3s - loss: 1.0966e-06 - val_loss: 1.0735e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0737e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.0722e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.0708e-06120/450 [=======>......................] - ETA: 2s - loss: 1.0694e-06150/450 [=========>....................] - ETA: 2s - loss: 1.0680e-06180/450 [===========>..................] - ETA: 2s - loss: 1.0666e-06210/450 [=============>................] - ETA: 1s - loss: 1.0652e-06240/450 [===============>..............] - ETA: 1s - loss: 1.0639e-06270/450 [=================>............] - ETA: 1s - loss: 1.0625e-06300/450 [===================>..........] - ETA: 1s - loss: 1.0612e-06330/450 [=====================>........] - ETA: 0s - loss: 1.0599e-06360/450 [=======================>......] - ETA: 0s - loss: 1.0585e-06390/450 [=========================>....] - ETA: 0s - loss: 1.0572e-06420/450 [===========================>..] - ETA: 0s - loss: 1.0558e-06450/450 [==============================] - 3s - loss: 1.0544e-06 - val_loss: 1.0328e-06
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0328e-06 60/450 [===>..........................] - ETA: 3s - loss: 1.0315e-06 90/450 [=====>........................] - ETA: 2s - loss: 1.0302e-06120/450 [=======>......................] - ETA: 2s - loss: 1.0289e-06150/450 [=========>....................] - ETA: 2s - loss: 1.0276e-06180/450 [===========>..................] - ETA: 2s - loss: 1.0263e-06210/450 [=============>................] - ETA: 1s - loss: 1.0250e-06240/450 [===============>..............] - ETA: 1s - loss: 1.0237e-06270/450 [=================>............] - ETA: 1s - loss: 1.0224e-06300/450 [===================>..........] - ETA: 1s - loss: 1.0211e-06330/450 [=====================>........] - ETA: 0s - loss: 1.0198e-06360/450 [=======================>......] - ETA: 0s - loss: 1.0185e-06390/450 [=========================>....] - ETA: 0s - loss: 1.0172e-06420/450 [===========================>..] - ETA: 0s - loss: 1.0160e-06450/450 [==============================] - 3s - loss: 1.0147e-06 - val_loss: 9.9440e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.9444e-07 60/450 [===>..........................] - ETA: 3s - loss: 9.9319e-07 90/450 [=====>........................] - ETA: 2s - loss: 9.9194e-07120/450 [=======>......................] - ETA: 2s - loss: 9.9071e-07150/450 [=========>....................] - ETA: 2s - loss: 9.8948e-07180/450 [===========>..................] - ETA: 2s - loss: 9.8825e-07210/450 [=============>................] - ETA: 1s - loss: 9.8702e-07240/450 [===============>..............] - ETA: 1s - loss: 9.8580e-07270/450 [=================>............] - ETA: 1s - loss: 9.8458e-07300/450 [===================>..........] - ETA: 1s - loss: 9.8336e-07330/450 [=====================>........] - ETA: 0s - loss: 9.8215e-07360/450 [=======================>......] - ETA: 0s - loss: 9.8094e-07390/450 [=========================>....] - ETA: 0s - loss: 9.7974e-07420/450 [===========================>..] - ETA: 0s - loss: 9.7854e-07450/450 [==============================] - 3s - loss: 9.7733e-07 - val_loss: 9.5816e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.5813e-07 60/450 [===>..........................] - ETA: 3s - loss: 9.5696e-07 90/450 [=====>........................] - ETA: 2s - loss: 9.5578e-07120/450 [=======>......................] - ETA: 2s - loss: 9.5462e-07150/450 [=========>....................] - ETA: 2s - loss: 9.5345e-07180/450 [===========>..................] - ETA: 2s - loss: 9.5229e-07210/450 [=============>................] - ETA: 1s - loss: 9.5114e-07240/450 [===============>..............] - ETA: 1s - loss: 9.4998e-07270/450 [=================>............] - ETA: 1s - loss: 9.4883e-07300/450 [===================>..........] - ETA: 1s - loss: 9.4768e-07330/450 [=====================>........] - ETA: 0s - loss: 9.4653e-07360/450 [=======================>......] - ETA: 0s - loss: 9.4538e-07390/450 [=========================>....] - ETA: 0s - loss: 9.4424e-07420/450 [===========================>..] - ETA: 0s - loss: 9.4310e-07450/450 [==============================] - 3s - loss: 9.4196e-07 - val_loss: 9.2383e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.2418e-07 60/450 [===>..........................] - ETA: 3s - loss: 9.2289e-07 90/450 [=====>........................] - ETA: 2s - loss: 9.2172e-07120/450 [=======>......................] - ETA: 2s - loss: 9.2065e-07150/450 [=========>....................] - ETA: 2s - loss: 9.1958e-07180/450 [===========>..................] - ETA: 2s - loss: 9.1855e-07210/450 [=============>................] - ETA: 1s - loss: 9.1741e-07240/450 [===============>..............] - ETA: 1s - loss: 9.1628e-07270/450 [=================>............] - ETA: 1s - loss: 9.1518e-07300/450 [===================>..........] - ETA: 1s - loss: 9.1428e-07330/450 [=====================>........] - ETA: 0s - loss: 9.1319e-07360/450 [=======================>......] - ETA: 0s - loss: 9.1211e-07390/450 [=========================>....] - ETA: 0s - loss: 9.1100e-07420/450 [===========================>..] - ETA: 0s - loss: 9.0989e-07450/450 [==============================] - 3s - loss: 9.0880e-07 - val_loss: 8.9129e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.9129e-07 60/450 [===>..........................] - ETA: 3s - loss: 8.9025e-07 90/450 [=====>........................] - ETA: 2s - loss: 8.8920e-07120/450 [=======>......................] - ETA: 2s - loss: 8.8815e-07150/450 [=========>....................] - ETA: 2s - loss: 8.8710e-07180/450 [===========>..................] - ETA: 2s - loss: 8.8605e-07210/450 [=============>................] - ETA: 1s - loss: 8.8501e-07240/450 [===============>..............] - ETA: 1s - loss: 8.8397e-07270/450 [=================>............] - ETA: 1s - loss: 8.8293e-07300/450 [===================>..........] - ETA: 1s - loss: 8.8190e-07330/450 [=====================>........] - ETA: 0s - loss: 8.8087e-07360/450 [=======================>......] - ETA: 0s - loss: 8.7984e-07390/450 [=========================>....] - ETA: 0s - loss: 8.7881e-07420/450 [===========================>..] - ETA: 0s - loss: 8.7778e-07450/450 [==============================] - 3s - loss: 8.7676e-07 - val_loss: 8.6044e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.6043e-07 60/450 [===>..........................] - ETA: 3s - loss: 8.5945e-07 90/450 [=====>........................] - ETA: 2s - loss: 8.5844e-07120/450 [=======>......................] - ETA: 2s - loss: 8.5744e-07150/450 [=========>....................] - ETA: 2s - loss: 8.5644e-07180/450 [===========>..................] - ETA: 2s - loss: 8.5546e-07210/450 [=============>................] - ETA: 1s - loss: 8.5447e-07240/450 [===============>..............] - ETA: 1s - loss: 8.5349e-07270/450 [=================>............] - ETA: 1s - loss: 8.5250e-07300/450 [===================>..........] - ETA: 1s - loss: 8.5152e-07330/450 [=====================>........] - ETA: 0s - loss: 8.5054e-07360/450 [=======================>......] - ETA: 0s - loss: 8.4956e-07390/450 [=========================>....] - ETA: 0s - loss: 8.4859e-07420/450 [===========================>..] - ETA: 0s - loss: 8.4761e-07450/450 [==============================] - 3s - loss: 8.4664e-07 - val_loss: 8.3111e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.3114e-07 60/450 [===>..........................] - ETA: 3s - loss: 8.3017e-07 90/450 [=====>........................] - ETA: 2s - loss: 8.2921e-07120/450 [=======>......................] - ETA: 2s - loss: 8.2827e-07150/450 [=========>....................] - ETA: 2s - loss: 8.2732e-07180/450 [===========>..................] - ETA: 2s - loss: 8.2638e-07210/450 [=============>................] - ETA: 1s - loss: 8.2544e-07240/450 [===============>..............] - ETA: 1s - loss: 8.2450e-07270/450 [=================>............] - ETA: 1s - loss: 8.2357e-07300/450 [===================>..........] - ETA: 1s - loss: 8.2263e-07330/450 [=====================>........] - ETA: 0s - loss: 8.2170e-07360/450 [=======================>......] - ETA: 0s - loss: 8.2076e-07390/450 [=========================>....] - ETA: 0s - loss: 8.1984e-07420/450 [===========================>..] - ETA: 0s - loss: 8.1891e-07450/450 [==============================] - 3s - loss: 8.1799e-07 - val_loss: 8.0322e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.0324e-07 60/450 [===>..........................] - ETA: 3s - loss: 8.0232e-07 90/450 [=====>........................] - ETA: 2s - loss: 8.0141e-07120/450 [=======>......................] - ETA: 2s - loss: 8.0051e-07150/450 [=========>....................] - ETA: 2s - loss: 7.9961e-07180/450 [===========>..................] - ETA: 2s - loss: 7.9871e-07210/450 [=============>................] - ETA: 1s - loss: 7.9782e-07240/450 [===============>..............] - ETA: 1s - loss: 7.9692e-07270/450 [=================>............] - ETA: 1s - loss: 7.9603e-07300/450 [===================>..........] - ETA: 1s - loss: 7.9514e-07330/450 [=====================>........] - ETA: 0s - loss: 7.9426e-07360/450 [=======================>......] - ETA: 0s - loss: 7.9337e-07390/450 [=========================>....] - ETA: 0s - loss: 7.9249e-07420/450 [===========================>..] - ETA: 0s - loss: 7.9161e-07450/450 [==============================] - 3s - loss: 7.9073e-07 - val_loss: 7.7669e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.7666e-07 60/450 [===>..........................] - ETA: 3s - loss: 7.7581e-07 90/450 [=====>........................] - ETA: 2s - loss: 7.7495e-07120/450 [=======>......................] - ETA: 2s - loss: 7.7409e-07150/450 [=========>....................] - ETA: 2s - loss: 7.7323e-07180/450 [===========>..................] - ETA: 2s - loss: 7.7238e-07210/450 [=============>................] - ETA: 1s - loss: 7.7152e-07240/450 [===============>..............] - ETA: 1s - loss: 7.7067e-07270/450 [=================>............] - ETA: 1s - loss: 7.6982e-07300/450 [===================>..........] - ETA: 1s - loss: 7.6897e-07330/450 [=====================>........] - ETA: 0s - loss: 7.6812e-07360/450 [=======================>......] - ETA: 0s - loss: 7.6728e-07390/450 [=========================>....] - ETA: 0s - loss: 7.6644e-07420/450 [===========================>..] - ETA: 0s - loss: 7.6560e-07450/450 [==============================] - 3s - loss: 7.6476e-07 - val_loss: 7.5139e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.5138e-07 60/450 [===>..........................] - ETA: 3s - loss: 7.5055e-07 90/450 [=====>........................] - ETA: 2s - loss: 7.4974e-07120/450 [=======>......................] - ETA: 2s - loss: 7.4892e-07150/450 [=========>....................] - ETA: 2s - loss: 7.4810e-07180/450 [===========>..................] - ETA: 2s - loss: 7.4729e-07210/450 [=============>................] - ETA: 1s - loss: 7.4648e-07240/450 [===============>..............] - ETA: 1s - loss: 7.4567e-07270/450 [=================>............] - ETA: 1s - loss: 7.4486e-07300/450 [===================>..........] - ETA: 1s - loss: 7.4405e-07330/450 [=====================>........] - ETA: 0s - loss: 7.4324e-07360/450 [=======================>......] - ETA: 0s - loss: 7.4243e-07390/450 [=========================>....] - ETA: 0s - loss: 7.4163e-07420/450 [===========================>..] - ETA: 0s - loss: 7.4083e-07450/450 [==============================] - 3s - loss: 7.4003e-07 - val_loss: 7.2723e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.2723e-07 60/450 [===>..........................] - ETA: 3s - loss: 7.2645e-07 90/450 [=====>........................] - ETA: 2s - loss: 7.2567e-07120/450 [=======>......................] - ETA: 2s - loss: 7.2488e-07150/450 [=========>....................] - ETA: 2s - loss: 7.2410e-07180/450 [===========>..................] - ETA: 2s - loss: 7.2332e-07210/450 [=============>................] - ETA: 1s - loss: 7.2254e-07240/450 [===============>..............] - ETA: 1s - loss: 7.2177e-07270/450 [=================>............] - ETA: 1s - loss: 7.2100e-07300/450 [===================>..........] - ETA: 1s - loss: 7.2022e-07330/450 [=====================>........] - ETA: 0s - loss: 7.1945e-07360/450 [=======================>......] - ETA: 0s - loss: 7.1868e-07390/450 [=========================>....] - ETA: 0s - loss: 7.1791e-07420/450 [===========================>..] - ETA: 0s - loss: 7.1715e-07450/450 [==============================] - 3s - loss: 7.1638e-07 - val_loss: 7.0417e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.0419e-07 60/450 [===>..........................] - ETA: 3s - loss: 7.0343e-07 90/450 [=====>........................] - ETA: 2s - loss: 7.0267e-07120/450 [=======>......................] - ETA: 2s - loss: 7.0193e-07150/450 [=========>....................] - ETA: 2s - loss: 7.0118e-07180/450 [===========>..................] - ETA: 2s - loss: 7.0044e-07210/450 [=============>................] - ETA: 1s - loss: 6.9970e-07240/450 [===============>..............] - ETA: 1s - loss: 6.9896e-07270/450 [=================>............] - ETA: 1s - loss: 6.9822e-07300/450 [===================>..........] - ETA: 1s - loss: 6.9748e-07330/450 [=====================>........] - ETA: 0s - loss: 6.9674e-07360/450 [=======================>......] - ETA: 0s - loss: 6.9600e-07390/450 [=========================>....] - ETA: 0s - loss: 6.9527e-07420/450 [===========================>..] - ETA: 0s - loss: 6.9454e-07450/450 [==============================] - 3s - loss: 6.9381e-07 - val_loss: 6.8212e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.8213e-07 60/450 [===>..........................] - ETA: 3s - loss: 6.8141e-07 90/450 [=====>........................] - ETA: 2s - loss: 6.8070e-07120/450 [=======>......................] - ETA: 2s - loss: 6.7999e-07150/450 [=========>....................] - ETA: 2s - loss: 6.7927e-07180/450 [===========>..................] - ETA: 2s - loss: 6.7856e-07210/450 [=============>................] - ETA: 1s - loss: 6.7784e-07240/450 [===============>..............] - ETA: 1s - loss: 6.7714e-07270/450 [=================>............] - ETA: 1s - loss: 6.7643e-07300/450 [===================>..........] - ETA: 1s - loss: 6.7572e-07330/450 [=====================>........] - ETA: 0s - loss: 6.7501e-07360/450 [=======================>......] - ETA: 0s - loss: 6.7431e-07390/450 [=========================>....] - ETA: 0s - loss: 6.7361e-07420/450 [===========================>..] - ETA: 0s - loss: 6.7291e-07450/450 [==============================] - 3s - loss: 6.7221e-07 - val_loss: 6.6104e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.6100e-07 60/450 [===>..........................] - ETA: 3s - loss: 6.6032e-07 90/450 [=====>........................] - ETA: 2s - loss: 6.5964e-07120/450 [=======>......................] - ETA: 2s - loss: 6.5895e-07150/450 [=========>....................] - ETA: 2s - loss: 6.5828e-07180/450 [===========>..................] - ETA: 2s - loss: 6.5759e-07210/450 [=============>................] - ETA: 1s - loss: 6.5692e-07240/450 [===============>..............] - ETA: 1s - loss: 6.5624e-07270/450 [=================>............] - ETA: 1s - loss: 6.5556e-07300/450 [===================>..........] - ETA: 1s - loss: 6.5489e-07330/450 [=====================>........] - ETA: 0s - loss: 6.5421e-07360/450 [=======================>......] - ETA: 0s - loss: 6.5354e-07390/450 [=========================>....] - ETA: 0s - loss: 6.5287e-07420/450 [===========================>..] - ETA: 0s - loss: 6.5220e-07450/450 [==============================] - 3s - loss: 6.5153e-07 - val_loss: 6.4088e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.4088e-07 60/450 [===>..........................] - ETA: 3s - loss: 6.4022e-07 90/450 [=====>........................] - ETA: 2s - loss: 6.3955e-07120/450 [=======>......................] - ETA: 2s - loss: 6.3891e-07150/450 [=========>....................] - ETA: 2s - loss: 6.3826e-07180/450 [===========>..................] - ETA: 2s - loss: 6.3760e-07210/450 [=============>................] - ETA: 1s - loss: 6.3696e-07240/450 [===============>..............] - ETA: 1s - loss: 6.3631e-07270/450 [=================>............] - ETA: 1s - loss: 6.3566e-07300/450 [===================>..........] - ETA: 1s - loss: 6.3500e-07330/450 [=====================>........] - ETA: 0s - loss: 6.3436e-07360/450 [=======================>......] - ETA: 0s - loss: 6.3372e-07390/450 [=========================>....] - ETA: 0s - loss: 6.3307e-07420/450 [===========================>..] - ETA: 0s - loss: 6.3243e-07450/450 [==============================] - 3s - loss: 6.3179e-07 - val_loss: 6.2152e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.2152e-07 60/450 [===>..........................] - ETA: 3s - loss: 6.2089e-07 90/450 [=====>........................] - ETA: 2s - loss: 6.2027e-07120/450 [=======>......................] - ETA: 2s - loss: 6.1965e-07150/450 [=========>....................] - ETA: 2s - loss: 6.1902e-07180/450 [===========>..................] - ETA: 2s - loss: 6.1839e-07210/450 [=============>................] - ETA: 1s - loss: 6.1776e-07240/450 [===============>..............] - ETA: 1s - loss: 6.1714e-07270/450 [=================>............] - ETA: 1s - loss: 6.1652e-07300/450 [===================>..........] - ETA: 1s - loss: 6.1590e-07330/450 [=====================>........] - ETA: 0s - loss: 6.1528e-07360/450 [=======================>......] - ETA: 0s - loss: 6.1466e-07390/450 [=========================>....] - ETA: 0s - loss: 6.1404e-07420/450 [===========================>..] - ETA: 0s - loss: 6.1342e-07450/450 [==============================] - 3s - loss: 6.1280e-07 - val_loss: 6.0299e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.0298e-07 60/450 [===>..........................] - ETA: 3s - loss: 6.0237e-07 90/450 [=====>........................] - ETA: 2s - loss: 6.0177e-07120/450 [=======>......................] - ETA: 2s - loss: 6.0117e-07150/450 [=========>....................] - ETA: 2s - loss: 6.0057e-07180/450 [===========>..................] - ETA: 2s - loss: 5.9996e-07210/450 [=============>................] - ETA: 1s - loss: 5.9937e-07240/450 [===============>..............] - ETA: 1s - loss: 5.9877e-07270/450 [=================>............] - ETA: 1s - loss: 5.9817e-07300/450 [===================>..........] - ETA: 1s - loss: 5.9758e-07330/450 [=====================>........] - ETA: 0s - loss: 5.9698e-07360/450 [=======================>......] - ETA: 0s - loss: 5.9639e-07390/450 [=========================>....] - ETA: 0s - loss: 5.9580e-07420/450 [===========================>..] - ETA: 0s - loss: 5.9521e-07450/450 [==============================] - 3s - loss: 5.9462e-07 - val_loss: 5.8517e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.8511e-07 60/450 [===>..........................] - ETA: 3s - loss: 5.8456e-07 90/450 [=====>........................] - ETA: 2s - loss: 5.8398e-07120/450 [=======>......................] - ETA: 2s - loss: 5.8342e-07150/450 [=========>....................] - ETA: 2s - loss: 5.8284e-07180/450 [===========>..................] - ETA: 2s - loss: 5.8227e-07210/450 [=============>................] - ETA: 1s - loss: 5.8169e-07240/450 [===============>..............] - ETA: 1s - loss: 5.8111e-07270/450 [=================>............] - ETA: 1s - loss: 5.8054e-07300/450 [===================>..........] - ETA: 1s - loss: 5.7997e-07330/450 [=====================>........] - ETA: 0s - loss: 5.7940e-07360/450 [=======================>......] - ETA: 0s - loss: 5.7883e-07390/450 [=========================>....] - ETA: 0s - loss: 5.7826e-07420/450 [===========================>..] - ETA: 0s - loss: 5.7770e-07450/450 [==============================] - 3s - loss: 5.7713e-07 - val_loss: 5.6808e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.6811e-07 60/450 [===>..........................] - ETA: 3s - loss: 5.6753e-07 90/450 [=====>........................] - ETA: 2s - loss: 5.6698e-07120/450 [=======>......................] - ETA: 2s - loss: 5.6642e-07150/450 [=========>....................] - ETA: 2s - loss: 5.6587e-07180/450 [===========>..................] - ETA: 2s - loss: 5.6531e-07210/450 [=============>................] - ETA: 1s - loss: 5.6476e-07240/450 [===============>..............] - ETA: 1s - loss: 5.6421e-07270/450 [=================>............] - ETA: 1s - loss: 5.6366e-07300/450 [===================>..........] - ETA: 1s - loss: 5.6311e-07330/450 [=====================>........] - ETA: 0s - loss: 5.6256e-07360/450 [=======================>......] - ETA: 0s - loss: 5.6201e-07390/450 [=========================>....] - ETA: 0s - loss: 5.6147e-07420/450 [===========================>..] - ETA: 0s - loss: 5.6092e-07450/450 [==============================] - 3s - loss: 5.6038e-07 - val_loss: 5.5171e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.5172e-07 60/450 [===>..........................] - ETA: 3s - loss: 5.5118e-07 90/450 [=====>........................] - ETA: 2s - loss: 5.5065e-07120/450 [=======>......................] - ETA: 2s - loss: 5.5012e-07150/450 [=========>....................] - ETA: 2s - loss: 5.4958e-07180/450 [===========>..................] - ETA: 2s - loss: 5.4905e-07210/450 [=============>................] - ETA: 1s - loss: 5.4851e-07240/450 [===============>..............] - ETA: 1s - loss: 5.4798e-07270/450 [=================>............] - ETA: 1s - loss: 5.4745e-07300/450 [===================>..........] - ETA: 1s - loss: 5.4693e-07330/450 [=====================>........] - ETA: 0s - loss: 5.4640e-07360/450 [=======================>......] - ETA: 0s - loss: 5.4588e-07390/450 [=========================>....] - ETA: 0s - loss: 5.4535e-07420/450 [===========================>..] - ETA: 0s - loss: 5.4483e-07450/450 [==============================] - 3s - loss: 5.4430e-07 - val_loss: 5.3595e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.3624e-07 60/450 [===>..........................] - ETA: 3s - loss: 5.3608e-07 90/450 [=====>........................] - ETA: 2s - loss: 5.3563e-07120/450 [=======>......................] - ETA: 2s - loss: 5.3493e-07150/450 [=========>....................] - ETA: 2s - loss: 5.3436e-07180/450 [===========>..................] - ETA: 2s - loss: 5.3400e-07210/450 [=============>................] - ETA: 1s - loss: 5.3342e-07240/450 [===============>..............] - ETA: 1s - loss: 5.3284e-07270/450 [=================>............] - ETA: 1s - loss: 5.3233e-07300/450 [===================>..........] - ETA: 1s - loss: 5.3177e-07330/450 [=====================>........] - ETA: 0s - loss: 5.3132e-07360/450 [=======================>......] - ETA: 0s - loss: 5.3081e-07390/450 [=========================>....] - ETA: 0s - loss: 5.3027e-07420/450 [===========================>..] - ETA: 0s - loss: 5.2975e-07450/450 [==============================] - 3s - loss: 5.2922e-07 - val_loss: 5.2077e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 2s - loss: 5.2085e-07 60/450 [===>..........................] - ETA: 2s - loss: 5.2055e-07 90/450 [=====>........................] - ETA: 2s - loss: 5.1996e-07120/450 [=======>......................] - ETA: 2s - loss: 5.1948e-07150/450 [=========>....................] - ETA: 2s - loss: 5.1895e-07180/450 [===========>..................] - ETA: 2s - loss: 5.1844e-07210/450 [=============>................] - ETA: 1s - loss: 5.1793e-07240/450 [===============>..............] - ETA: 1s - loss: 5.1742e-07270/450 [=================>............] - ETA: 1s - loss: 5.1692e-07300/450 [===================>..........] - ETA: 1s - loss: 5.1646e-07330/450 [=====================>........] - ETA: 0s - loss: 5.1606e-07360/450 [=======================>......] - ETA: 0s - loss: 5.1559e-07390/450 [=========================>....] - ETA: 0s - loss: 5.1510e-07420/450 [===========================>..] - ETA: 0s - loss: 5.1460e-07450/450 [==============================] - 3s - loss: 5.1410e-07 - val_loss: 5.0618e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.0618e-07 60/450 [===>..........................] - ETA: 3s - loss: 5.0570e-07 90/450 [=====>........................] - ETA: 2s - loss: 5.0522e-07120/450 [=======>......................] - ETA: 2s - loss: 5.0475e-07150/450 [=========>....................] - ETA: 2s - loss: 5.0427e-07180/450 [===========>..................] - ETA: 2s - loss: 5.0380e-07210/450 [=============>................] - ETA: 1s - loss: 5.0333e-07240/450 [===============>..............] - ETA: 1s - loss: 5.0286e-07270/450 [=================>............] - ETA: 1s - loss: 5.0239e-07300/450 [===================>..........] - ETA: 1s - loss: 5.0192e-07330/450 [=====================>........] - ETA: 0s - loss: 5.0145e-07360/450 [=======================>......] - ETA: 0s - loss: 5.0098e-07390/450 [=========================>....] - ETA: 0s - loss: 5.0051e-07420/450 [===========================>..] - ETA: 0s - loss: 5.0004e-07450/450 [==============================] - 3s - loss: 4.9958e-07 - val_loss: 4.9212e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.9213e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.9165e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.9121e-07120/450 [=======>......................] - ETA: 2s - loss: 4.9075e-07150/450 [=========>....................] - ETA: 2s - loss: 4.9029e-07180/450 [===========>..................] - ETA: 2s - loss: 4.8984e-07210/450 [=============>................] - ETA: 1s - loss: 4.8939e-07240/450 [===============>..............] - ETA: 1s - loss: 4.8893e-07270/450 [=================>............] - ETA: 1s - loss: 4.8848e-07300/450 [===================>..........] - ETA: 1s - loss: 4.8803e-07330/450 [=====================>........] - ETA: 0s - loss: 4.8758e-07360/450 [=======================>......] - ETA: 0s - loss: 4.8713e-07390/450 [=========================>....] - ETA: 0s - loss: 4.8667e-07420/450 [===========================>..] - ETA: 0s - loss: 4.8622e-07450/450 [==============================] - 3s - loss: 4.8577e-07 - val_loss: 4.7861e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.7860e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.7817e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.7773e-07120/450 [=======>......................] - ETA: 2s - loss: 4.7729e-07150/450 [=========>....................] - ETA: 2s - loss: 4.7684e-07180/450 [===========>..................] - ETA: 2s - loss: 4.7641e-07210/450 [=============>................] - ETA: 1s - loss: 4.7597e-07240/450 [===============>..............] - ETA: 1s - loss: 4.7553e-07270/450 [=================>............] - ETA: 1s - loss: 4.7509e-07300/450 [===================>..........] - ETA: 1s - loss: 4.7465e-07330/450 [=====================>........] - ETA: 0s - loss: 4.7422e-07360/450 [=======================>......] - ETA: 0s - loss: 4.7378e-07390/450 [=========================>....] - ETA: 0s - loss: 4.7335e-07420/450 [===========================>..] - ETA: 0s - loss: 4.7291e-07450/450 [==============================] - 3s - loss: 4.7248e-07 - val_loss: 4.6557e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.6558e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.6515e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.6473e-07120/450 [=======>......................] - ETA: 2s - loss: 4.6430e-07150/450 [=========>....................] - ETA: 2s - loss: 4.6387e-07180/450 [===========>..................] - ETA: 2s - loss: 4.6345e-07210/450 [=============>................] - ETA: 1s - loss: 4.6302e-07240/450 [===============>..............] - ETA: 1s - loss: 4.6260e-07270/450 [=================>............] - ETA: 1s - loss: 4.6218e-07300/450 [===================>..........] - ETA: 1s - loss: 4.6176e-07330/450 [=====================>........] - ETA: 0s - loss: 4.6134e-07360/450 [=======================>......] - ETA: 0s - loss: 4.6092e-07390/450 [=========================>....] - ETA: 0s - loss: 4.6050e-07420/450 [===========================>..] - ETA: 0s - loss: 4.6008e-07450/450 [==============================] - 3s - loss: 4.5967e-07 - val_loss: 4.5299e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.5298e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.5257e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.5216e-07120/450 [=======>......................] - ETA: 2s - loss: 4.5175e-07150/450 [=========>....................] - ETA: 2s - loss: 4.5135e-07180/450 [===========>..................] - ETA: 2s - loss: 4.5094e-07210/450 [=============>................] - ETA: 1s - loss: 4.5053e-07240/450 [===============>..............] - ETA: 1s - loss: 4.5012e-07270/450 [=================>............] - ETA: 1s - loss: 4.4972e-07300/450 [===================>..........] - ETA: 1s - loss: 4.4931e-07330/450 [=====================>........] - ETA: 0s - loss: 4.4891e-07360/450 [=======================>......] - ETA: 0s - loss: 4.4850e-07390/450 [=========================>....] - ETA: 0s - loss: 4.4810e-07420/450 [===========================>..] - ETA: 0s - loss: 4.4770e-07450/450 [==============================] - 3s - loss: 4.4729e-07 - val_loss: 4.4086e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.4087e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.4047e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.4007e-07120/450 [=======>......................] - ETA: 2s - loss: 4.3967e-07150/450 [=========>....................] - ETA: 2s - loss: 4.3928e-07180/450 [===========>..................] - ETA: 2s - loss: 4.3889e-07210/450 [=============>................] - ETA: 1s - loss: 4.3849e-07240/450 [===============>..............] - ETA: 1s - loss: 4.3810e-07270/450 [=================>............] - ETA: 1s - loss: 4.3771e-07300/450 [===================>..........] - ETA: 1s - loss: 4.3731e-07330/450 [=====================>........] - ETA: 0s - loss: 4.3692e-07360/450 [=======================>......] - ETA: 0s - loss: 4.3653e-07390/450 [=========================>....] - ETA: 0s - loss: 4.3614e-07420/450 [===========================>..] - ETA: 0s - loss: 4.3576e-07450/450 [==============================] - 3s - loss: 4.3537e-07 - val_loss: 4.2917e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.2918e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.2877e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.2840e-07120/450 [=======>......................] - ETA: 2s - loss: 4.2801e-07150/450 [=========>....................] - ETA: 2s - loss: 4.2763e-07180/450 [===========>..................] - ETA: 2s - loss: 4.2725e-07210/450 [=============>................] - ETA: 1s - loss: 4.2687e-07240/450 [===============>..............] - ETA: 1s - loss: 4.2649e-07270/450 [=================>............] - ETA: 1s - loss: 4.2611e-07300/450 [===================>..........] - ETA: 1s - loss: 4.2574e-07330/450 [=====================>........] - ETA: 0s - loss: 4.2536e-07360/450 [=======================>......] - ETA: 0s - loss: 4.2498e-07390/450 [=========================>....] - ETA: 0s - loss: 4.2461e-07420/450 [===========================>..] - ETA: 0s - loss: 4.2423e-07450/450 [==============================] - 3s - loss: 4.2386e-07 - val_loss: 4.1787e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.1786e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.1750e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.1713e-07120/450 [=======>......................] - ETA: 2s - loss: 4.1676e-07150/450 [=========>....................] - ETA: 2s - loss: 4.1639e-07180/450 [===========>..................] - ETA: 2s - loss: 4.1603e-07210/450 [=============>................] - ETA: 1s - loss: 4.1566e-07240/450 [===============>..............] - ETA: 1s - loss: 4.1530e-07270/450 [=================>............] - ETA: 1s - loss: 4.1493e-07300/450 [===================>..........] - ETA: 1s - loss: 4.1456e-07330/450 [=====================>........] - ETA: 0s - loss: 4.1420e-07360/450 [=======================>......] - ETA: 0s - loss: 4.1383e-07390/450 [=========================>....] - ETA: 0s - loss: 4.1347e-07420/450 [===========================>..] - ETA: 0s - loss: 4.1311e-07450/450 [==============================] - 3s - loss: 4.1275e-07 - val_loss: 4.0696e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.0694e-07 60/450 [===>..........................] - ETA: 3s - loss: 4.0659e-07 90/450 [=====>........................] - ETA: 2s - loss: 4.0624e-07120/450 [=======>......................] - ETA: 2s - loss: 4.0589e-07150/450 [=========>....................] - ETA: 2s - loss: 4.0553e-07180/450 [===========>..................] - ETA: 2s - loss: 4.0518e-07210/450 [=============>................] - ETA: 1s - loss: 4.0483e-07240/450 [===============>..............] - ETA: 1s - loss: 4.0447e-07270/450 [=================>............] - ETA: 1s - loss: 4.0412e-07300/450 [===================>..........] - ETA: 1s - loss: 4.0377e-07330/450 [=====================>........] - ETA: 0s - loss: 4.0341e-07360/450 [=======================>......] - ETA: 0s - loss: 4.0306e-07390/450 [=========================>....] - ETA: 0s - loss: 4.0271e-07420/450 [===========================>..] - ETA: 0s - loss: 4.0236e-07450/450 [==============================] - 3s - loss: 4.0201e-07 - val_loss: 3.9643e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.9642e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.9607e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.9572e-07120/450 [=======>......................] - ETA: 2s - loss: 3.9538e-07150/450 [=========>....................] - ETA: 2s - loss: 3.9504e-07180/450 [===========>..................] - ETA: 2s - loss: 3.9470e-07210/450 [=============>................] - ETA: 1s - loss: 3.9436e-07240/450 [===============>..............] - ETA: 1s - loss: 3.9402e-07270/450 [=================>............] - ETA: 1s - loss: 3.9367e-07300/450 [===================>..........] - ETA: 1s - loss: 3.9333e-07330/450 [=====================>........] - ETA: 0s - loss: 3.9299e-07360/450 [=======================>......] - ETA: 0s - loss: 3.9265e-07390/450 [=========================>....] - ETA: 0s - loss: 3.9231e-07420/450 [===========================>..] - ETA: 0s - loss: 3.9198e-07450/450 [==============================] - 3s - loss: 3.9164e-07 - val_loss: 3.8623e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.8622e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.8589e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.8556e-07120/450 [=======>......................] - ETA: 2s - loss: 3.8523e-07150/450 [=========>....................] - ETA: 2s - loss: 3.8490e-07180/450 [===========>..................] - ETA: 2s - loss: 3.8457e-07210/450 [=============>................] - ETA: 1s - loss: 3.8424e-07240/450 [===============>..............] - ETA: 1s - loss: 3.8391e-07270/450 [=================>............] - ETA: 1s - loss: 3.8358e-07300/450 [===================>..........] - ETA: 1s - loss: 3.8325e-07330/450 [=====================>........] - ETA: 0s - loss: 3.8292e-07360/450 [=======================>......] - ETA: 0s - loss: 3.8259e-07390/450 [=========================>....] - ETA: 0s - loss: 3.8226e-07420/450 [===========================>..] - ETA: 0s - loss: 3.8193e-07450/450 [==============================] - 3s - loss: 3.8161e-07 - val_loss: 3.7638e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.7638e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.7605e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.7573e-07120/450 [=======>......................] - ETA: 2s - loss: 3.7541e-07150/450 [=========>....................] - ETA: 2s - loss: 3.7509e-07180/450 [===========>..................] - ETA: 2s - loss: 3.7477e-07210/450 [=============>................] - ETA: 1s - loss: 3.7445e-07240/450 [===============>..............] - ETA: 1s - loss: 3.7413e-07270/450 [=================>............] - ETA: 1s - loss: 3.7381e-07300/450 [===================>..........] - ETA: 1s - loss: 3.7349e-07330/450 [=====================>........] - ETA: 0s - loss: 3.7317e-07360/450 [=======================>......] - ETA: 0s - loss: 3.7286e-07390/450 [=========================>....] - ETA: 0s - loss: 3.7254e-07420/450 [===========================>..] - ETA: 0s - loss: 3.7222e-07450/450 [==============================] - 3s - loss: 3.7191e-07 - val_loss: 3.6686e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.6687e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.6655e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.6624e-07120/450 [=======>......................] - ETA: 2s - loss: 3.6593e-07150/450 [=========>....................] - ETA: 2s - loss: 3.6562e-07180/450 [===========>..................] - ETA: 2s - loss: 3.6531e-07210/450 [=============>................] - ETA: 1s - loss: 3.6500e-07240/450 [===============>..............] - ETA: 1s - loss: 3.6470e-07270/450 [=================>............] - ETA: 1s - loss: 3.6439e-07300/450 [===================>..........] - ETA: 1s - loss: 3.6408e-07330/450 [=====================>........] - ETA: 0s - loss: 3.6377e-07360/450 [=======================>......] - ETA: 0s - loss: 3.6346e-07390/450 [=========================>....] - ETA: 0s - loss: 3.6316e-07420/450 [===========================>..] - ETA: 0s - loss: 3.6285e-07450/450 [==============================] - 3s - loss: 3.6254e-07 - val_loss: 3.5766e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.5764e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.5734e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.5704e-07120/450 [=======>......................] - ETA: 2s - loss: 3.5674e-07150/450 [=========>....................] - ETA: 2s - loss: 3.5644e-07180/450 [===========>..................] - ETA: 2s - loss: 3.5614e-07210/450 [=============>................] - ETA: 1s - loss: 3.5584e-07240/450 [===============>..............] - ETA: 1s - loss: 3.5554e-07270/450 [=================>............] - ETA: 1s - loss: 3.5524e-07300/450 [===================>..........] - ETA: 1s - loss: 3.5495e-07330/450 [=====================>........] - ETA: 0s - loss: 3.5465e-07360/450 [=======================>......] - ETA: 0s - loss: 3.5435e-07390/450 [=========================>....] - ETA: 0s - loss: 3.5405e-07420/450 [===========================>..] - ETA: 0s - loss: 3.5376e-07450/450 [==============================] - 3s - loss: 3.5346e-07 - val_loss: 3.4874e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.4875e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.4846e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.4817e-07120/450 [=======>......................] - ETA: 2s - loss: 3.4788e-07150/450 [=========>....................] - ETA: 2s - loss: 3.4759e-07180/450 [===========>..................] - ETA: 2s - loss: 3.4729e-07210/450 [=============>................] - ETA: 1s - loss: 3.4701e-07240/450 [===============>..............] - ETA: 1s - loss: 3.4672e-07270/450 [=================>............] - ETA: 1s - loss: 3.4642e-07300/450 [===================>..........] - ETA: 1s - loss: 3.4613e-07330/450 [=====================>........] - ETA: 0s - loss: 3.4585e-07360/450 [=======================>......] - ETA: 0s - loss: 3.4556e-07390/450 [=========================>....] - ETA: 0s - loss: 3.4527e-07420/450 [===========================>..] - ETA: 0s - loss: 3.4498e-07450/450 [==============================] - 3s - loss: 3.4470e-07 - val_loss: 3.4010e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.4015e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.3985e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.3956e-07120/450 [=======>......................] - ETA: 2s - loss: 3.3928e-07150/450 [=========>....................] - ETA: 2s - loss: 3.3900e-07180/450 [===========>..................] - ETA: 2s - loss: 3.3872e-07210/450 [=============>................] - ETA: 1s - loss: 3.3844e-07240/450 [===============>..............] - ETA: 1s - loss: 3.3816e-07270/450 [=================>............] - ETA: 1s - loss: 3.3788e-07300/450 [===================>..........] - ETA: 1s - loss: 3.3760e-07330/450 [=====================>........] - ETA: 0s - loss: 3.3732e-07360/450 [=======================>......] - ETA: 0s - loss: 3.3704e-07390/450 [=========================>....] - ETA: 0s - loss: 3.3677e-07420/450 [===========================>..] - ETA: 0s - loss: 3.3649e-07450/450 [==============================] - 3s - loss: 3.3621e-07 - val_loss: 3.3174e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.3175e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.3147e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.3120e-07120/450 [=======>......................] - ETA: 2s - loss: 3.3092e-07150/450 [=========>....................] - ETA: 2s - loss: 3.3065e-07180/450 [===========>..................] - ETA: 2s - loss: 3.3038e-07210/450 [=============>................] - ETA: 1s - loss: 3.3010e-07240/450 [===============>..............] - ETA: 1s - loss: 3.2983e-07270/450 [=================>............] - ETA: 1s - loss: 3.2956e-07300/450 [===================>..........] - ETA: 1s - loss: 3.2929e-07330/450 [=====================>........] - ETA: 0s - loss: 3.2902e-07360/450 [=======================>......] - ETA: 0s - loss: 3.2875e-07390/450 [=========================>....] - ETA: 0s - loss: 3.2848e-07420/450 [===========================>..] - ETA: 0s - loss: 3.2821e-07450/450 [==============================] - 3s - loss: 3.2794e-07 - val_loss: 3.2365e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.2366e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.2376e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.2345e-07120/450 [=======>......................] - ETA: 2s - loss: 3.2310e-07150/450 [=========>....................] - ETA: 2s - loss: 3.2288e-07180/450 [===========>..................] - ETA: 2s - loss: 3.2269e-07210/450 [=============>................] - ETA: 1s - loss: 3.2243e-07240/450 [===============>..............] - ETA: 1s - loss: 3.2216e-07270/450 [=================>............] - ETA: 1s - loss: 3.2196e-07300/450 [===================>..........] - ETA: 1s - loss: 3.2171e-07330/450 [=====================>........] - ETA: 0s - loss: 3.2147e-07360/450 [=======================>......] - ETA: 0s - loss: 3.2120e-07390/450 [=========================>....] - ETA: 0s - loss: 3.2090e-07420/450 [===========================>..] - ETA: 0s - loss: 3.2061e-07450/450 [==============================] - 3s - loss: 3.2033e-07 - val_loss: 3.1583e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.1584e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.1556e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.1531e-07120/450 [=======>......................] - ETA: 2s - loss: 3.1505e-07150/450 [=========>....................] - ETA: 2s - loss: 3.1479e-07180/450 [===========>..................] - ETA: 2s - loss: 3.1454e-07210/450 [=============>................] - ETA: 1s - loss: 3.1428e-07240/450 [===============>..............] - ETA: 1s - loss: 3.1403e-07270/450 [=================>............] - ETA: 1s - loss: 3.1377e-07300/450 [===================>..........] - ETA: 1s - loss: 3.1352e-07330/450 [=====================>........] - ETA: 0s - loss: 3.1326e-07360/450 [=======================>......] - ETA: 0s - loss: 3.1301e-07390/450 [=========================>....] - ETA: 0s - loss: 3.1276e-07420/450 [===========================>..] - ETA: 0s - loss: 3.1250e-07450/450 [==============================] - 3s - loss: 3.1225e-07 - val_loss: 3.0821e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.0851e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.0832e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.0796e-07120/450 [=======>......................] - ETA: 2s - loss: 3.0781e-07150/450 [=========>....................] - ETA: 2s - loss: 3.0754e-07180/450 [===========>..................] - ETA: 2s - loss: 3.0724e-07210/450 [=============>................] - ETA: 1s - loss: 3.0706e-07240/450 [===============>..............] - ETA: 1s - loss: 3.0683e-07270/450 [=================>............] - ETA: 1s - loss: 3.0654e-07300/450 [===================>..........] - ETA: 1s - loss: 3.0637e-07330/450 [=====================>........] - ETA: 0s - loss: 3.0609e-07360/450 [=======================>......] - ETA: 0s - loss: 3.0581e-07390/450 [=========================>....] - ETA: 0s - loss: 3.0554e-07420/450 [===========================>..] - ETA: 0s - loss: 3.0531e-07450/450 [==============================] - 3s - loss: 3.0507e-07 - val_loss: 3.0085e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.0085e-07 60/450 [===>..........................] - ETA: 3s - loss: 3.0060e-07 90/450 [=====>........................] - ETA: 2s - loss: 3.0036e-07120/450 [=======>......................] - ETA: 2s - loss: 3.0012e-07150/450 [=========>....................] - ETA: 2s - loss: 2.9988e-07180/450 [===========>..................] - ETA: 2s - loss: 2.9963e-07210/450 [=============>................] - ETA: 1s - loss: 2.9939e-07240/450 [===============>..............] - ETA: 1s - loss: 2.9916e-07270/450 [=================>............] - ETA: 1s - loss: 2.9892e-07300/450 [===================>..........] - ETA: 1s - loss: 2.9868e-07330/450 [=====================>........] - ETA: 0s - loss: 2.9844e-07360/450 [=======================>......] - ETA: 0s - loss: 2.9820e-07390/450 [=========================>....] - ETA: 0s - loss: 2.9796e-07420/450 [===========================>..] - ETA: 0s - loss: 2.9772e-07450/450 [==============================] - 3s - loss: 2.9749e-07 - val_loss: 2.9369e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.9371e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.9348e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.9325e-07120/450 [=======>......................] - ETA: 2s - loss: 2.9302e-07150/450 [=========>....................] - ETA: 2s - loss: 2.9278e-07180/450 [===========>..................] - ETA: 2s - loss: 2.9255e-07210/450 [=============>................] - ETA: 1s - loss: 2.9232e-07240/450 [===============>..............] - ETA: 1s - loss: 2.9208e-07270/450 [=================>............] - ETA: 1s - loss: 2.9185e-07300/450 [===================>..........] - ETA: 1s - loss: 2.9161e-07330/450 [=====================>........] - ETA: 0s - loss: 2.9138e-07360/450 [=======================>......] - ETA: 0s - loss: 2.9115e-07390/450 [=========================>....] - ETA: 0s - loss: 2.9092e-07420/450 [===========================>..] - ETA: 0s - loss: 2.9069e-07450/450 [==============================] - 3s - loss: 2.9046e-07 - val_loss: 2.8679e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.8679e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.8657e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.8634e-07120/450 [=======>......................] - ETA: 2s - loss: 2.8611e-07150/450 [=========>....................] - ETA: 2s - loss: 2.8589e-07180/450 [===========>..................] - ETA: 2s - loss: 2.8567e-07210/450 [=============>................] - ETA: 1s - loss: 2.8544e-07240/450 [===============>..............] - ETA: 1s - loss: 2.8521e-07270/450 [=================>............] - ETA: 1s - loss: 2.8499e-07300/450 [===================>..........] - ETA: 1s - loss: 2.8477e-07330/450 [=====================>........] - ETA: 0s - loss: 2.8454e-07360/450 [=======================>......] - ETA: 0s - loss: 2.8432e-07390/450 [=========================>....] - ETA: 0s - loss: 2.8410e-07420/450 [===========================>..] - ETA: 0s - loss: 2.8387e-07450/450 [==============================] - 3s - loss: 2.8365e-07 - val_loss: 2.8006e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.8006e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.7983e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.7962e-07120/450 [=======>......................] - ETA: 2s - loss: 2.7940e-07150/450 [=========>....................] - ETA: 2s - loss: 2.7918e-07180/450 [===========>..................] - ETA: 2s - loss: 2.7896e-07210/450 [=============>................] - ETA: 1s - loss: 2.7874e-07240/450 [===============>..............] - ETA: 1s - loss: 2.7852e-07270/450 [=================>............] - ETA: 1s - loss: 2.7830e-07300/450 [===================>..........] - ETA: 1s - loss: 2.7808e-07330/450 [=====================>........] - ETA: 0s - loss: 2.7786e-07360/450 [=======================>......] - ETA: 0s - loss: 2.7765e-07390/450 [=========================>....] - ETA: 0s - loss: 2.7743e-07420/450 [===========================>..] - ETA: 0s - loss: 2.7721e-07450/450 [==============================] - 3s - loss: 2.7700e-07 - val_loss: 2.7354e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.7352e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.7331e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.7310e-07120/450 [=======>......................] - ETA: 2s - loss: 2.7289e-07150/450 [=========>....................] - ETA: 2s - loss: 2.7268e-07180/450 [===========>..................] - ETA: 2s - loss: 2.7247e-07210/450 [=============>................] - ETA: 1s - loss: 2.7226e-07240/450 [===============>..............] - ETA: 1s - loss: 2.7205e-07270/450 [=================>............] - ETA: 1s - loss: 2.7184e-07300/450 [===================>..........] - ETA: 1s - loss: 2.7162e-07330/450 [=====================>........] - ETA: 0s - loss: 2.7141e-07360/450 [=======================>......] - ETA: 0s - loss: 2.7120e-07390/450 [=========================>....] - ETA: 0s - loss: 2.7099e-07420/450 [===========================>..] - ETA: 0s - loss: 2.7078e-07450/450 [==============================] - 3s - loss: 2.7057e-07 - val_loss: 2.6721e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.6720e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.6700e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.6679e-07120/450 [=======>......................] - ETA: 2s - loss: 2.6658e-07150/450 [=========>....................] - ETA: 2s - loss: 2.6637e-07180/450 [===========>..................] - ETA: 2s - loss: 2.6617e-07210/450 [=============>................] - ETA: 1s - loss: 2.6596e-07240/450 [===============>..............] - ETA: 1s - loss: 2.6575e-07270/450 [=================>............] - ETA: 1s - loss: 2.6555e-07300/450 [===================>..........] - ETA: 1s - loss: 2.6534e-07330/450 [=====================>........] - ETA: 0s - loss: 2.6514e-07360/450 [=======================>......] - ETA: 0s - loss: 2.6493e-07390/450 [=========================>....] - ETA: 0s - loss: 2.6473e-07420/450 [===========================>..] - ETA: 0s - loss: 2.6452e-07450/450 [==============================] - 3s - loss: 2.6432e-07 - val_loss: 2.6106e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.6105e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.6085e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.6066e-07120/450 [=======>......................] - ETA: 2s - loss: 2.6046e-07150/450 [=========>....................] - ETA: 2s - loss: 2.6026e-07180/450 [===========>..................] - ETA: 2s - loss: 2.6005e-07210/450 [=============>................] - ETA: 1s - loss: 2.5985e-07240/450 [===============>..............] - ETA: 1s - loss: 2.5965e-07270/450 [=================>............] - ETA: 1s - loss: 2.5946e-07300/450 [===================>..........] - ETA: 1s - loss: 2.5926e-07330/450 [=====================>........] - ETA: 0s - loss: 2.5906e-07360/450 [=======================>......] - ETA: 0s - loss: 2.5886e-07390/450 [=========================>....] - ETA: 0s - loss: 2.5866e-07420/450 [===========================>..] - ETA: 0s - loss: 2.5846e-07450/450 [==============================] - 3s - loss: 2.5826e-07 - val_loss: 2.5511e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.5511e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.5490e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.5471e-07120/450 [=======>......................] - ETA: 2s - loss: 2.5452e-07150/450 [=========>....................] - ETA: 2s - loss: 2.5433e-07180/450 [===========>..................] - ETA: 2s - loss: 2.5413e-07210/450 [=============>................] - ETA: 1s - loss: 2.5393e-07240/450 [===============>..............] - ETA: 1s - loss: 2.5374e-07270/450 [=================>............] - ETA: 1s - loss: 2.5355e-07300/450 [===================>..........] - ETA: 1s - loss: 2.5335e-07330/450 [=====================>........] - ETA: 0s - loss: 2.5316e-07360/450 [=======================>......] - ETA: 0s - loss: 2.5297e-07390/450 [=========================>....] - ETA: 0s - loss: 2.5277e-07420/450 [===========================>..] - ETA: 0s - loss: 2.5258e-07450/450 [==============================] - 3s - loss: 2.5239e-07 - val_loss: 2.4933e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.4932e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.4913e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.4894e-07120/450 [=======>......................] - ETA: 2s - loss: 2.4875e-07150/450 [=========>....................] - ETA: 2s - loss: 2.4856e-07180/450 [===========>..................] - ETA: 2s - loss: 2.4837e-07210/450 [=============>................] - ETA: 1s - loss: 2.4819e-07240/450 [===============>..............] - ETA: 1s - loss: 2.4800e-07270/450 [=================>............] - ETA: 1s - loss: 2.4781e-07300/450 [===================>..........] - ETA: 1s - loss: 2.4762e-07330/450 [=====================>........] - ETA: 0s - loss: 2.4743e-07360/450 [=======================>......] - ETA: 0s - loss: 2.4724e-07390/450 [=========================>....] - ETA: 0s - loss: 2.4705e-07420/450 [===========================>..] - ETA: 0s - loss: 2.4687e-07450/450 [==============================] - 3s - loss: 2.4668e-07 - val_loss: 2.4369e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.4369e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.4351e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.4332e-07120/450 [=======>......................] - ETA: 2s - loss: 2.4314e-07150/450 [=========>....................] - ETA: 2s - loss: 2.4295e-07180/450 [===========>..................] - ETA: 2s - loss: 2.4277e-07210/450 [=============>................] - ETA: 1s - loss: 2.4259e-07240/450 [===============>..............] - ETA: 1s - loss: 2.4240e-07270/450 [=================>............] - ETA: 1s - loss: 2.4222e-07300/450 [===================>..........] - ETA: 1s - loss: 2.4204e-07330/450 [=====================>........] - ETA: 0s - loss: 2.4186e-07360/450 [=======================>......] - ETA: 0s - loss: 2.4167e-07390/450 [=========================>....] - ETA: 0s - loss: 2.4149e-07420/450 [===========================>..] - ETA: 0s - loss: 2.4131e-07450/450 [==============================] - 3s - loss: 2.4113e-07 - val_loss: 2.3821e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.3821e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.3803e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.3785e-07120/450 [=======>......................] - ETA: 2s - loss: 2.3767e-07150/450 [=========>....................] - ETA: 2s - loss: 2.3749e-07180/450 [===========>..................] - ETA: 2s - loss: 2.3731e-07210/450 [=============>................] - ETA: 1s - loss: 2.3713e-07240/450 [===============>..............] - ETA: 1s - loss: 2.3695e-07270/450 [=================>............] - ETA: 1s - loss: 2.3678e-07300/450 [===================>..........] - ETA: 1s - loss: 2.3660e-07330/450 [=====================>........] - ETA: 0s - loss: 2.3642e-07360/450 [=======================>......] - ETA: 0s - loss: 2.3624e-07390/450 [=========================>....] - ETA: 0s - loss: 2.3607e-07420/450 [===========================>..] - ETA: 0s - loss: 2.3589e-07450/450 [==============================] - 3s - loss: 2.3571e-07 - val_loss: 2.3290e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.3290e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.3272e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.3254e-07120/450 [=======>......................] - ETA: 2s - loss: 2.3237e-07150/450 [=========>....................] - ETA: 2s - loss: 2.3220e-07180/450 [===========>..................] - ETA: 2s - loss: 2.3202e-07210/450 [=============>................] - ETA: 1s - loss: 2.3185e-07240/450 [===============>..............] - ETA: 1s - loss: 2.3168e-07270/450 [=================>............] - ETA: 1s - loss: 2.3151e-07300/450 [===================>..........] - ETA: 1s - loss: 2.3133e-07330/450 [=====================>........] - ETA: 0s - loss: 2.3116e-07360/450 [=======================>......] - ETA: 0s - loss: 2.3099e-07390/450 [=========================>....] - ETA: 0s - loss: 2.3082e-07420/450 [===========================>..] - ETA: 0s - loss: 2.3064e-07450/450 [==============================] - 3s - loss: 2.3047e-07 - val_loss: 2.2772e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2773e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.2756e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.2739e-07120/450 [=======>......................] - ETA: 2s - loss: 2.2722e-07150/450 [=========>....................] - ETA: 2s - loss: 2.2705e-07180/450 [===========>..................] - ETA: 2s - loss: 2.2688e-07210/450 [=============>................] - ETA: 1s - loss: 2.2672e-07240/450 [===============>..............] - ETA: 1s - loss: 2.2655e-07270/450 [=================>............] - ETA: 1s - loss: 2.2638e-07300/450 [===================>..........] - ETA: 1s - loss: 2.2621e-07330/450 [=====================>........] - ETA: 0s - loss: 2.2604e-07360/450 [=======================>......] - ETA: 0s - loss: 2.2588e-07390/450 [=========================>....] - ETA: 0s - loss: 2.2571e-07420/450 [===========================>..] - ETA: 0s - loss: 2.2554e-07450/450 [==============================] - 3s - loss: 2.2537e-07 - val_loss: 2.2272e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2269e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.2254e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.2238e-07120/450 [=======>......................] - ETA: 2s - loss: 2.2222e-07150/450 [=========>....................] - ETA: 2s - loss: 2.2206e-07180/450 [===========>..................] - ETA: 2s - loss: 2.2189e-07210/450 [=============>................] - ETA: 1s - loss: 2.2173e-07240/450 [===============>..............] - ETA: 1s - loss: 2.2157e-07270/450 [=================>............] - ETA: 1s - loss: 2.2140e-07300/450 [===================>..........] - ETA: 1s - loss: 2.2124e-07330/450 [=====================>........] - ETA: 0s - loss: 2.2108e-07360/450 [=======================>......] - ETA: 0s - loss: 2.2091e-07390/450 [=========================>....] - ETA: 0s - loss: 2.2075e-07420/450 [===========================>..] - ETA: 0s - loss: 2.2059e-07450/450 [==============================] - 3s - loss: 2.2043e-07 - val_loss: 2.1783e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.1783e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.1767e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.1751e-07120/450 [=======>......................] - ETA: 2s - loss: 2.1735e-07150/450 [=========>....................] - ETA: 2s - loss: 2.1719e-07180/450 [===========>..................] - ETA: 2s - loss: 2.1703e-07210/450 [=============>................] - ETA: 1s - loss: 2.1687e-07240/450 [===============>..............] - ETA: 1s - loss: 2.1671e-07270/450 [=================>............] - ETA: 1s - loss: 2.1655e-07300/450 [===================>..........] - ETA: 1s - loss: 2.1640e-07330/450 [=====================>........] - ETA: 0s - loss: 2.1624e-07360/450 [=======================>......] - ETA: 0s - loss: 2.1608e-07390/450 [=========================>....] - ETA: 0s - loss: 2.1592e-07420/450 [===========================>..] - ETA: 0s - loss: 2.1576e-07450/450 [==============================] - 3s - loss: 2.1560e-07 - val_loss: 2.1309e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.1310e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.1294e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.1278e-07120/450 [=======>......................] - ETA: 2s - loss: 2.1262e-07150/450 [=========>....................] - ETA: 2s - loss: 2.1246e-07180/450 [===========>..................] - ETA: 2s - loss: 2.1231e-07210/450 [=============>................] - ETA: 1s - loss: 2.1215e-07240/450 [===============>..............] - ETA: 1s - loss: 2.1200e-07270/450 [=================>............] - ETA: 1s - loss: 2.1184e-07300/450 [===================>..........] - ETA: 1s - loss: 2.1169e-07330/450 [=====================>........] - ETA: 0s - loss: 2.1153e-07360/450 [=======================>......] - ETA: 0s - loss: 2.1138e-07390/450 [=========================>....] - ETA: 0s - loss: 2.1123e-07420/450 [===========================>..] - ETA: 0s - loss: 2.1107e-07450/450 [==============================] - 3s - loss: 2.1092e-07 - val_loss: 2.0846e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0845e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.0830e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.0815e-07120/450 [=======>......................] - ETA: 2s - loss: 2.0800e-07150/450 [=========>....................] - ETA: 2s - loss: 2.0785e-07180/450 [===========>..................] - ETA: 2s - loss: 2.0770e-07210/450 [=============>................] - ETA: 1s - loss: 2.0755e-07240/450 [===============>..............] - ETA: 1s - loss: 2.0740e-07270/450 [=================>............] - ETA: 1s - loss: 2.0725e-07300/450 [===================>..........] - ETA: 1s - loss: 2.0712e-07330/450 [=====================>........] - ETA: 0s - loss: 2.0697e-07360/450 [=======================>......] - ETA: 0s - loss: 2.0681e-07390/450 [=========================>....] - ETA: 0s - loss: 2.0666e-07420/450 [===========================>..] - ETA: 0s - loss: 2.0651e-07450/450 [==============================] - 3s - loss: 2.0636e-07 - val_loss: 2.0397e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0398e-07 60/450 [===>..........................] - ETA: 3s - loss: 2.0383e-07 90/450 [=====>........................] - ETA: 2s - loss: 2.0368e-07120/450 [=======>......................] - ETA: 2s - loss: 2.0353e-07150/450 [=========>....................] - ETA: 2s - loss: 2.0338e-07180/450 [===========>..................] - ETA: 2s - loss: 2.0324e-07210/450 [=============>................] - ETA: 1s - loss: 2.0309e-07240/450 [===============>..............] - ETA: 1s - loss: 2.0294e-07270/450 [=================>............] - ETA: 1s - loss: 2.0280e-07300/450 [===================>..........] - ETA: 1s - loss: 2.0265e-07330/450 [=====================>........] - ETA: 0s - loss: 2.0251e-07360/450 [=======================>......] - ETA: 0s - loss: 2.0237e-07390/450 [=========================>....] - ETA: 0s - loss: 2.0222e-07420/450 [===========================>..] - ETA: 0s - loss: 2.0208e-07450/450 [==============================] - 3s - loss: 2.0193e-07 - val_loss: 1.9961e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9961e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.9946e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.9932e-07120/450 [=======>......................] - ETA: 2s - loss: 1.9917e-07150/450 [=========>....................] - ETA: 2s - loss: 1.9903e-07180/450 [===========>..................] - ETA: 2s - loss: 1.9889e-07210/450 [=============>................] - ETA: 1s - loss: 1.9874e-07240/450 [===============>..............] - ETA: 1s - loss: 1.9860e-07270/450 [=================>............] - ETA: 1s - loss: 1.9846e-07300/450 [===================>..........] - ETA: 1s - loss: 1.9832e-07330/450 [=====================>........] - ETA: 0s - loss: 1.9818e-07360/450 [=======================>......] - ETA: 0s - loss: 1.9803e-07390/450 [=========================>....] - ETA: 0s - loss: 1.9789e-07420/450 [===========================>..] - ETA: 0s - loss: 1.9775e-07450/450 [==============================] - 3s - loss: 1.9761e-07 - val_loss: 1.9534e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9535e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.9521e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.9507e-07120/450 [=======>......................] - ETA: 2s - loss: 1.9493e-07150/450 [=========>....................] - ETA: 2s - loss: 1.9479e-07180/450 [===========>..................] - ETA: 2s - loss: 1.9465e-07210/450 [=============>................] - ETA: 1s - loss: 1.9451e-07240/450 [===============>..............] - ETA: 1s - loss: 1.9437e-07270/450 [=================>............] - ETA: 1s - loss: 1.9423e-07300/450 [===================>..........] - ETA: 1s - loss: 1.9409e-07330/450 [=====================>........] - ETA: 0s - loss: 1.9396e-07360/450 [=======================>......] - ETA: 0s - loss: 1.9382e-07390/450 [=========================>....] - ETA: 0s - loss: 1.9368e-07420/450 [===========================>..] - ETA: 0s - loss: 1.9354e-07450/450 [==============================] - 3s - loss: 1.9340e-07 - val_loss: 1.9121e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9122e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.9108e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.9094e-07120/450 [=======>......................] - ETA: 2s - loss: 1.9081e-07150/450 [=========>....................] - ETA: 2s - loss: 1.9067e-07180/450 [===========>..................] - ETA: 2s - loss: 1.9053e-07210/450 [=============>................] - ETA: 1s - loss: 1.9040e-07240/450 [===============>..............] - ETA: 1s - loss: 1.9026e-07270/450 [=================>............] - ETA: 1s - loss: 1.9013e-07300/450 [===================>..........] - ETA: 1s - loss: 1.9000e-07330/450 [=====================>........] - ETA: 0s - loss: 1.8986e-07360/450 [=======================>......] - ETA: 0s - loss: 1.8973e-07390/450 [=========================>....] - ETA: 0s - loss: 1.8959e-07420/450 [===========================>..] - ETA: 0s - loss: 1.8946e-07450/450 [==============================] - 3s - loss: 1.8932e-07 - val_loss: 1.8718e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8719e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.8706e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.8693e-07120/450 [=======>......................] - ETA: 2s - loss: 1.8680e-07150/450 [=========>....................] - ETA: 2s - loss: 1.8666e-07180/450 [===========>..................] - ETA: 2s - loss: 1.8653e-07210/450 [=============>................] - ETA: 1s - loss: 1.8640e-07240/450 [===============>..............] - ETA: 1s - loss: 1.8627e-07270/450 [=================>............] - ETA: 1s - loss: 1.8614e-07300/450 [===================>..........] - ETA: 1s - loss: 1.8601e-07330/450 [=====================>........] - ETA: 0s - loss: 1.8588e-07360/450 [=======================>......] - ETA: 0s - loss: 1.8574e-07390/450 [=========================>....] - ETA: 0s - loss: 1.8561e-07420/450 [===========================>..] - ETA: 0s - loss: 1.8548e-07450/450 [==============================] - 3s - loss: 1.8535e-07 - val_loss: 1.8328e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8325e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.8312e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.8299e-07120/450 [=======>......................] - ETA: 2s - loss: 1.8286e-07150/450 [=========>....................] - ETA: 2s - loss: 1.8273e-07180/450 [===========>..................] - ETA: 2s - loss: 1.8260e-07210/450 [=============>................] - ETA: 1s - loss: 1.8248e-07240/450 [===============>..............] - ETA: 1s - loss: 1.8235e-07270/450 [=================>............] - ETA: 1s - loss: 1.8222e-07300/450 [===================>..........] - ETA: 1s - loss: 1.8209e-07330/450 [=====================>........] - ETA: 0s - loss: 1.8196e-07360/450 [=======================>......] - ETA: 0s - loss: 1.8184e-07390/450 [=========================>....] - ETA: 0s - loss: 1.8171e-07420/450 [===========================>..] - ETA: 0s - loss: 1.8158e-07450/450 [==============================] - 3s - loss: 1.8145e-07 - val_loss: 1.7943e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7943e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.7931e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.7918e-07120/450 [=======>......................] - ETA: 2s - loss: 1.7906e-07150/450 [=========>....................] - ETA: 2s - loss: 1.7893e-07180/450 [===========>..................] - ETA: 2s - loss: 1.7880e-07210/450 [=============>................] - ETA: 1s - loss: 1.7868e-07240/450 [===============>..............] - ETA: 1s - loss: 1.7856e-07270/450 [=================>............] - ETA: 1s - loss: 1.7843e-07300/450 [===================>..........] - ETA: 1s - loss: 1.7831e-07330/450 [=====================>........] - ETA: 0s - loss: 1.7818e-07360/450 [=======================>......] - ETA: 0s - loss: 1.7806e-07390/450 [=========================>....] - ETA: 0s - loss: 1.7793e-07420/450 [===========================>..] - ETA: 0s - loss: 1.7781e-07450/450 [==============================] - 3s - loss: 1.7769e-07 - val_loss: 1.7573e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7571e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.7558e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.7546e-07120/450 [=======>......................] - ETA: 2s - loss: 1.7534e-07150/450 [=========>....................] - ETA: 2s - loss: 1.7522e-07180/450 [===========>..................] - ETA: 2s - loss: 1.7510e-07210/450 [=============>................] - ETA: 1s - loss: 1.7499e-07240/450 [===============>..............] - ETA: 1s - loss: 1.7487e-07270/450 [=================>............] - ETA: 1s - loss: 1.7474e-07300/450 [===================>..........] - ETA: 1s - loss: 1.7462e-07330/450 [=====================>........] - ETA: 0s - loss: 1.7450e-07360/450 [=======================>......] - ETA: 0s - loss: 1.7438e-07390/450 [=========================>....] - ETA: 0s - loss: 1.7426e-07420/450 [===========================>..] - ETA: 0s - loss: 1.7414e-07450/450 [==============================] - 3s - loss: 1.7402e-07 - val_loss: 1.7208e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7207e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.7196e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.7184e-07120/450 [=======>......................] - ETA: 2s - loss: 1.7172e-07150/450 [=========>....................] - ETA: 2s - loss: 1.7161e-07180/450 [===========>..................] - ETA: 2s - loss: 1.7149e-07210/450 [=============>................] - ETA: 1s - loss: 1.7137e-07240/450 [===============>..............] - ETA: 1s - loss: 1.7125e-07270/450 [=================>............] - ETA: 1s - loss: 1.7113e-07300/450 [===================>..........] - ETA: 1s - loss: 1.7102e-07330/450 [=====================>........] - ETA: 0s - loss: 1.7090e-07360/450 [=======================>......] - ETA: 0s - loss: 1.7078e-07390/450 [=========================>....] - ETA: 0s - loss: 1.7066e-07420/450 [===========================>..] - ETA: 0s - loss: 1.7054e-07450/450 [==============================] - 3s - loss: 1.7043e-07 - val_loss: 1.6854e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6855e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.6843e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.6832e-07120/450 [=======>......................] - ETA: 2s - loss: 1.6820e-07150/450 [=========>....................] - ETA: 2s - loss: 1.6808e-07180/450 [===========>..................] - ETA: 2s - loss: 1.6797e-07210/450 [=============>................] - ETA: 1s - loss: 1.6785e-07240/450 [===============>..............] - ETA: 1s - loss: 1.6774e-07270/450 [=================>............] - ETA: 1s - loss: 1.6762e-07300/450 [===================>..........] - ETA: 1s - loss: 1.6750e-07330/450 [=====================>........] - ETA: 0s - loss: 1.6739e-07360/450 [=======================>......] - ETA: 0s - loss: 1.6727e-07390/450 [=========================>....] - ETA: 0s - loss: 1.6716e-07420/450 [===========================>..] - ETA: 0s - loss: 1.6705e-07450/450 [==============================] - 3s - loss: 1.6693e-07 - val_loss: 1.6510e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6510e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.6499e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.6488e-07120/450 [=======>......................] - ETA: 2s - loss: 1.6477e-07150/450 [=========>....................] - ETA: 2s - loss: 1.6466e-07180/450 [===========>..................] - ETA: 2s - loss: 1.6455e-07210/450 [=============>................] - ETA: 1s - loss: 1.6443e-07240/450 [===============>..............] - ETA: 1s - loss: 1.6432e-07270/450 [=================>............] - ETA: 1s - loss: 1.6421e-07300/450 [===================>..........] - ETA: 1s - loss: 1.6410e-07330/450 [=====================>........] - ETA: 0s - loss: 1.6399e-07360/450 [=======================>......] - ETA: 0s - loss: 1.6387e-07390/450 [=========================>....] - ETA: 0s - loss: 1.6376e-07420/450 [===========================>..] - ETA: 0s - loss: 1.6365e-07450/450 [==============================] - 3s - loss: 1.6354e-07 - val_loss: 1.6176e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6175e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.6164e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.6153e-07120/450 [=======>......................] - ETA: 2s - loss: 1.6142e-07150/450 [=========>....................] - ETA: 2s - loss: 1.6131e-07180/450 [===========>..................] - ETA: 2s - loss: 1.6120e-07210/450 [=============>................] - ETA: 1s - loss: 1.6109e-07240/450 [===============>..............] - ETA: 1s - loss: 1.6098e-07270/450 [=================>............] - ETA: 1s - loss: 1.6087e-07300/450 [===================>..........] - ETA: 1s - loss: 1.6076e-07330/450 [=====================>........] - ETA: 0s - loss: 1.6065e-07360/450 [=======================>......] - ETA: 0s - loss: 1.6055e-07390/450 [=========================>....] - ETA: 0s - loss: 1.6044e-07420/450 [===========================>..] - ETA: 0s - loss: 1.6033e-07450/450 [==============================] - 3s - loss: 1.6022e-07 - val_loss: 1.5848e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5849e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.5837e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.5827e-07120/450 [=======>......................] - ETA: 2s - loss: 1.5816e-07150/450 [=========>....................] - ETA: 2s - loss: 1.5805e-07180/450 [===========>..................] - ETA: 2s - loss: 1.5794e-07210/450 [=============>................] - ETA: 1s - loss: 1.5784e-07240/450 [===============>..............] - ETA: 1s - loss: 1.5773e-07270/450 [=================>............] - ETA: 1s - loss: 1.5762e-07300/450 [===================>..........] - ETA: 1s - loss: 1.5751e-07330/450 [=====================>........] - ETA: 0s - loss: 1.5741e-07360/450 [=======================>......] - ETA: 0s - loss: 1.5730e-07390/450 [=========================>....] - ETA: 0s - loss: 1.5720e-07420/450 [===========================>..] - ETA: 0s - loss: 1.5709e-07450/450 [==============================] - 3s - loss: 1.5698e-07 - val_loss: 1.5530e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5531e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.5519e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.5509e-07120/450 [=======>......................] - ETA: 2s - loss: 1.5498e-07150/450 [=========>....................] - ETA: 2s - loss: 1.5488e-07180/450 [===========>..................] - ETA: 2s - loss: 1.5478e-07210/450 [=============>................] - ETA: 1s - loss: 1.5467e-07240/450 [===============>..............] - ETA: 1s - loss: 1.5457e-07270/450 [=================>............] - ETA: 1s - loss: 1.5447e-07300/450 [===================>..........] - ETA: 1s - loss: 1.5436e-07330/450 [=====================>........] - ETA: 0s - loss: 1.5426e-07360/450 [=======================>......] - ETA: 0s - loss: 1.5416e-07390/450 [=========================>....] - ETA: 0s - loss: 1.5405e-07420/450 [===========================>..] - ETA: 0s - loss: 1.5395e-07450/450 [==============================] - 3s - loss: 1.5385e-07 - val_loss: 1.5220e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5220e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.5209e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.5199e-07120/450 [=======>......................] - ETA: 2s - loss: 1.5189e-07150/450 [=========>....................] - ETA: 2s - loss: 1.5179e-07180/450 [===========>..................] - ETA: 2s - loss: 1.5168e-07210/450 [=============>................] - ETA: 1s - loss: 1.5158e-07240/450 [===============>..............] - ETA: 1s - loss: 1.5148e-07270/450 [=================>............] - ETA: 1s - loss: 1.5138e-07300/450 [===================>..........] - ETA: 1s - loss: 1.5128e-07330/450 [=====================>........] - ETA: 0s - loss: 1.5118e-07360/450 [=======================>......] - ETA: 0s - loss: 1.5108e-07390/450 [=========================>....] - ETA: 0s - loss: 1.5098e-07420/450 [===========================>..] - ETA: 0s - loss: 1.5088e-07450/450 [==============================] - 3s - loss: 1.5078e-07 - val_loss: 1.4915e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4917e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.4907e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.4897e-07120/450 [=======>......................] - ETA: 2s - loss: 1.4886e-07150/450 [=========>....................] - ETA: 2s - loss: 1.4877e-07180/450 [===========>..................] - ETA: 2s - loss: 1.4867e-07210/450 [=============>................] - ETA: 1s - loss: 1.4857e-07240/450 [===============>..............] - ETA: 1s - loss: 1.4847e-07270/450 [=================>............] - ETA: 1s - loss: 1.4837e-07300/450 [===================>..........] - ETA: 1s - loss: 1.4827e-07330/450 [=====================>........] - ETA: 0s - loss: 1.4817e-07360/450 [=======================>......] - ETA: 0s - loss: 1.4808e-07390/450 [=========================>....] - ETA: 0s - loss: 1.4798e-07420/450 [===========================>..] - ETA: 0s - loss: 1.4788e-07450/450 [==============================] - 3s - loss: 1.4778e-07 - val_loss: 1.4622e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4621e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.4611e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.4602e-07120/450 [=======>......................] - ETA: 2s - loss: 1.4592e-07150/450 [=========>....................] - ETA: 2s - loss: 1.4583e-07180/450 [===========>..................] - ETA: 2s - loss: 1.4573e-07210/450 [=============>................] - ETA: 1s - loss: 1.4563e-07240/450 [===============>..............] - ETA: 1s - loss: 1.4553e-07270/450 [=================>............] - ETA: 1s - loss: 1.4544e-07300/450 [===================>..........] - ETA: 1s - loss: 1.4534e-07330/450 [=====================>........] - ETA: 0s - loss: 1.4524e-07360/450 [=======================>......] - ETA: 0s - loss: 1.4515e-07390/450 [=========================>....] - ETA: 0s - loss: 1.4505e-07420/450 [===========================>..] - ETA: 0s - loss: 1.4496e-07450/450 [==============================] - 3s - loss: 1.4486e-07 - val_loss: 1.4331e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4331e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.4322e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.4312e-07120/450 [=======>......................] - ETA: 2s - loss: 1.4302e-07150/450 [=========>....................] - ETA: 2s - loss: 1.4293e-07180/450 [===========>..................] - ETA: 2s - loss: 1.4283e-07210/450 [=============>................] - ETA: 1s - loss: 1.4274e-07240/450 [===============>..............] - ETA: 1s - loss: 1.4264e-07270/450 [=================>............] - ETA: 1s - loss: 1.4255e-07300/450 [===================>..........] - ETA: 1s - loss: 1.4246e-07330/450 [=====================>........] - ETA: 0s - loss: 1.4236e-07360/450 [=======================>......] - ETA: 0s - loss: 1.4227e-07390/450 [=========================>....] - ETA: 0s - loss: 1.4218e-07420/450 [===========================>..] - ETA: 0s - loss: 1.4208e-07450/450 [==============================] - 3s - loss: 1.4199e-07 - val_loss: 1.4049e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4050e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.4040e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.4031e-07120/450 [=======>......................] - ETA: 2s - loss: 1.4022e-07150/450 [=========>....................] - ETA: 2s - loss: 1.4013e-07180/450 [===========>..................] - ETA: 2s - loss: 1.4004e-07210/450 [=============>................] - ETA: 1s - loss: 1.3994e-07240/450 [===============>..............] - ETA: 1s - loss: 1.3985e-07270/450 [=================>............] - ETA: 1s - loss: 1.3976e-07300/450 [===================>..........] - ETA: 1s - loss: 1.3967e-07330/450 [=====================>........] - ETA: 0s - loss: 1.3958e-07360/450 [=======================>......] - ETA: 0s - loss: 1.3948e-07390/450 [=========================>....] - ETA: 0s - loss: 1.3939e-07420/450 [===========================>..] - ETA: 0s - loss: 1.3930e-07450/450 [==============================] - 3s - loss: 1.3921e-07 - val_loss: 1.3775e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3776e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.3767e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.3758e-07120/450 [=======>......................] - ETA: 2s - loss: 1.3749e-07150/450 [=========>....................] - ETA: 2s - loss: 1.3740e-07180/450 [===========>..................] - ETA: 2s - loss: 1.3731e-07210/450 [=============>................] - ETA: 1s - loss: 1.3722e-07240/450 [===============>..............] - ETA: 1s - loss: 1.3713e-07270/450 [=================>............] - ETA: 1s - loss: 1.3704e-07300/450 [===================>..........] - ETA: 1s - loss: 1.3695e-07330/450 [=====================>........] - ETA: 0s - loss: 1.3686e-07360/450 [=======================>......] - ETA: 0s - loss: 1.3678e-07390/450 [=========================>....] - ETA: 0s - loss: 1.3669e-07420/450 [===========================>..] - ETA: 0s - loss: 1.3660e-07450/450 [==============================] - 3s - loss: 1.3651e-07 - val_loss: 1.3508e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3509e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.3500e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.3491e-07120/450 [=======>......................] - ETA: 2s - loss: 1.3482e-07150/450 [=========>....................] - ETA: 2s - loss: 1.3473e-07180/450 [===========>..................] - ETA: 2s - loss: 1.3464e-07210/450 [=============>................] - ETA: 1s - loss: 1.3456e-07240/450 [===============>..............] - ETA: 1s - loss: 1.3447e-07270/450 [=================>............] - ETA: 1s - loss: 1.3438e-07300/450 [===================>..........] - ETA: 1s - loss: 1.3430e-07330/450 [=====================>........] - ETA: 0s - loss: 1.3421e-07360/450 [=======================>......] - ETA: 0s - loss: 1.3412e-07390/450 [=========================>....] - ETA: 0s - loss: 1.3403e-07420/450 [===========================>..] - ETA: 0s - loss: 1.3395e-07450/450 [==============================] - 3s - loss: 1.3386e-07 - val_loss: 1.3247e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3246e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.3238e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.3229e-07120/450 [=======>......................] - ETA: 2s - loss: 1.3221e-07150/450 [=========>....................] - ETA: 2s - loss: 1.3213e-07180/450 [===========>..................] - ETA: 2s - loss: 1.3204e-07210/450 [=============>................] - ETA: 1s - loss: 1.3195e-07240/450 [===============>..............] - ETA: 1s - loss: 1.3187e-07270/450 [=================>............] - ETA: 1s - loss: 1.3178e-07300/450 [===================>..........] - ETA: 1s - loss: 1.3170e-07330/450 [=====================>........] - ETA: 0s - loss: 1.3161e-07360/450 [=======================>......] - ETA: 0s - loss: 1.3153e-07390/450 [=========================>....] - ETA: 0s - loss: 1.3144e-07420/450 [===========================>..] - ETA: 0s - loss: 1.3136e-07450/450 [==============================] - 3s - loss: 1.3127e-07 - val_loss: 1.2992e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2992e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.2983e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.2975e-07120/450 [=======>......................] - ETA: 2s - loss: 1.2967e-07150/450 [=========>....................] - ETA: 2s - loss: 1.2958e-07180/450 [===========>..................] - ETA: 2s - loss: 1.2950e-07210/450 [=============>................] - ETA: 1s - loss: 1.2941e-07240/450 [===============>..............] - ETA: 1s - loss: 1.2933e-07270/450 [=================>............] - ETA: 1s - loss: 1.2925e-07300/450 [===================>..........] - ETA: 1s - loss: 1.2916e-07330/450 [=====================>........] - ETA: 0s - loss: 1.2908e-07360/450 [=======================>......] - ETA: 0s - loss: 1.2900e-07390/450 [=========================>....] - ETA: 0s - loss: 1.2891e-07420/450 [===========================>..] - ETA: 0s - loss: 1.2883e-07450/450 [==============================] - 3s - loss: 1.2875e-07 - val_loss: 1.2742e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2744e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.2735e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.2727e-07120/450 [=======>......................] - ETA: 2s - loss: 1.2718e-07150/450 [=========>....................] - ETA: 2s - loss: 1.2710e-07180/450 [===========>..................] - ETA: 2s - loss: 1.2702e-07210/450 [=============>................] - ETA: 1s - loss: 1.2694e-07240/450 [===============>..............] - ETA: 1s - loss: 1.2685e-07270/450 [=================>............] - ETA: 1s - loss: 1.2677e-07300/450 [===================>..........] - ETA: 1s - loss: 1.2669e-07330/450 [=====================>........] - ETA: 0s - loss: 1.2661e-07360/450 [=======================>......] - ETA: 0s - loss: 1.2653e-07390/450 [=========================>....] - ETA: 0s - loss: 1.2645e-07420/450 [===========================>..] - ETA: 0s - loss: 1.2637e-07450/450 [==============================] - 3s - loss: 1.2629e-07 - val_loss: 1.2501e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2500e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.2492e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.2484e-07120/450 [=======>......................] - ETA: 2s - loss: 1.2476e-07150/450 [=========>....................] - ETA: 2s - loss: 1.2468e-07180/450 [===========>..................] - ETA: 2s - loss: 1.2460e-07210/450 [=============>................] - ETA: 1s - loss: 1.2452e-07240/450 [===============>..............] - ETA: 1s - loss: 1.2444e-07270/450 [=================>............] - ETA: 1s - loss: 1.2436e-07300/450 [===================>..........] - ETA: 1s - loss: 1.2428e-07330/450 [=====================>........] - ETA: 0s - loss: 1.2420e-07360/450 [=======================>......] - ETA: 0s - loss: 1.2412e-07390/450 [=========================>....] - ETA: 0s - loss: 1.2405e-07420/450 [===========================>..] - ETA: 0s - loss: 1.2397e-07450/450 [==============================] - 3s - loss: 1.2389e-07 - val_loss: 1.2262e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2262e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.2255e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.2247e-07120/450 [=======>......................] - ETA: 2s - loss: 1.2239e-07150/450 [=========>....................] - ETA: 2s - loss: 1.2231e-07180/450 [===========>..................] - ETA: 2s - loss: 1.2223e-07210/450 [=============>................] - ETA: 1s - loss: 1.2216e-07240/450 [===============>..............] - ETA: 1s - loss: 1.2208e-07270/450 [=================>............] - ETA: 1s - loss: 1.2200e-07300/450 [===================>..........] - ETA: 1s - loss: 1.2192e-07330/450 [=====================>........] - ETA: 0s - loss: 1.2185e-07360/450 [=======================>......] - ETA: 0s - loss: 1.2177e-07390/450 [=========================>....] - ETA: 0s - loss: 1.2169e-07420/450 [===========================>..] - ETA: 0s - loss: 1.2161e-07450/450 [==============================] - 3s - loss: 1.2154e-07 - val_loss: 1.2030e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2030e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.2023e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.2015e-07120/450 [=======>......................] - ETA: 2s - loss: 1.2007e-07150/450 [=========>....................] - ETA: 2s - loss: 1.2000e-07180/450 [===========>..................] - ETA: 2s - loss: 1.1992e-07210/450 [=============>................] - ETA: 1s - loss: 1.1985e-07240/450 [===============>..............] - ETA: 1s - loss: 1.1977e-07270/450 [=================>............] - ETA: 1s - loss: 1.1969e-07300/450 [===================>..........] - ETA: 1s - loss: 1.1962e-07330/450 [=====================>........] - ETA: 0s - loss: 1.1954e-07360/450 [=======================>......] - ETA: 0s - loss: 1.1947e-07390/450 [=========================>....] - ETA: 0s - loss: 1.1939e-07420/450 [===========================>..] - ETA: 0s - loss: 1.1932e-07450/450 [==============================] - 3s - loss: 1.1924e-07 - val_loss: 1.1805e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1807e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.1799e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.1791e-07120/450 [=======>......................] - ETA: 2s - loss: 1.1784e-07150/450 [=========>....................] - ETA: 2s - loss: 1.1777e-07180/450 [===========>..................] - ETA: 2s - loss: 1.1769e-07210/450 [=============>................] - ETA: 1s - loss: 1.1762e-07240/450 [===============>..............] - ETA: 1s - loss: 1.1754e-07270/450 [=================>............] - ETA: 1s - loss: 1.1747e-07300/450 [===================>..........] - ETA: 1s - loss: 1.1740e-07330/450 [=====================>........] - ETA: 0s - loss: 1.1733e-07360/450 [=======================>......] - ETA: 0s - loss: 1.1725e-07390/450 [=========================>....] - ETA: 0s - loss: 1.1718e-07420/450 [===========================>..] - ETA: 0s - loss: 1.1710e-07450/450 [==============================] - 3s - loss: 1.1703e-07 - val_loss: 1.1587e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1586e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.1578e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.1571e-07120/450 [=======>......................] - ETA: 2s - loss: 1.1563e-07150/450 [=========>....................] - ETA: 2s - loss: 1.1556e-07180/450 [===========>..................] - ETA: 2s - loss: 1.1549e-07210/450 [=============>................] - ETA: 1s - loss: 1.1542e-07240/450 [===============>..............] - ETA: 1s - loss: 1.1535e-07270/450 [=================>............] - ETA: 1s - loss: 1.1527e-07300/450 [===================>..........] - ETA: 1s - loss: 1.1520e-07330/450 [=====================>........] - ETA: 0s - loss: 1.1513e-07360/450 [=======================>......] - ETA: 0s - loss: 1.1506e-07390/450 [=========================>....] - ETA: 0s - loss: 1.1499e-07420/450 [===========================>..] - ETA: 0s - loss: 1.1492e-07450/450 [==============================] - 3s - loss: 1.1484e-07 - val_loss: 1.1370e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1370e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.1363e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.1355e-07120/450 [=======>......................] - ETA: 2s - loss: 1.1349e-07150/450 [=========>....................] - ETA: 2s - loss: 1.1341e-07180/450 [===========>..................] - ETA: 2s - loss: 1.1334e-07210/450 [=============>................] - ETA: 1s - loss: 1.1327e-07240/450 [===============>..............] - ETA: 1s - loss: 1.1320e-07270/450 [=================>............] - ETA: 1s - loss: 1.1313e-07300/450 [===================>..........] - ETA: 1s - loss: 1.1306e-07330/450 [=====================>........] - ETA: 0s - loss: 1.1299e-07360/450 [=======================>......] - ETA: 0s - loss: 1.1292e-07390/450 [=========================>....] - ETA: 0s - loss: 1.1285e-07420/450 [===========================>..] - ETA: 0s - loss: 1.1277e-07450/450 [==============================] - 3s - loss: 1.1270e-07 - val_loss: 1.1157e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1157e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.1150e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.1144e-07120/450 [=======>......................] - ETA: 2s - loss: 1.1137e-07150/450 [=========>....................] - ETA: 2s - loss: 1.1130e-07180/450 [===========>..................] - ETA: 2s - loss: 1.1123e-07210/450 [=============>................] - ETA: 1s - loss: 1.1116e-07240/450 [===============>..............] - ETA: 1s - loss: 1.1109e-07270/450 [=================>............] - ETA: 1s - loss: 1.1102e-07300/450 [===================>..........] - ETA: 1s - loss: 1.1095e-07330/450 [=====================>........] - ETA: 0s - loss: 1.1088e-07360/450 [=======================>......] - ETA: 0s - loss: 1.1081e-07390/450 [=========================>....] - ETA: 0s - loss: 1.1074e-07420/450 [===========================>..] - ETA: 0s - loss: 1.1067e-07450/450 [==============================] - 3s - loss: 1.1061e-07 - val_loss: 1.0951e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0950e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.0943e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.0937e-07120/450 [=======>......................] - ETA: 2s - loss: 1.0930e-07150/450 [=========>....................] - ETA: 2s - loss: 1.0923e-07180/450 [===========>..................] - ETA: 2s - loss: 1.0917e-07210/450 [=============>................] - ETA: 1s - loss: 1.0910e-07240/450 [===============>..............] - ETA: 1s - loss: 1.0903e-07270/450 [=================>............] - ETA: 1s - loss: 1.0896e-07300/450 [===================>..........] - ETA: 1s - loss: 1.0890e-07330/450 [=====================>........] - ETA: 0s - loss: 1.0883e-07360/450 [=======================>......] - ETA: 0s - loss: 1.0876e-07390/450 [=========================>....] - ETA: 0s - loss: 1.0869e-07420/450 [===========================>..] - ETA: 0s - loss: 1.0863e-07450/450 [==============================] - 3s - loss: 1.0856e-07 - val_loss: 1.0749e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0748e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.0742e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.0736e-07120/450 [=======>......................] - ETA: 2s - loss: 1.0729e-07150/450 [=========>....................] - ETA: 2s - loss: 1.0723e-07180/450 [===========>..................] - ETA: 2s - loss: 1.0716e-07210/450 [=============>................] - ETA: 1s - loss: 1.0709e-07240/450 [===============>..............] - ETA: 1s - loss: 1.0703e-07270/450 [=================>............] - ETA: 1s - loss: 1.0696e-07300/450 [===================>..........] - ETA: 1s - loss: 1.0690e-07330/450 [=====================>........] - ETA: 0s - loss: 1.0683e-07360/450 [=======================>......] - ETA: 0s - loss: 1.0677e-07390/450 [=========================>....] - ETA: 0s - loss: 1.0670e-07420/450 [===========================>..] - ETA: 0s - loss: 1.0663e-07450/450 [==============================] - 3s - loss: 1.0657e-07 - val_loss: 1.0552e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0553e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.0546e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.0539e-07120/450 [=======>......................] - ETA: 2s - loss: 1.0533e-07150/450 [=========>....................] - ETA: 2s - loss: 1.0527e-07180/450 [===========>..................] - ETA: 2s - loss: 1.0520e-07210/450 [=============>................] - ETA: 1s - loss: 1.0514e-07240/450 [===============>..............] - ETA: 1s - loss: 1.0507e-07270/450 [=================>............] - ETA: 1s - loss: 1.0501e-07300/450 [===================>..........] - ETA: 1s - loss: 1.0494e-07330/450 [=====================>........] - ETA: 0s - loss: 1.0488e-07360/450 [=======================>......] - ETA: 0s - loss: 1.0482e-07390/450 [=========================>....] - ETA: 0s - loss: 1.0475e-07420/450 [===========================>..] - ETA: 0s - loss: 1.0469e-07450/450 [==============================] - 3s - loss: 1.0462e-07 - val_loss: 1.0360e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0360e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.0354e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.0348e-07120/450 [=======>......................] - ETA: 2s - loss: 1.0342e-07150/450 [=========>....................] - ETA: 2s - loss: 1.0336e-07180/450 [===========>..................] - ETA: 2s - loss: 1.0329e-07210/450 [=============>................] - ETA: 1s - loss: 1.0323e-07240/450 [===============>..............] - ETA: 1s - loss: 1.0317e-07270/450 [=================>............] - ETA: 1s - loss: 1.0310e-07300/450 [===================>..........] - ETA: 1s - loss: 1.0304e-07330/450 [=====================>........] - ETA: 0s - loss: 1.0298e-07360/450 [=======================>......] - ETA: 0s - loss: 1.0291e-07390/450 [=========================>....] - ETA: 0s - loss: 1.0285e-07420/450 [===========================>..] - ETA: 0s - loss: 1.0279e-07450/450 [==============================] - 3s - loss: 1.0273e-07 - val_loss: 1.0172e-07
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0172e-07 60/450 [===>..........................] - ETA: 3s - loss: 1.0166e-07 90/450 [=====>........................] - ETA: 2s - loss: 1.0160e-07120/450 [=======>......................] - ETA: 2s - loss: 1.0153e-07150/450 [=========>....................] - ETA: 2s - loss: 1.0147e-07180/450 [===========>..................] - ETA: 2s - loss: 1.0141e-07210/450 [=============>................] - ETA: 1s - loss: 1.0135e-07240/450 [===============>..............] - ETA: 1s - loss: 1.0129e-07270/450 [=================>............] - ETA: 1s - loss: 1.0123e-07300/450 [===================>..........] - ETA: 1s - loss: 1.0117e-07330/450 [=====================>........] - ETA: 0s - loss: 1.0111e-07360/450 [=======================>......] - ETA: 0s - loss: 1.0105e-07390/450 [=========================>....] - ETA: 0s - loss: 1.0099e-07420/450 [===========================>..] - ETA: 0s - loss: 1.0093e-07450/450 [==============================] - 3s - loss: 1.0087e-07 - val_loss: 9.9890e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.9882e-08 60/450 [===>..........................] - ETA: 3s - loss: 9.9820e-08 90/450 [=====>........................] - ETA: 2s - loss: 9.9761e-08120/450 [=======>......................] - ETA: 2s - loss: 9.9702e-08150/450 [=========>....................] - ETA: 2s - loss: 9.9642e-08180/450 [===========>..................] - ETA: 2s - loss: 9.9581e-08210/450 [=============>................] - ETA: 1s - loss: 9.9520e-08240/450 [===============>..............] - ETA: 1s - loss: 9.9460e-08270/450 [=================>............] - ETA: 1s - loss: 9.9400e-08300/450 [===================>..........] - ETA: 1s - loss: 9.9340e-08330/450 [=====================>........] - ETA: 0s - loss: 9.9280e-08360/450 [=======================>......] - ETA: 0s - loss: 9.9220e-08390/450 [=========================>....] - ETA: 0s - loss: 9.9160e-08420/450 [===========================>..] - ETA: 0s - loss: 9.9101e-08450/450 [==============================] - 3s - loss: 9.9041e-08 - val_loss: 9.8089e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.8094e-08 60/450 [===>..........................] - ETA: 3s - loss: 9.8032e-08 90/450 [=====>........................] - ETA: 2s - loss: 9.7972e-08120/450 [=======>......................] - ETA: 2s - loss: 9.7915e-08150/450 [=========>....................] - ETA: 2s - loss: 9.7856e-08180/450 [===========>..................] - ETA: 2s - loss: 9.7798e-08210/450 [=============>................] - ETA: 1s - loss: 9.7738e-08240/450 [===============>..............] - ETA: 1s - loss: 9.7679e-08270/450 [=================>............] - ETA: 1s - loss: 9.7620e-08300/450 [===================>..........] - ETA: 1s - loss: 9.7562e-08330/450 [=====================>........] - ETA: 0s - loss: 9.7503e-08360/450 [=======================>......] - ETA: 0s - loss: 9.7444e-08390/450 [=========================>....] - ETA: 0s - loss: 9.7385e-08420/450 [===========================>..] - ETA: 0s - loss: 9.7327e-08450/450 [==============================] - 3s - loss: 9.7268e-08 - val_loss: 9.6339e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.6329e-08 60/450 [===>..........................] - ETA: 3s - loss: 9.6273e-08 90/450 [=====>........................] - ETA: 2s - loss: 9.6215e-08120/450 [=======>......................] - ETA: 2s - loss: 9.6157e-08150/450 [=========>....................] - ETA: 2s - loss: 9.6099e-08180/450 [===========>..................] - ETA: 2s - loss: 9.6042e-08210/450 [=============>................] - ETA: 1s - loss: 9.5984e-08240/450 [===============>..............] - ETA: 1s - loss: 9.5926e-08270/450 [=================>............] - ETA: 1s - loss: 9.5869e-08300/450 [===================>..........] - ETA: 1s - loss: 9.5811e-08330/450 [=====================>........] - ETA: 0s - loss: 9.5754e-08360/450 [=======================>......] - ETA: 0s - loss: 9.5697e-08390/450 [=========================>....] - ETA: 0s - loss: 9.5640e-08420/450 [===========================>..] - ETA: 0s - loss: 9.5582e-08450/450 [==============================] - 3s - loss: 9.5526e-08 - val_loss: 9.4640e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.4637e-08 60/450 [===>..........................] - ETA: 3s - loss: 9.4586e-08 90/450 [=====>........................] - ETA: 2s - loss: 9.4531e-08120/450 [=======>......................] - ETA: 2s - loss: 9.4474e-08150/450 [=========>....................] - ETA: 2s - loss: 9.4416e-08180/450 [===========>..................] - ETA: 2s - loss: 9.4361e-08210/450 [=============>................] - ETA: 1s - loss: 9.4303e-08240/450 [===============>..............] - ETA: 1s - loss: 9.4249e-08270/450 [=================>............] - ETA: 1s - loss: 9.4193e-08300/450 [===================>..........] - ETA: 1s - loss: 9.4138e-08330/450 [=====================>........] - ETA: 0s - loss: 9.4083e-08360/450 [=======================>......] - ETA: 0s - loss: 9.4028e-08390/450 [=========================>....] - ETA: 0s - loss: 9.3972e-08420/450 [===========================>..] - ETA: 0s - loss: 9.3916e-08450/450 [==============================] - 3s - loss: 9.3860e-08 - val_loss: 9.2938e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.2940e-08 60/450 [===>..........................] - ETA: 3s - loss: 9.2882e-08 90/450 [=====>........................] - ETA: 2s - loss: 9.2828e-08120/450 [=======>......................] - ETA: 2s - loss: 9.2775e-08150/450 [=========>....................] - ETA: 2s - loss: 9.2720e-08180/450 [===========>..................] - ETA: 2s - loss: 9.2664e-08210/450 [=============>................] - ETA: 1s - loss: 9.2609e-08240/450 [===============>..............] - ETA: 1s - loss: 9.2553e-08270/450 [=================>............] - ETA: 1s - loss: 9.2498e-08300/450 [===================>..........] - ETA: 1s - loss: 9.2443e-08330/450 [=====================>........] - ETA: 0s - loss: 9.2388e-08360/450 [=======================>......] - ETA: 0s - loss: 9.2333e-08390/450 [=========================>....] - ETA: 0s - loss: 9.2278e-08420/450 [===========================>..] - ETA: 0s - loss: 9.2223e-08450/450 [==============================] - 3s - loss: 9.2168e-08 - val_loss: 9.1287e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.1288e-08 60/450 [===>..........................] - ETA: 3s - loss: 9.1236e-08 90/450 [=====>........................] - ETA: 2s - loss: 9.1181e-08120/450 [=======>......................] - ETA: 2s - loss: 9.1126e-08150/450 [=========>....................] - ETA: 2s - loss: 9.1106e-08180/450 [===========>..................] - ETA: 2s - loss: 9.1046e-08210/450 [=============>................] - ETA: 1s - loss: 9.0989e-08240/450 [===============>..............] - ETA: 1s - loss: 9.0932e-08270/450 [=================>............] - ETA: 1s - loss: 9.0876e-08300/450 [===================>..........] - ETA: 1s - loss: 9.0820e-08330/450 [=====================>........] - ETA: 0s - loss: 9.0765e-08360/450 [=======================>......] - ETA: 0s - loss: 9.0710e-08390/450 [=========================>....] - ETA: 0s - loss: 9.0656e-08420/450 [===========================>..] - ETA: 0s - loss: 9.0601e-08450/450 [==============================] - 3s - loss: 9.0547e-08 - val_loss: 8.9687e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.9687e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.9635e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.9580e-08120/450 [=======>......................] - ETA: 2s - loss: 8.9528e-08150/450 [=========>....................] - ETA: 2s - loss: 8.9475e-08180/450 [===========>..................] - ETA: 2s - loss: 8.9422e-08210/450 [=============>................] - ETA: 1s - loss: 8.9368e-08240/450 [===============>..............] - ETA: 1s - loss: 8.9315e-08270/450 [=================>............] - ETA: 1s - loss: 8.9263e-08300/450 [===================>..........] - ETA: 1s - loss: 8.9210e-08330/450 [=====================>........] - ETA: 0s - loss: 8.9157e-08360/450 [=======================>......] - ETA: 0s - loss: 8.9105e-08390/450 [=========================>....] - ETA: 0s - loss: 8.9053e-08420/450 [===========================>..] - ETA: 0s - loss: 8.9000e-08450/450 [==============================] - 3s - loss: 8.8948e-08 - val_loss: 8.8104e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.8478e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.8240e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.8382e-08120/450 [=======>......................] - ETA: 2s - loss: 8.8236e-08150/450 [=========>....................] - ETA: 2s - loss: 8.8129e-08180/450 [===========>..................] - ETA: 2s - loss: 8.8039e-08210/450 [=============>................] - ETA: 1s - loss: 8.8053e-08240/450 [===============>..............] - ETA: 1s - loss: 8.8020e-08270/450 [=================>............] - ETA: 1s - loss: 8.8037e-08300/450 [===================>..........] - ETA: 1s - loss: 8.7951e-08330/450 [=====================>........] - ETA: 0s - loss: 8.7938e-08360/450 [=======================>......] - ETA: 0s - loss: 8.7892e-08390/450 [=========================>....] - ETA: 0s - loss: 8.7814e-08420/450 [===========================>..] - ETA: 0s - loss: 8.7772e-08450/450 [==============================] - 3s - loss: 8.7720e-08 - val_loss: 8.6565e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.6566e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.6516e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.6465e-08120/450 [=======>......................] - ETA: 2s - loss: 8.6414e-08150/450 [=========>....................] - ETA: 2s - loss: 8.6362e-08180/450 [===========>..................] - ETA: 2s - loss: 8.6312e-08210/450 [=============>................] - ETA: 1s - loss: 8.6262e-08240/450 [===============>..............] - ETA: 1s - loss: 8.6212e-08270/450 [=================>............] - ETA: 1s - loss: 8.6161e-08300/450 [===================>..........] - ETA: 1s - loss: 8.6111e-08330/450 [=====================>........] - ETA: 0s - loss: 8.6060e-08360/450 [=======================>......] - ETA: 0s - loss: 8.6010e-08390/450 [=========================>....] - ETA: 0s - loss: 8.5960e-08420/450 [===========================>..] - ETA: 0s - loss: 8.5909e-08450/450 [==============================] - 3s - loss: 8.5859e-08 - val_loss: 8.5064e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.5077e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.5027e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.4976e-08120/450 [=======>......................] - ETA: 2s - loss: 8.4926e-08150/450 [=========>....................] - ETA: 2s - loss: 8.4877e-08180/450 [===========>..................] - ETA: 2s - loss: 8.4827e-08210/450 [=============>................] - ETA: 1s - loss: 8.4777e-08240/450 [===============>..............] - ETA: 1s - loss: 8.4728e-08270/450 [=================>............] - ETA: 1s - loss: 8.4678e-08300/450 [===================>..........] - ETA: 1s - loss: 8.4629e-08330/450 [=====================>........] - ETA: 0s - loss: 8.4581e-08360/450 [=======================>......] - ETA: 0s - loss: 8.4531e-08390/450 [=========================>....] - ETA: 0s - loss: 8.4482e-08420/450 [===========================>..] - ETA: 0s - loss: 8.4433e-08450/450 [==============================] - 3s - loss: 8.4384e-08 - val_loss: 8.3592e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.3598e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.3548e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.3499e-08120/450 [=======>......................] - ETA: 2s - loss: 8.3450e-08150/450 [=========>....................] - ETA: 2s - loss: 8.3401e-08180/450 [===========>..................] - ETA: 2s - loss: 8.3354e-08210/450 [=============>................] - ETA: 1s - loss: 8.3306e-08240/450 [===============>..............] - ETA: 1s - loss: 8.3258e-08270/450 [=================>............] - ETA: 1s - loss: 8.3209e-08300/450 [===================>..........] - ETA: 1s - loss: 8.3161e-08330/450 [=====================>........] - ETA: 0s - loss: 8.3113e-08360/450 [=======================>......] - ETA: 0s - loss: 8.3066e-08390/450 [=========================>....] - ETA: 0s - loss: 8.3018e-08420/450 [===========================>..] - ETA: 0s - loss: 8.2970e-08450/450 [==============================] - 3s - loss: 8.2922e-08 - val_loss: 8.2171e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.2162e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.2110e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.2062e-08120/450 [=======>......................] - ETA: 2s - loss: 8.2302e-08150/450 [=========>....................] - ETA: 2s - loss: 8.2295e-08180/450 [===========>..................] - ETA: 2s - loss: 8.2193e-08210/450 [=============>................] - ETA: 1s - loss: 8.2248e-08240/450 [===============>..............] - ETA: 1s - loss: 8.2153e-08270/450 [=================>............] - ETA: 1s - loss: 8.2120e-08300/450 [===================>..........] - ETA: 1s - loss: 8.2116e-08330/450 [=====================>........] - ETA: 0s - loss: 8.2035e-08360/450 [=======================>......] - ETA: 0s - loss: 8.2097e-08390/450 [=========================>....] - ETA: 0s - loss: 8.2068e-08420/450 [===========================>..] - ETA: 0s - loss: 8.2034e-08450/450 [==============================] - 3s - loss: 8.1955e-08 - val_loss: 8.0738e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.0741e-08 60/450 [===>..........................] - ETA: 3s - loss: 8.0747e-08 90/450 [=====>........................] - ETA: 2s - loss: 8.0682e-08120/450 [=======>......................] - ETA: 2s - loss: 8.0625e-08150/450 [=========>....................] - ETA: 2s - loss: 8.0574e-08180/450 [===========>..................] - ETA: 2s - loss: 8.0523e-08210/450 [=============>................] - ETA: 1s - loss: 8.0475e-08240/450 [===============>..............] - ETA: 1s - loss: 8.0426e-08270/450 [=================>............] - ETA: 1s - loss: 8.0378e-08300/450 [===================>..........] - ETA: 1s - loss: 8.0331e-08330/450 [=====================>........] - ETA: 0s - loss: 8.0347e-08360/450 [=======================>......] - ETA: 0s - loss: 8.0295e-08390/450 [=========================>....] - ETA: 0s - loss: 8.0244e-08420/450 [===========================>..] - ETA: 0s - loss: 8.0193e-08450/450 [==============================] - 3s - loss: 8.0171e-08 - val_loss: 7.9766e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.9356e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.9310e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.9265e-08120/450 [=======>......................] - ETA: 2s - loss: 7.9219e-08150/450 [=========>....................] - ETA: 2s - loss: 7.9173e-08180/450 [===========>..................] - ETA: 2s - loss: 7.9128e-08210/450 [=============>................] - ETA: 1s - loss: 7.9082e-08240/450 [===============>..............] - ETA: 1s - loss: 7.9037e-08270/450 [=================>............] - ETA: 1s - loss: 7.8992e-08300/450 [===================>..........] - ETA: 1s - loss: 7.8948e-08330/450 [=====================>........] - ETA: 0s - loss: 7.8903e-08360/450 [=======================>......] - ETA: 0s - loss: 7.8857e-08390/450 [=========================>....] - ETA: 0s - loss: 7.8812e-08420/450 [===========================>..] - ETA: 0s - loss: 7.8768e-08450/450 [==============================] - 3s - loss: 7.8723e-08 - val_loss: 7.8001e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.8044e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.7997e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.7958e-08120/450 [=======>......................] - ETA: 2s - loss: 7.7913e-08150/450 [=========>....................] - ETA: 2s - loss: 7.7865e-08180/450 [===========>..................] - ETA: 2s - loss: 7.7819e-08210/450 [=============>................] - ETA: 1s - loss: 7.7777e-08240/450 [===============>..............] - ETA: 1s - loss: 7.7733e-08270/450 [=================>............] - ETA: 1s - loss: 7.7689e-08300/450 [===================>..........] - ETA: 1s - loss: 7.7643e-08330/450 [=====================>........] - ETA: 0s - loss: 7.7599e-08360/450 [=======================>......] - ETA: 0s - loss: 7.7554e-08390/450 [=========================>....] - ETA: 0s - loss: 7.7509e-08420/450 [===========================>..] - ETA: 0s - loss: 7.7466e-08450/450 [==============================] - 3s - loss: 7.7422e-08 - val_loss: 7.6763e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.6741e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.6692e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.6645e-08120/450 [=======>......................] - ETA: 2s - loss: 7.6602e-08150/450 [=========>....................] - ETA: 2s - loss: 7.6555e-08180/450 [===========>..................] - ETA: 2s - loss: 7.6512e-08210/450 [=============>................] - ETA: 1s - loss: 7.6468e-08240/450 [===============>..............] - ETA: 1s - loss: 7.6426e-08270/450 [=================>............] - ETA: 1s - loss: 7.6384e-08300/450 [===================>..........] - ETA: 1s - loss: 7.6340e-08330/450 [=====================>........] - ETA: 0s - loss: 7.6296e-08360/450 [=======================>......] - ETA: 0s - loss: 7.6254e-08390/450 [=========================>....] - ETA: 0s - loss: 7.6210e-08420/450 [===========================>..] - ETA: 0s - loss: 7.6168e-08450/450 [==============================] - 3s - loss: 7.6125e-08 - val_loss: 7.5391e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.6052e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.6045e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.5774e-08120/450 [=======>......................] - ETA: 2s - loss: 7.5615e-08150/450 [=========>....................] - ETA: 2s - loss: 7.5534e-08180/450 [===========>..................] - ETA: 2s - loss: 7.5660e-08210/450 [=============>................] - ETA: 1s - loss: 7.5652e-08240/450 [===============>..............] - ETA: 1s - loss: 7.5545e-08270/450 [=================>............] - ETA: 1s - loss: 7.5479e-08300/450 [===================>..........] - ETA: 1s - loss: 7.5394e-08330/450 [=====================>........] - ETA: 0s - loss: 7.5316e-08360/450 [=======================>......] - ETA: 0s - loss: 7.5245e-08390/450 [=========================>....] - ETA: 0s - loss: 7.5211e-08420/450 [===========================>..] - ETA: 0s - loss: 7.5181e-08450/450 [==============================] - 3s - loss: 7.5131e-08 - val_loss: 7.4230e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.4124e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.4086e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.4049e-08120/450 [=======>......................] - ETA: 2s - loss: 7.4009e-08150/450 [=========>....................] - ETA: 2s - loss: 7.3966e-08180/450 [===========>..................] - ETA: 2s - loss: 7.3925e-08210/450 [=============>................] - ETA: 1s - loss: 7.3884e-08240/450 [===============>..............] - ETA: 1s - loss: 7.3843e-08270/450 [=================>............] - ETA: 1s - loss: 7.3802e-08300/450 [===================>..........] - ETA: 1s - loss: 7.3760e-08330/450 [=====================>........] - ETA: 0s - loss: 7.3719e-08360/450 [=======================>......] - ETA: 0s - loss: 7.3678e-08390/450 [=========================>....] - ETA: 0s - loss: 7.3635e-08420/450 [===========================>..] - ETA: 0s - loss: 7.3594e-08450/450 [==============================] - 3s - loss: 7.3552e-08 - val_loss: 7.2887e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.2896e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.2848e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.2806e-08120/450 [=======>......................] - ETA: 2s - loss: 7.2763e-08150/450 [=========>....................] - ETA: 2s - loss: 7.2725e-08180/450 [===========>..................] - ETA: 2s - loss: 7.2683e-08210/450 [=============>................] - ETA: 1s - loss: 7.2642e-08240/450 [===============>..............] - ETA: 1s - loss: 7.2601e-08270/450 [=================>............] - ETA: 1s - loss: 7.2560e-08300/450 [===================>..........] - ETA: 1s - loss: 7.2519e-08330/450 [=====================>........] - ETA: 0s - loss: 7.2479e-08360/450 [=======================>......] - ETA: 0s - loss: 7.2438e-08390/450 [=========================>....] - ETA: 0s - loss: 7.2398e-08420/450 [===========================>..] - ETA: 0s - loss: 7.2357e-08450/450 [==============================] - 3s - loss: 7.2316e-08 - val_loss: 7.1656e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.1673e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.1630e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.1592e-08120/450 [=======>......................] - ETA: 2s - loss: 7.1552e-08150/450 [=========>....................] - ETA: 2s - loss: 7.1511e-08180/450 [===========>..................] - ETA: 2s - loss: 7.1471e-08210/450 [=============>................] - ETA: 1s - loss: 7.1431e-08240/450 [===============>..............] - ETA: 1s - loss: 7.1391e-08270/450 [=================>............] - ETA: 1s - loss: 7.1351e-08300/450 [===================>..........] - ETA: 1s - loss: 7.1310e-08330/450 [=====================>........] - ETA: 0s - loss: 7.1271e-08360/450 [=======================>......] - ETA: 0s - loss: 7.1231e-08390/450 [=========================>....] - ETA: 0s - loss: 7.1191e-08420/450 [===========================>..] - ETA: 0s - loss: 7.1152e-08450/450 [==============================] - 3s - loss: 7.1113e-08 - val_loss: 7.0480e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 7.0484e-08 60/450 [===>..........................] - ETA: 3s - loss: 7.0440e-08 90/450 [=====>........................] - ETA: 2s - loss: 7.0403e-08120/450 [=======>......................] - ETA: 2s - loss: 7.0372e-08150/450 [=========>....................] - ETA: 2s - loss: 7.0332e-08180/450 [===========>..................] - ETA: 2s - loss: 7.0292e-08210/450 [=============>................] - ETA: 1s - loss: 7.0253e-08240/450 [===============>..............] - ETA: 1s - loss: 7.0213e-08270/450 [=================>............] - ETA: 1s - loss: 7.0174e-08300/450 [===================>..........] - ETA: 1s - loss: 7.0135e-08330/450 [=====================>........] - ETA: 0s - loss: 7.0096e-08360/450 [=======================>......] - ETA: 0s - loss: 7.0057e-08390/450 [=========================>....] - ETA: 0s - loss: 7.0017e-08420/450 [===========================>..] - ETA: 0s - loss: 6.9978e-08450/450 [==============================] - 3s - loss: 6.9938e-08 - val_loss: 7.0419e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.9299e-08 60/450 [===>..........................] - ETA: 2s - loss: 6.9259e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.9222e-08120/450 [=======>......................] - ETA: 2s - loss: 6.9182e-08150/450 [=========>....................] - ETA: 2s - loss: 6.9144e-08180/450 [===========>..................] - ETA: 2s - loss: 6.9106e-08210/450 [=============>................] - ETA: 1s - loss: 6.9067e-08240/450 [===============>..............] - ETA: 1s - loss: 6.9028e-08270/450 [=================>............] - ETA: 1s - loss: 6.8991e-08300/450 [===================>..........] - ETA: 1s - loss: 6.8952e-08330/450 [=====================>........] - ETA: 0s - loss: 6.8914e-08360/450 [=======================>......] - ETA: 0s - loss: 6.8877e-08390/450 [=========================>....] - ETA: 0s - loss: 6.8838e-08420/450 [===========================>..] - ETA: 0s - loss: 6.8800e-08450/450 [==============================] - 3s - loss: 6.8762e-08 - val_loss: 6.8154e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.8154e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.8116e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.8077e-08120/450 [=======>......................] - ETA: 2s - loss: 6.8039e-08150/450 [=========>....................] - ETA: 2s - loss: 6.8001e-08180/450 [===========>..................] - ETA: 2s - loss: 6.7963e-08210/450 [=============>................] - ETA: 1s - loss: 6.7925e-08240/450 [===============>..............] - ETA: 1s - loss: 6.7888e-08270/450 [=================>............] - ETA: 1s - loss: 6.7850e-08300/450 [===================>..........] - ETA: 1s - loss: 6.7813e-08330/450 [=====================>........] - ETA: 0s - loss: 6.7775e-08360/450 [=======================>......] - ETA: 0s - loss: 6.7738e-08390/450 [=========================>....] - ETA: 0s - loss: 6.7703e-08420/450 [===========================>..] - ETA: 0s - loss: 6.7665e-08450/450 [==============================] - 3s - loss: 6.7628e-08 - val_loss: 6.7026e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.7029e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.6991e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.6955e-08120/450 [=======>......................] - ETA: 2s - loss: 6.6918e-08150/450 [=========>....................] - ETA: 2s - loss: 6.6882e-08180/450 [===========>..................] - ETA: 2s - loss: 6.6845e-08210/450 [=============>................] - ETA: 1s - loss: 6.6808e-08240/450 [===============>..............] - ETA: 1s - loss: 6.6772e-08270/450 [=================>............] - ETA: 1s - loss: 6.6735e-08300/450 [===================>..........] - ETA: 1s - loss: 6.6699e-08330/450 [=====================>........] - ETA: 0s - loss: 6.6662e-08360/450 [=======================>......] - ETA: 0s - loss: 6.6625e-08390/450 [=========================>....] - ETA: 0s - loss: 6.6588e-08420/450 [===========================>..] - ETA: 0s - loss: 6.6552e-08450/450 [==============================] - 3s - loss: 6.6515e-08 - val_loss: 6.5932e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.5937e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.5898e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.5863e-08120/450 [=======>......................] - ETA: 2s - loss: 6.5827e-08150/450 [=========>....................] - ETA: 2s - loss: 6.5791e-08180/450 [===========>..................] - ETA: 2s - loss: 6.5755e-08210/450 [=============>................] - ETA: 1s - loss: 6.5720e-08240/450 [===============>..............] - ETA: 1s - loss: 6.5683e-08270/450 [=================>............] - ETA: 1s - loss: 6.5648e-08300/450 [===================>..........] - ETA: 1s - loss: 6.5612e-08330/450 [=====================>........] - ETA: 0s - loss: 6.5576e-08360/450 [=======================>......] - ETA: 0s - loss: 6.5540e-08390/450 [=========================>....] - ETA: 0s - loss: 6.5503e-08420/450 [===========================>..] - ETA: 0s - loss: 6.5468e-08450/450 [==============================] - 3s - loss: 6.5432e-08 - val_loss: 6.4855e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.4855e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.4821e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.4787e-08120/450 [=======>......................] - ETA: 2s - loss: 6.4751e-08150/450 [=========>....................] - ETA: 2s - loss: 6.4716e-08180/450 [===========>..................] - ETA: 2s - loss: 6.4683e-08210/450 [=============>................] - ETA: 1s - loss: 6.4646e-08240/450 [===============>..............] - ETA: 1s - loss: 6.4611e-08270/450 [=================>............] - ETA: 1s - loss: 6.4576e-08300/450 [===================>..........] - ETA: 1s - loss: 6.4540e-08330/450 [=====================>........] - ETA: 0s - loss: 6.4505e-08360/450 [=======================>......] - ETA: 0s - loss: 6.4470e-08390/450 [=========================>....] - ETA: 0s - loss: 6.4435e-08420/450 [===========================>..] - ETA: 0s - loss: 6.4401e-08450/450 [==============================] - 3s - loss: 6.4367e-08 - val_loss: 6.3797e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.3798e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.3763e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.3728e-08120/450 [=======>......................] - ETA: 2s - loss: 6.3693e-08150/450 [=========>....................] - ETA: 2s - loss: 6.3658e-08180/450 [===========>..................] - ETA: 2s - loss: 6.3623e-08210/450 [=============>................] - ETA: 1s - loss: 6.3589e-08240/450 [===============>..............] - ETA: 1s - loss: 6.3555e-08270/450 [=================>............] - ETA: 1s - loss: 6.3520e-08300/450 [===================>..........] - ETA: 1s - loss: 6.3485e-08330/450 [=====================>........] - ETA: 0s - loss: 6.3450e-08360/450 [=======================>......] - ETA: 0s - loss: 6.3415e-08390/450 [=========================>....] - ETA: 0s - loss: 6.3381e-08420/450 [===========================>..] - ETA: 0s - loss: 6.3346e-08450/450 [==============================] - 3s - loss: 6.3312e-08 - val_loss: 6.2767e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.2785e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.2753e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.2719e-08120/450 [=======>......................] - ETA: 2s - loss: 6.2683e-08150/450 [=========>....................] - ETA: 2s - loss: 6.2649e-08180/450 [===========>..................] - ETA: 2s - loss: 6.2614e-08210/450 [=============>................] - ETA: 1s - loss: 6.2580e-08240/450 [===============>..............] - ETA: 1s - loss: 6.2547e-08270/450 [=================>............] - ETA: 1s - loss: 6.2512e-08300/450 [===================>..........] - ETA: 1s - loss: 6.2478e-08330/450 [=====================>........] - ETA: 0s - loss: 6.2444e-08360/450 [=======================>......] - ETA: 0s - loss: 6.2410e-08390/450 [=========================>....] - ETA: 0s - loss: 6.2376e-08420/450 [===========================>..] - ETA: 0s - loss: 6.2342e-08450/450 [==============================] - 3s - loss: 6.2309e-08 - val_loss: 6.1776e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.1762e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.1727e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.1692e-08120/450 [=======>......................] - ETA: 2s - loss: 6.1660e-08150/450 [=========>....................] - ETA: 2s - loss: 6.1626e-08180/450 [===========>..................] - ETA: 2s - loss: 6.1594e-08210/450 [=============>................] - ETA: 1s - loss: 6.1560e-08240/450 [===============>..............] - ETA: 1s - loss: 6.1527e-08270/450 [=================>............] - ETA: 1s - loss: 6.1494e-08300/450 [===================>..........] - ETA: 1s - loss: 6.1460e-08330/450 [=====================>........] - ETA: 0s - loss: 6.1427e-08360/450 [=======================>......] - ETA: 0s - loss: 6.1394e-08390/450 [=========================>....] - ETA: 0s - loss: 6.1361e-08420/450 [===========================>..] - ETA: 0s - loss: 6.1328e-08450/450 [==============================] - 3s - loss: 6.1296e-08 - val_loss: 6.0758e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 6.0754e-08 60/450 [===>..........................] - ETA: 3s - loss: 6.0725e-08 90/450 [=====>........................] - ETA: 2s - loss: 6.0694e-08120/450 [=======>......................] - ETA: 2s - loss: 6.0661e-08150/450 [=========>....................] - ETA: 2s - loss: 6.0628e-08180/450 [===========>..................] - ETA: 2s - loss: 6.0595e-08210/450 [=============>................] - ETA: 1s - loss: 6.0562e-08240/450 [===============>..............] - ETA: 1s - loss: 6.0529e-08270/450 [=================>............] - ETA: 1s - loss: 6.0497e-08300/450 [===================>..........] - ETA: 1s - loss: 6.0464e-08330/450 [=====================>........] - ETA: 0s - loss: 6.0432e-08360/450 [=======================>......] - ETA: 0s - loss: 6.0399e-08390/450 [=========================>....] - ETA: 0s - loss: 6.0367e-08420/450 [===========================>..] - ETA: 0s - loss: 6.0334e-08450/450 [==============================] - 3s - loss: 6.0301e-08 - val_loss: 5.9780e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.9779e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.9746e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.9716e-08120/450 [=======>......................] - ETA: 2s - loss: 5.9684e-08150/450 [=========>....................] - ETA: 2s - loss: 5.9652e-08180/450 [===========>..................] - ETA: 2s - loss: 5.9620e-08210/450 [=============>................] - ETA: 1s - loss: 5.9588e-08240/450 [===============>..............] - ETA: 1s - loss: 5.9557e-08270/450 [=================>............] - ETA: 1s - loss: 5.9524e-08300/450 [===================>..........] - ETA: 1s - loss: 5.9492e-08330/450 [=====================>........] - ETA: 0s - loss: 5.9460e-08360/450 [=======================>......] - ETA: 0s - loss: 5.9429e-08390/450 [=========================>....] - ETA: 0s - loss: 5.9397e-08420/450 [===========================>..] - ETA: 0s - loss: 5.9365e-08450/450 [==============================] - 3s - loss: 5.9333e-08 - val_loss: 5.8829e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.8834e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.8805e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.8774e-08120/450 [=======>......................] - ETA: 2s - loss: 5.8743e-08150/450 [=========>....................] - ETA: 2s - loss: 5.8713e-08180/450 [===========>..................] - ETA: 2s - loss: 5.8681e-08210/450 [=============>................] - ETA: 1s - loss: 5.8650e-08240/450 [===============>..............] - ETA: 1s - loss: 5.8618e-08270/450 [=================>............] - ETA: 1s - loss: 5.8587e-08300/450 [===================>..........] - ETA: 1s - loss: 5.8555e-08330/450 [=====================>........] - ETA: 0s - loss: 5.8524e-08360/450 [=======================>......] - ETA: 0s - loss: 5.8493e-08390/450 [=========================>....] - ETA: 0s - loss: 5.8462e-08420/450 [===========================>..] - ETA: 0s - loss: 5.8430e-08450/450 [==============================] - 3s - loss: 5.8399e-08 - val_loss: 5.7912e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.8349e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.8089e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.8168e-08120/450 [=======>......................] - ETA: 2s - loss: 5.8163e-08150/450 [=========>....................] - ETA: 2s - loss: 5.8284e-08180/450 [===========>..................] - ETA: 2s - loss: 5.8167e-08210/450 [=============>................] - ETA: 1s - loss: 5.8075e-08240/450 [===============>..............] - ETA: 1s - loss: 5.7998e-08270/450 [=================>............] - ETA: 1s - loss: 5.7932e-08300/450 [===================>..........] - ETA: 1s - loss: 5.7919e-08330/450 [=====================>........] - ETA: 0s - loss: 5.7899e-08360/450 [=======================>......] - ETA: 0s - loss: 5.7948e-08390/450 [=========================>....] - ETA: 0s - loss: 5.7887e-08420/450 [===========================>..] - ETA: 0s - loss: 5.7831e-08450/450 [==============================] - 3s - loss: 5.7803e-08 - val_loss: 5.6969e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.6969e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.6939e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.6909e-08120/450 [=======>......................] - ETA: 2s - loss: 5.6878e-08150/450 [=========>....................] - ETA: 2s - loss: 5.6847e-08180/450 [===========>..................] - ETA: 2s - loss: 5.6818e-08210/450 [=============>................] - ETA: 1s - loss: 5.6788e-08240/450 [===============>..............] - ETA: 1s - loss: 5.6758e-08270/450 [=================>............] - ETA: 1s - loss: 5.6728e-08300/450 [===================>..........] - ETA: 1s - loss: 5.6697e-08330/450 [=====================>........] - ETA: 0s - loss: 5.6668e-08360/450 [=======================>......] - ETA: 0s - loss: 5.6638e-08390/450 [=========================>....] - ETA: 0s - loss: 5.6608e-08420/450 [===========================>..] - ETA: 0s - loss: 5.6578e-08450/450 [==============================] - 3s - loss: 5.6548e-08 - val_loss: 5.6076e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.6110e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.6079e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.6053e-08120/450 [=======>......................] - ETA: 2s - loss: 5.6024e-08150/450 [=========>....................] - ETA: 2s - loss: 5.5995e-08180/450 [===========>..................] - ETA: 2s - loss: 5.5965e-08210/450 [=============>................] - ETA: 1s - loss: 5.5935e-08240/450 [===============>..............] - ETA: 1s - loss: 5.5905e-08270/450 [=================>............] - ETA: 1s - loss: 5.5876e-08300/450 [===================>..........] - ETA: 1s - loss: 5.5847e-08330/450 [=====================>........] - ETA: 0s - loss: 5.5816e-08360/450 [=======================>......] - ETA: 0s - loss: 5.5786e-08390/450 [=========================>....] - ETA: 0s - loss: 5.5756e-08420/450 [===========================>..] - ETA: 0s - loss: 5.5727e-08450/450 [==============================] - 3s - loss: 5.5697e-08 - val_loss: 5.5219e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.5226e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.5198e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.5169e-08120/450 [=======>......................] - ETA: 2s - loss: 5.5139e-08150/450 [=========>....................] - ETA: 2s - loss: 5.5114e-08180/450 [===========>..................] - ETA: 2s - loss: 5.5084e-08210/450 [=============>................] - ETA: 1s - loss: 5.5055e-08240/450 [===============>..............] - ETA: 1s - loss: 5.5025e-08270/450 [=================>............] - ETA: 1s - loss: 5.4997e-08300/450 [===================>..........] - ETA: 1s - loss: 5.4967e-08330/450 [=====================>........] - ETA: 0s - loss: 5.4938e-08360/450 [=======================>......] - ETA: 0s - loss: 5.4909e-08390/450 [=========================>....] - ETA: 0s - loss: 5.4881e-08420/450 [===========================>..] - ETA: 0s - loss: 5.4852e-08450/450 [==============================] - 3s - loss: 5.4823e-08 - val_loss: 5.4371e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.4351e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.4317e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.4289e-08120/450 [=======>......................] - ETA: 2s - loss: 5.4258e-08150/450 [=========>....................] - ETA: 2s - loss: 5.4232e-08180/450 [===========>..................] - ETA: 2s - loss: 5.4202e-08210/450 [=============>................] - ETA: 1s - loss: 5.4173e-08240/450 [===============>..............] - ETA: 1s - loss: 5.4144e-08270/450 [=================>............] - ETA: 1s - loss: 5.4117e-08300/450 [===================>..........] - ETA: 1s - loss: 5.4089e-08330/450 [=====================>........] - ETA: 0s - loss: 5.4060e-08360/450 [=======================>......] - ETA: 0s - loss: 5.4032e-08390/450 [=========================>....] - ETA: 0s - loss: 5.4003e-08420/450 [===========================>..] - ETA: 0s - loss: 5.3975e-08450/450 [==============================] - 3s - loss: 5.3947e-08 - val_loss: 5.3491e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.3485e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.3462e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.3435e-08120/450 [=======>......................] - ETA: 2s - loss: 5.3407e-08150/450 [=========>....................] - ETA: 2s - loss: 5.3379e-08180/450 [===========>..................] - ETA: 2s - loss: 5.3351e-08210/450 [=============>................] - ETA: 1s - loss: 5.3324e-08240/450 [===============>..............] - ETA: 1s - loss: 5.3296e-08270/450 [=================>............] - ETA: 1s - loss: 5.3268e-08300/450 [===================>..........] - ETA: 1s - loss: 5.3241e-08330/450 [=====================>........] - ETA: 0s - loss: 5.3213e-08360/450 [=======================>......] - ETA: 0s - loss: 5.3186e-08390/450 [=========================>....] - ETA: 0s - loss: 5.3158e-08420/450 [===========================>..] - ETA: 0s - loss: 5.3130e-08450/450 [==============================] - 3s - loss: 5.3102e-08 - val_loss: 5.2650e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.2652e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.2625e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.2598e-08120/450 [=======>......................] - ETA: 2s - loss: 5.2572e-08150/450 [=========>....................] - ETA: 2s - loss: 5.2544e-08180/450 [===========>..................] - ETA: 2s - loss: 5.2516e-08210/450 [=============>................] - ETA: 1s - loss: 5.2488e-08240/450 [===============>..............] - ETA: 1s - loss: 5.2462e-08270/450 [=================>............] - ETA: 1s - loss: 5.2434e-08300/450 [===================>..........] - ETA: 1s - loss: 5.2406e-08330/450 [=====================>........] - ETA: 0s - loss: 5.2379e-08360/450 [=======================>......] - ETA: 0s - loss: 5.2352e-08390/450 [=========================>....] - ETA: 0s - loss: 5.2325e-08420/450 [===========================>..] - ETA: 0s - loss: 5.2298e-08450/450 [==============================] - 3s - loss: 5.2271e-08 - val_loss: 5.1840e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.1914e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.1879e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.1851e-08120/450 [=======>......................] - ETA: 2s - loss: 5.1824e-08150/450 [=========>....................] - ETA: 2s - loss: 5.1797e-08180/450 [===========>..................] - ETA: 2s - loss: 5.1771e-08210/450 [=============>................] - ETA: 1s - loss: 5.1745e-08240/450 [===============>..............] - ETA: 1s - loss: 5.1718e-08270/450 [=================>............] - ETA: 1s - loss: 5.1692e-08300/450 [===================>..........] - ETA: 1s - loss: 5.1666e-08330/450 [=====================>........] - ETA: 0s - loss: 5.1639e-08360/450 [=======================>......] - ETA: 0s - loss: 5.1611e-08390/450 [=========================>....] - ETA: 0s - loss: 5.1584e-08420/450 [===========================>..] - ETA: 0s - loss: 5.1558e-08450/450 [==============================] - 3s - loss: 5.1531e-08 - val_loss: 5.1107e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.1052e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.1028e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.1002e-08120/450 [=======>......................] - ETA: 2s - loss: 5.0974e-08150/450 [=========>....................] - ETA: 2s - loss: 5.0950e-08180/450 [===========>..................] - ETA: 2s - loss: 5.0923e-08210/450 [=============>................] - ETA: 1s - loss: 5.0895e-08240/450 [===============>..............] - ETA: 1s - loss: 5.0868e-08270/450 [=================>............] - ETA: 1s - loss: 5.0842e-08300/450 [===================>..........] - ETA: 1s - loss: 5.0815e-08330/450 [=====================>........] - ETA: 0s - loss: 5.0789e-08360/450 [=======================>......] - ETA: 0s - loss: 5.0763e-08390/450 [=========================>....] - ETA: 0s - loss: 5.0737e-08420/450 [===========================>..] - ETA: 0s - loss: 5.0711e-08450/450 [==============================] - 3s - loss: 5.0684e-08 - val_loss: 5.0252e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 5.0256e-08 60/450 [===>..........................] - ETA: 3s - loss: 5.0225e-08 90/450 [=====>........................] - ETA: 2s - loss: 5.0199e-08120/450 [=======>......................] - ETA: 2s - loss: 5.0173e-08150/450 [=========>....................] - ETA: 2s - loss: 5.0146e-08180/450 [===========>..................] - ETA: 2s - loss: 5.0120e-08210/450 [=============>................] - ETA: 1s - loss: 5.0094e-08240/450 [===============>..............] - ETA: 1s - loss: 5.0068e-08270/450 [=================>............] - ETA: 1s - loss: 5.0041e-08300/450 [===================>..........] - ETA: 1s - loss: 5.0015e-08330/450 [=====================>........] - ETA: 0s - loss: 4.9990e-08360/450 [=======================>......] - ETA: 0s - loss: 4.9964e-08390/450 [=========================>....] - ETA: 0s - loss: 4.9938e-08420/450 [===========================>..] - ETA: 0s - loss: 4.9912e-08450/450 [==============================] - 3s - loss: 4.9886e-08 - val_loss: 4.9463e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.9476e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.9451e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.9424e-08120/450 [=======>......................] - ETA: 2s - loss: 4.9398e-08150/450 [=========>....................] - ETA: 2s - loss: 4.9372e-08180/450 [===========>..................] - ETA: 2s - loss: 4.9348e-08210/450 [=============>................] - ETA: 1s - loss: 4.9322e-08240/450 [===============>..............] - ETA: 1s - loss: 4.9297e-08270/450 [=================>............] - ETA: 1s - loss: 4.9271e-08300/450 [===================>..........] - ETA: 1s - loss: 4.9245e-08330/450 [=====================>........] - ETA: 0s - loss: 4.9220e-08360/450 [=======================>......] - ETA: 0s - loss: 4.9195e-08390/450 [=========================>....] - ETA: 0s - loss: 4.9170e-08420/450 [===========================>..] - ETA: 0s - loss: 4.9145e-08450/450 [==============================] - 3s - loss: 4.9120e-08 - val_loss: 4.8719e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.8724e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.8698e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.8672e-08120/450 [=======>......................] - ETA: 2s - loss: 4.8647e-08150/450 [=========>....................] - ETA: 2s - loss: 4.8622e-08180/450 [===========>..................] - ETA: 2s - loss: 4.8598e-08210/450 [=============>................] - ETA: 1s - loss: 4.8572e-08240/450 [===============>..............] - ETA: 1s - loss: 4.8548e-08270/450 [=================>............] - ETA: 1s - loss: 4.8523e-08300/450 [===================>..........] - ETA: 1s - loss: 4.8497e-08330/450 [=====================>........] - ETA: 0s - loss: 4.8472e-08360/450 [=======================>......] - ETA: 0s - loss: 4.8447e-08390/450 [=========================>....] - ETA: 0s - loss: 4.8422e-08420/450 [===========================>..] - ETA: 0s - loss: 4.8398e-08450/450 [==============================] - 3s - loss: 4.8373e-08 - val_loss: 4.7978e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.7969e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.7943e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.7919e-08120/450 [=======>......................] - ETA: 2s - loss: 4.7895e-08150/450 [=========>....................] - ETA: 2s - loss: 4.7870e-08180/450 [===========>..................] - ETA: 2s - loss: 4.7846e-08210/450 [=============>................] - ETA: 1s - loss: 4.7821e-08240/450 [===============>..............] - ETA: 1s - loss: 4.7797e-08270/450 [=================>............] - ETA: 1s - loss: 4.7772e-08300/450 [===================>..........] - ETA: 1s - loss: 4.7748e-08330/450 [=====================>........] - ETA: 0s - loss: 4.7724e-08360/450 [=======================>......] - ETA: 0s - loss: 4.7699e-08390/450 [=========================>....] - ETA: 0s - loss: 4.7674e-08420/450 [===========================>..] - ETA: 0s - loss: 4.7651e-08450/450 [==============================] - 3s - loss: 4.7626e-08 - val_loss: 4.7237e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.7239e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.7213e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.7189e-08120/450 [=======>......................] - ETA: 2s - loss: 4.7165e-08150/450 [=========>....................] - ETA: 2s - loss: 4.7142e-08180/450 [===========>..................] - ETA: 2s - loss: 4.7118e-08210/450 [=============>................] - ETA: 1s - loss: 4.7094e-08240/450 [===============>..............] - ETA: 1s - loss: 4.7070e-08270/450 [=================>............] - ETA: 1s - loss: 4.7046e-08300/450 [===================>..........] - ETA: 1s - loss: 4.7022e-08330/450 [=====================>........] - ETA: 0s - loss: 4.6998e-08360/450 [=======================>......] - ETA: 0s - loss: 4.6975e-08390/450 [=========================>....] - ETA: 0s - loss: 4.6964e-08420/450 [===========================>..] - ETA: 0s - loss: 4.6939e-08450/450 [==============================] - 3s - loss: 4.6914e-08 - val_loss: 4.6534e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.6528e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.6502e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.6479e-08120/450 [=======>......................] - ETA: 2s - loss: 4.6455e-08150/450 [=========>....................] - ETA: 2s - loss: 4.6432e-08180/450 [===========>..................] - ETA: 2s - loss: 4.6410e-08210/450 [=============>................] - ETA: 1s - loss: 4.6387e-08240/450 [===============>..............] - ETA: 1s - loss: 4.6364e-08270/450 [=================>............] - ETA: 1s - loss: 4.6341e-08300/450 [===================>..........] - ETA: 1s - loss: 4.6317e-08330/450 [=====================>........] - ETA: 0s - loss: 4.6293e-08360/450 [=======================>......] - ETA: 0s - loss: 4.6270e-08390/450 [=========================>....] - ETA: 0s - loss: 4.6247e-08420/450 [===========================>..] - ETA: 0s - loss: 4.6223e-08450/450 [==============================] - 3s - loss: 4.6199e-08 - val_loss: 4.5823e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 2s - loss: 4.5833e-08 60/450 [===>..........................] - ETA: 2s - loss: 4.5809e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.5785e-08120/450 [=======>......................] - ETA: 2s - loss: 4.5762e-08150/450 [=========>....................] - ETA: 2s - loss: 4.5738e-08180/450 [===========>..................] - ETA: 1s - loss: 4.5715e-08210/450 [=============>................] - ETA: 1s - loss: 4.5691e-08240/450 [===============>..............] - ETA: 1s - loss: 4.5669e-08270/450 [=================>............] - ETA: 1s - loss: 4.5646e-08300/450 [===================>..........] - ETA: 1s - loss: 4.5623e-08330/450 [=====================>........] - ETA: 0s - loss: 4.5601e-08360/450 [=======================>......] - ETA: 0s - loss: 4.5578e-08390/450 [=========================>....] - ETA: 0s - loss: 4.5555e-08420/450 [===========================>..] - ETA: 0s - loss: 4.5532e-08450/450 [==============================] - 3s - loss: 4.5509e-08 - val_loss: 4.5165e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.5165e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.5139e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.5118e-08120/450 [=======>......................] - ETA: 2s - loss: 4.5094e-08150/450 [=========>....................] - ETA: 2s - loss: 4.5071e-08180/450 [===========>..................] - ETA: 2s - loss: 4.5048e-08210/450 [=============>................] - ETA: 1s - loss: 4.5024e-08240/450 [===============>..............] - ETA: 1s - loss: 4.5000e-08270/450 [=================>............] - ETA: 1s - loss: 4.4977e-08300/450 [===================>..........] - ETA: 1s - loss: 4.4955e-08330/450 [=====================>........] - ETA: 0s - loss: 4.4933e-08360/450 [=======================>......] - ETA: 0s - loss: 4.4910e-08390/450 [=========================>....] - ETA: 0s - loss: 4.4888e-08420/450 [===========================>..] - ETA: 0s - loss: 4.4865e-08450/450 [==============================] - 3s - loss: 4.4843e-08 - val_loss: 4.4450e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.4456e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.4487e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.4448e-08120/450 [=======>......................] - ETA: 2s - loss: 4.4417e-08150/450 [=========>....................] - ETA: 2s - loss: 4.4390e-08180/450 [===========>..................] - ETA: 2s - loss: 4.4364e-08210/450 [=============>................] - ETA: 1s - loss: 4.4339e-08240/450 [===============>..............] - ETA: 1s - loss: 4.4316e-08270/450 [=================>............] - ETA: 1s - loss: 4.4292e-08300/450 [===================>..........] - ETA: 1s - loss: 4.4269e-08330/450 [=====================>........] - ETA: 0s - loss: 4.4246e-08360/450 [=======================>......] - ETA: 0s - loss: 4.4223e-08390/450 [=========================>....] - ETA: 0s - loss: 4.4200e-08420/450 [===========================>..] - ETA: 0s - loss: 4.4177e-08450/450 [==============================] - 3s - loss: 4.4154e-08 - val_loss: 4.3803e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.3803e-08 60/450 [===>..........................] - ETA: 2s - loss: 4.3779e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.3757e-08120/450 [=======>......................] - ETA: 2s - loss: 4.3735e-08150/450 [=========>....................] - ETA: 2s - loss: 4.3712e-08180/450 [===========>..................] - ETA: 2s - loss: 4.3690e-08210/450 [=============>................] - ETA: 1s - loss: 4.3669e-08240/450 [===============>..............] - ETA: 1s - loss: 4.3647e-08270/450 [=================>............] - ETA: 1s - loss: 4.3625e-08300/450 [===================>..........] - ETA: 1s - loss: 4.3604e-08330/450 [=====================>........] - ETA: 0s - loss: 4.3582e-08360/450 [=======================>......] - ETA: 0s - loss: 4.3561e-08390/450 [=========================>....] - ETA: 0s - loss: 4.3539e-08420/450 [===========================>..] - ETA: 0s - loss: 4.3517e-08450/450 [==============================] - 3s - loss: 4.3495e-08 - val_loss: 4.3141e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.3137e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.3119e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.3096e-08120/450 [=======>......................] - ETA: 2s - loss: 4.3074e-08150/450 [=========>....................] - ETA: 2s - loss: 4.3052e-08180/450 [===========>..................] - ETA: 2s - loss: 4.3031e-08210/450 [=============>................] - ETA: 1s - loss: 4.3009e-08240/450 [===============>..............] - ETA: 1s - loss: 4.2987e-08270/450 [=================>............] - ETA: 1s - loss: 4.2966e-08300/450 [===================>..........] - ETA: 1s - loss: 4.2945e-08330/450 [=====================>........] - ETA: 0s - loss: 4.2923e-08360/450 [=======================>......] - ETA: 0s - loss: 4.2902e-08390/450 [=========================>....] - ETA: 0s - loss: 4.2881e-08420/450 [===========================>..] - ETA: 0s - loss: 4.2859e-08450/450 [==============================] - 3s - loss: 4.2838e-08 - val_loss: 4.2501e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.2495e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.2472e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.2453e-08120/450 [=======>......................] - ETA: 2s - loss: 4.2432e-08150/450 [=========>....................] - ETA: 2s - loss: 4.2411e-08180/450 [===========>..................] - ETA: 2s - loss: 4.2390e-08210/450 [=============>................] - ETA: 1s - loss: 4.2369e-08240/450 [===============>..............] - ETA: 1s - loss: 4.2348e-08270/450 [=================>............] - ETA: 1s - loss: 4.2326e-08300/450 [===================>..........] - ETA: 1s - loss: 4.2305e-08330/450 [=====================>........] - ETA: 0s - loss: 4.2284e-08360/450 [=======================>......] - ETA: 0s - loss: 4.2264e-08390/450 [=========================>....] - ETA: 0s - loss: 4.2242e-08420/450 [===========================>..] - ETA: 0s - loss: 4.2221e-08450/450 [==============================] - 3s - loss: 4.2200e-08 - val_loss: 4.1861e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.1863e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.1842e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.1820e-08120/450 [=======>......................] - ETA: 2s - loss: 4.1800e-08150/450 [=========>....................] - ETA: 2s - loss: 4.1779e-08180/450 [===========>..................] - ETA: 2s - loss: 4.1758e-08210/450 [=============>................] - ETA: 1s - loss: 4.1737e-08240/450 [===============>..............] - ETA: 1s - loss: 4.1717e-08270/450 [=================>............] - ETA: 1s - loss: 4.1697e-08300/450 [===================>..........] - ETA: 1s - loss: 4.1676e-08330/450 [=====================>........] - ETA: 0s - loss: 4.1656e-08360/450 [=======================>......] - ETA: 0s - loss: 4.1635e-08390/450 [=========================>....] - ETA: 0s - loss: 4.1614e-08420/450 [===========================>..] - ETA: 0s - loss: 4.1593e-08450/450 [==============================] - 3s - loss: 4.1573e-08 - val_loss: 4.1244e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.1263e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.1236e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.1213e-08120/450 [=======>......................] - ETA: 2s - loss: 4.1191e-08150/450 [=========>....................] - ETA: 2s - loss: 4.1170e-08180/450 [===========>..................] - ETA: 2s - loss: 4.1150e-08210/450 [=============>................] - ETA: 1s - loss: 4.1129e-08240/450 [===============>..............] - ETA: 1s - loss: 4.1108e-08270/450 [=================>............] - ETA: 1s - loss: 4.1088e-08300/450 [===================>..........] - ETA: 1s - loss: 4.1067e-08330/450 [=====================>........] - ETA: 0s - loss: 4.1047e-08360/450 [=======================>......] - ETA: 0s - loss: 4.1027e-08390/450 [=========================>....] - ETA: 0s - loss: 4.1007e-08420/450 [===========================>..] - ETA: 0s - loss: 4.0986e-08450/450 [==============================] - 3s - loss: 4.0966e-08 - val_loss: 4.0633e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.0643e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.0622e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.0602e-08120/450 [=======>......................] - ETA: 2s - loss: 4.0582e-08150/450 [=========>....................] - ETA: 2s - loss: 4.0562e-08180/450 [===========>..................] - ETA: 2s - loss: 4.0542e-08210/450 [=============>................] - ETA: 1s - loss: 4.0522e-08240/450 [===============>..............] - ETA: 1s - loss: 4.0502e-08270/450 [=================>............] - ETA: 1s - loss: 4.0482e-08300/450 [===================>..........] - ETA: 1s - loss: 4.0461e-08330/450 [=====================>........] - ETA: 0s - loss: 4.0442e-08360/450 [=======================>......] - ETA: 0s - loss: 4.0422e-08390/450 [=========================>....] - ETA: 0s - loss: 4.0402e-08420/450 [===========================>..] - ETA: 0s - loss: 4.0382e-08450/450 [==============================] - 3s - loss: 4.0363e-08 - val_loss: 4.0041e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 4.0042e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.0023e-08 90/450 [=====>........................] - ETA: 2s - loss: 4.0003e-08120/450 [=======>......................] - ETA: 2s - loss: 3.9983e-08150/450 [=========>....................] - ETA: 2s - loss: 3.9964e-08180/450 [===========>..................] - ETA: 2s - loss: 3.9944e-08210/450 [=============>................] - ETA: 1s - loss: 3.9924e-08240/450 [===============>..............] - ETA: 1s - loss: 3.9905e-08270/450 [=================>............] - ETA: 1s - loss: 3.9886e-08300/450 [===================>..........] - ETA: 1s - loss: 3.9866e-08330/450 [=====================>........] - ETA: 0s - loss: 3.9847e-08360/450 [=======================>......] - ETA: 0s - loss: 3.9827e-08390/450 [=========================>....] - ETA: 0s - loss: 3.9808e-08420/450 [===========================>..] - ETA: 0s - loss: 3.9788e-08450/450 [==============================] - 3s - loss: 3.9769e-08 - val_loss: 3.9460e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.9467e-08 60/450 [===>..........................] - ETA: 3s - loss: 4.0152e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.9898e-08120/450 [=======>......................] - ETA: 2s - loss: 3.9944e-08150/450 [=========>....................] - ETA: 2s - loss: 3.9818e-08180/450 [===========>..................] - ETA: 2s - loss: 3.9726e-08210/450 [=============>................] - ETA: 1s - loss: 3.9776e-08240/450 [===============>..............] - ETA: 1s - loss: 3.9833e-08270/450 [=================>............] - ETA: 1s - loss: 3.9758e-08300/450 [===================>..........] - ETA: 1s - loss: 3.9694e-08330/450 [=====================>........] - ETA: 0s - loss: 3.9639e-08360/450 [=======================>......] - ETA: 0s - loss: 3.9589e-08390/450 [=========================>....] - ETA: 0s - loss: 3.9698e-08420/450 [===========================>..] - ETA: 0s - loss: 3.9646e-08450/450 [==============================] - 3s - loss: 3.9664e-08 - val_loss: 3.8883e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.8882e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.8862e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.8977e-08120/450 [=======>......................] - ETA: 2s - loss: 3.9147e-08150/450 [=========>....................] - ETA: 2s - loss: 3.9064e-08180/450 [===========>..................] - ETA: 2s - loss: 3.9043e-08210/450 [=============>................] - ETA: 1s - loss: 3.8987e-08240/450 [===============>..............] - ETA: 1s - loss: 3.9003e-08270/450 [=================>............] - ETA: 1s - loss: 3.8999e-08300/450 [===================>..........] - ETA: 1s - loss: 3.8985e-08330/450 [=====================>........] - ETA: 0s - loss: 3.8942e-08360/450 [=======================>......] - ETA: 0s - loss: 3.8902e-08390/450 [=========================>....] - ETA: 0s - loss: 3.8869e-08420/450 [===========================>..] - ETA: 0s - loss: 3.8835e-08450/450 [==============================] - 3s - loss: 3.8838e-08 - val_loss: 3.8321e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.8315e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.8298e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.8280e-08120/450 [=======>......................] - ETA: 2s - loss: 3.8262e-08150/450 [=========>....................] - ETA: 2s - loss: 3.8243e-08180/450 [===========>..................] - ETA: 2s - loss: 3.8224e-08210/450 [=============>................] - ETA: 1s - loss: 3.8206e-08240/450 [===============>..............] - ETA: 1s - loss: 3.8187e-08270/450 [=================>............] - ETA: 1s - loss: 3.8169e-08300/450 [===================>..........] - ETA: 1s - loss: 3.8150e-08330/450 [=====================>........] - ETA: 0s - loss: 3.8132e-08360/450 [=======================>......] - ETA: 0s - loss: 3.8113e-08390/450 [=========================>....] - ETA: 0s - loss: 3.8095e-08420/450 [===========================>..] - ETA: 0s - loss: 3.8076e-08450/450 [==============================] - 3s - loss: 3.8058e-08 - val_loss: 3.7762e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.7774e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.7754e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.7734e-08120/450 [=======>......................] - ETA: 2s - loss: 3.7716e-08150/450 [=========>....................] - ETA: 2s - loss: 3.7698e-08180/450 [===========>..................] - ETA: 2s - loss: 3.7679e-08210/450 [=============>................] - ETA: 1s - loss: 3.7660e-08240/450 [===============>..............] - ETA: 1s - loss: 3.7642e-08270/450 [=================>............] - ETA: 1s - loss: 3.7623e-08300/450 [===================>..........] - ETA: 1s - loss: 3.7605e-08330/450 [=====================>........] - ETA: 0s - loss: 3.7586e-08360/450 [=======================>......] - ETA: 0s - loss: 3.7568e-08390/450 [=========================>....] - ETA: 0s - loss: 3.7550e-08420/450 [===========================>..] - ETA: 0s - loss: 3.7532e-08450/450 [==============================] - 3s - loss: 3.7513e-08 - val_loss: 3.7215e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.7215e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.7197e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.7178e-08120/450 [=======>......................] - ETA: 2s - loss: 3.7159e-08150/450 [=========>....................] - ETA: 2s - loss: 3.7142e-08180/450 [===========>..................] - ETA: 2s - loss: 3.7124e-08210/450 [=============>................] - ETA: 1s - loss: 3.7106e-08240/450 [===============>..............] - ETA: 1s - loss: 3.7088e-08270/450 [=================>............] - ETA: 1s - loss: 3.7070e-08300/450 [===================>..........] - ETA: 1s - loss: 3.7052e-08330/450 [=====================>........] - ETA: 0s - loss: 3.7034e-08360/450 [=======================>......] - ETA: 0s - loss: 3.7016e-08390/450 [=========================>....] - ETA: 0s - loss: 3.6998e-08420/450 [===========================>..] - ETA: 0s - loss: 3.6980e-08450/450 [==============================] - 3s - loss: 3.6962e-08 - val_loss: 3.6680e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.6678e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.6661e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.6642e-08120/450 [=======>......................] - ETA: 2s - loss: 3.6625e-08150/450 [=========>....................] - ETA: 2s - loss: 3.6607e-08180/450 [===========>..................] - ETA: 2s - loss: 3.6590e-08210/450 [=============>................] - ETA: 1s - loss: 3.6572e-08240/450 [===============>..............] - ETA: 1s - loss: 3.6555e-08270/450 [=================>............] - ETA: 1s - loss: 3.6537e-08300/450 [===================>..........] - ETA: 1s - loss: 3.6521e-08330/450 [=====================>........] - ETA: 0s - loss: 3.6503e-08360/450 [=======================>......] - ETA: 0s - loss: 3.6485e-08390/450 [=========================>....] - ETA: 0s - loss: 3.6468e-08420/450 [===========================>..] - ETA: 0s - loss: 3.6450e-08450/450 [==============================] - 3s - loss: 3.6432e-08 - val_loss: 3.6154e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.6151e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.6137e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.6121e-08120/450 [=======>......................] - ETA: 2s - loss: 3.6103e-08150/450 [=========>....................] - ETA: 2s - loss: 3.6084e-08180/450 [===========>..................] - ETA: 2s - loss: 3.6066e-08210/450 [=============>................] - ETA: 1s - loss: 3.6050e-08240/450 [===============>..............] - ETA: 1s - loss: 3.6033e-08270/450 [=================>............] - ETA: 1s - loss: 3.6015e-08300/450 [===================>..........] - ETA: 1s - loss: 3.5998e-08330/450 [=====================>........] - ETA: 0s - loss: 3.5981e-08360/450 [=======================>......] - ETA: 0s - loss: 3.5964e-08390/450 [=========================>....] - ETA: 0s - loss: 3.5946e-08420/450 [===========================>..] - ETA: 0s - loss: 3.5930e-08450/450 [==============================] - 3s - loss: 3.5913e-08 - val_loss: 3.5639e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.5665e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.5648e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.5630e-08120/450 [=======>......................] - ETA: 2s - loss: 3.5613e-08150/450 [=========>....................] - ETA: 2s - loss: 3.5597e-08180/450 [===========>..................] - ETA: 2s - loss: 3.5580e-08210/450 [=============>................] - ETA: 1s - loss: 3.5563e-08240/450 [===============>..............] - ETA: 1s - loss: 3.5546e-08270/450 [=================>............] - ETA: 1s - loss: 3.5529e-08300/450 [===================>..........] - ETA: 1s - loss: 3.5512e-08330/450 [=====================>........] - ETA: 0s - loss: 3.5495e-08360/450 [=======================>......] - ETA: 0s - loss: 3.5478e-08390/450 [=========================>....] - ETA: 0s - loss: 3.5461e-08420/450 [===========================>..] - ETA: 0s - loss: 3.5443e-08450/450 [==============================] - 3s - loss: 3.5427e-08 - val_loss: 3.5158e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.5154e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.5139e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.5122e-08120/450 [=======>......................] - ETA: 2s - loss: 3.5106e-08150/450 [=========>....................] - ETA: 2s - loss: 3.5089e-08180/450 [===========>..................] - ETA: 2s - loss: 3.5075e-08210/450 [=============>................] - ETA: 1s - loss: 3.5057e-08240/450 [===============>..............] - ETA: 1s - loss: 3.5041e-08270/450 [=================>............] - ETA: 1s - loss: 3.5024e-08300/450 [===================>..........] - ETA: 1s - loss: 3.5008e-08330/450 [=====================>........] - ETA: 0s - loss: 3.4991e-08360/450 [=======================>......] - ETA: 0s - loss: 3.4974e-08390/450 [=========================>....] - ETA: 0s - loss: 3.4957e-08420/450 [===========================>..] - ETA: 0s - loss: 3.4940e-08450/450 [==============================] - 3s - loss: 3.4923e-08 - val_loss: 3.4652e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.4660e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.4645e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.4627e-08120/450 [=======>......................] - ETA: 2s - loss: 3.4609e-08150/450 [=========>....................] - ETA: 2s - loss: 3.4593e-08180/450 [===========>..................] - ETA: 2s - loss: 3.4577e-08210/450 [=============>................] - ETA: 1s - loss: 3.4562e-08240/450 [===============>..............] - ETA: 1s - loss: 3.4545e-08270/450 [=================>............] - ETA: 1s - loss: 3.4528e-08300/450 [===================>..........] - ETA: 1s - loss: 3.4512e-08330/450 [=====================>........] - ETA: 0s - loss: 3.4495e-08360/450 [=======================>......] - ETA: 0s - loss: 3.4478e-08390/450 [=========================>....] - ETA: 0s - loss: 3.4462e-08420/450 [===========================>..] - ETA: 0s - loss: 3.4446e-08450/450 [==============================] - 3s - loss: 3.4429e-08 - val_loss: 3.4142e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.4151e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.4134e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.4119e-08120/450 [=======>......................] - ETA: 2s - loss: 3.4102e-08150/450 [=========>....................] - ETA: 2s - loss: 3.4085e-08180/450 [===========>..................] - ETA: 2s - loss: 3.4068e-08210/450 [=============>................] - ETA: 1s - loss: 3.4052e-08240/450 [===============>..............] - ETA: 1s - loss: 3.4036e-08270/450 [=================>............] - ETA: 1s - loss: 3.4020e-08300/450 [===================>..........] - ETA: 1s - loss: 3.4003e-08330/450 [=====================>........] - ETA: 0s - loss: 3.3987e-08360/450 [=======================>......] - ETA: 0s - loss: 3.3971e-08390/450 [=========================>....] - ETA: 0s - loss: 3.3956e-08420/450 [===========================>..] - ETA: 0s - loss: 3.3939e-08450/450 [==============================] - 3s - loss: 3.3923e-08 - val_loss: 3.3663e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.3661e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.3646e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.3630e-08120/450 [=======>......................] - ETA: 2s - loss: 3.3614e-08150/450 [=========>....................] - ETA: 2s - loss: 3.3598e-08180/450 [===========>..................] - ETA: 2s - loss: 3.3582e-08210/450 [=============>................] - ETA: 1s - loss: 3.3566e-08240/450 [===============>..............] - ETA: 1s - loss: 3.3550e-08270/450 [=================>............] - ETA: 1s - loss: 3.3534e-08300/450 [===================>..........] - ETA: 1s - loss: 3.3518e-08330/450 [=====================>........] - ETA: 0s - loss: 3.3502e-08360/450 [=======================>......] - ETA: 0s - loss: 3.3486e-08390/450 [=========================>....] - ETA: 0s - loss: 3.3470e-08420/450 [===========================>..] - ETA: 0s - loss: 3.3454e-08450/450 [==============================] - 3s - loss: 3.3438e-08 - val_loss: 3.3189e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.3197e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.3180e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.3165e-08120/450 [=======>......................] - ETA: 2s - loss: 3.3151e-08150/450 [=========>....................] - ETA: 2s - loss: 3.3135e-08180/450 [===========>..................] - ETA: 2s - loss: 3.3119e-08210/450 [=============>................] - ETA: 1s - loss: 3.3103e-08240/450 [===============>..............] - ETA: 1s - loss: 3.3088e-08270/450 [=================>............] - ETA: 1s - loss: 3.3073e-08300/450 [===================>..........] - ETA: 1s - loss: 3.3057e-08330/450 [=====================>........] - ETA: 0s - loss: 3.3041e-08360/450 [=======================>......] - ETA: 0s - loss: 3.3026e-08390/450 [=========================>....] - ETA: 0s - loss: 3.3010e-08420/450 [===========================>..] - ETA: 0s - loss: 3.2995e-08450/450 [==============================] - 3s - loss: 3.2979e-08 - val_loss: 3.2742e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.2714e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.2698e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.2682e-08120/450 [=======>......................] - ETA: 2s - loss: 3.2667e-08150/450 [=========>....................] - ETA: 2s - loss: 3.2651e-08180/450 [===========>..................] - ETA: 2s - loss: 3.2636e-08210/450 [=============>................] - ETA: 1s - loss: 3.2621e-08240/450 [===============>..............] - ETA: 1s - loss: 3.2605e-08270/450 [=================>............] - ETA: 1s - loss: 3.2590e-08300/450 [===================>..........] - ETA: 1s - loss: 3.2574e-08330/450 [=====================>........] - ETA: 0s - loss: 3.2559e-08360/450 [=======================>......] - ETA: 0s - loss: 3.2544e-08390/450 [=========================>....] - ETA: 0s - loss: 3.2528e-08420/450 [===========================>..] - ETA: 0s - loss: 3.2513e-08450/450 [==============================] - 3s - loss: 3.2498e-08 - val_loss: 3.2254e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.2257e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.2243e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.2227e-08120/450 [=======>......................] - ETA: 2s - loss: 3.2211e-08150/450 [=========>....................] - ETA: 2s - loss: 3.2196e-08180/450 [===========>..................] - ETA: 2s - loss: 3.2181e-08210/450 [=============>................] - ETA: 1s - loss: 3.2166e-08240/450 [===============>..............] - ETA: 1s - loss: 3.2151e-08270/450 [=================>............] - ETA: 1s - loss: 3.2136e-08300/450 [===================>..........] - ETA: 1s - loss: 3.2121e-08330/450 [=====================>........] - ETA: 0s - loss: 3.2106e-08360/450 [=======================>......] - ETA: 0s - loss: 3.2091e-08390/450 [=========================>....] - ETA: 0s - loss: 3.2076e-08420/450 [===========================>..] - ETA: 0s - loss: 3.2061e-08450/450 [==============================] - 3s - loss: 3.2046e-08 - val_loss: 3.1806e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.1805e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.1789e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.1776e-08120/450 [=======>......................] - ETA: 2s - loss: 3.1762e-08150/450 [=========>....................] - ETA: 2s - loss: 3.1746e-08180/450 [===========>..................] - ETA: 2s - loss: 3.1732e-08210/450 [=============>................] - ETA: 1s - loss: 3.1718e-08240/450 [===============>..............] - ETA: 1s - loss: 3.1703e-08270/450 [=================>............] - ETA: 1s - loss: 3.1688e-08300/450 [===================>..........] - ETA: 1s - loss: 3.1673e-08330/450 [=====================>........] - ETA: 0s - loss: 3.1658e-08360/450 [=======================>......] - ETA: 0s - loss: 3.1644e-08390/450 [=========================>....] - ETA: 0s - loss: 3.1629e-08420/450 [===========================>..] - ETA: 0s - loss: 3.1614e-08450/450 [==============================] - 3s - loss: 3.1600e-08 - val_loss: 3.1366e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.1374e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.1355e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.1340e-08120/450 [=======>......................] - ETA: 2s - loss: 3.1326e-08150/450 [=========>....................] - ETA: 2s - loss: 3.1311e-08180/450 [===========>..................] - ETA: 2s - loss: 3.1296e-08210/450 [=============>................] - ETA: 1s - loss: 3.1281e-08240/450 [===============>..............] - ETA: 1s - loss: 3.1266e-08270/450 [=================>............] - ETA: 1s - loss: 3.1252e-08300/450 [===================>..........] - ETA: 1s - loss: 3.1237e-08330/450 [=====================>........] - ETA: 0s - loss: 3.1222e-08360/450 [=======================>......] - ETA: 0s - loss: 3.1208e-08390/450 [=========================>....] - ETA: 0s - loss: 3.1193e-08420/450 [===========================>..] - ETA: 0s - loss: 3.1179e-08450/450 [==============================] - 3s - loss: 3.1164e-08 - val_loss: 3.0936e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.0934e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.0921e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.0908e-08120/450 [=======>......................] - ETA: 2s - loss: 3.0894e-08150/450 [=========>....................] - ETA: 2s - loss: 3.0880e-08180/450 [===========>..................] - ETA: 2s - loss: 3.0865e-08210/450 [=============>................] - ETA: 1s - loss: 3.0851e-08240/450 [===============>..............] - ETA: 1s - loss: 3.0837e-08270/450 [=================>............] - ETA: 1s - loss: 3.0823e-08300/450 [===================>..........] - ETA: 1s - loss: 3.0808e-08330/450 [=====================>........] - ETA: 0s - loss: 3.0794e-08360/450 [=======================>......] - ETA: 0s - loss: 3.0781e-08390/450 [=========================>....] - ETA: 0s - loss: 3.0767e-08420/450 [===========================>..] - ETA: 0s - loss: 3.0752e-08450/450 [==============================] - 3s - loss: 3.0738e-08 - val_loss: 3.0502e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.0514e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.0493e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.0477e-08120/450 [=======>......................] - ETA: 2s - loss: 3.0465e-08150/450 [=========>....................] - ETA: 2s - loss: 3.0449e-08180/450 [===========>..................] - ETA: 2s - loss: 3.0433e-08210/450 [=============>................] - ETA: 1s - loss: 3.0420e-08240/450 [===============>..............] - ETA: 1s - loss: 3.0405e-08270/450 [=================>............] - ETA: 1s - loss: 3.0390e-08300/450 [===================>..........] - ETA: 1s - loss: 3.0378e-08330/450 [=====================>........] - ETA: 0s - loss: 3.0364e-08360/450 [=======================>......] - ETA: 0s - loss: 3.0349e-08390/450 [=========================>....] - ETA: 0s - loss: 3.0335e-08420/450 [===========================>..] - ETA: 0s - loss: 3.0321e-08450/450 [==============================] - 3s - loss: 3.0306e-08 - val_loss: 3.0078e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 3.0094e-08 60/450 [===>..........................] - ETA: 3s - loss: 3.0075e-08 90/450 [=====>........................] - ETA: 2s - loss: 3.0061e-08120/450 [=======>......................] - ETA: 2s - loss: 3.0048e-08150/450 [=========>....................] - ETA: 2s - loss: 3.0034e-08180/450 [===========>..................] - ETA: 2s - loss: 3.0020e-08210/450 [=============>................] - ETA: 1s - loss: 3.0006e-08240/450 [===============>..............] - ETA: 1s - loss: 2.9993e-08270/450 [=================>............] - ETA: 1s - loss: 2.9978e-08300/450 [===================>..........] - ETA: 1s - loss: 2.9964e-08330/450 [=====================>........] - ETA: 0s - loss: 2.9950e-08360/450 [=======================>......] - ETA: 0s - loss: 2.9937e-08390/450 [=========================>....] - ETA: 0s - loss: 2.9924e-08420/450 [===========================>..] - ETA: 0s - loss: 2.9910e-08450/450 [==============================] - 3s - loss: 2.9897e-08 - val_loss: 2.9682e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.9686e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.9672e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.9658e-08120/450 [=======>......................] - ETA: 2s - loss: 2.9645e-08150/450 [=========>....................] - ETA: 2s - loss: 2.9630e-08180/450 [===========>..................] - ETA: 2s - loss: 2.9617e-08210/450 [=============>................] - ETA: 1s - loss: 2.9603e-08240/450 [===============>..............] - ETA: 1s - loss: 2.9589e-08270/450 [=================>............] - ETA: 1s - loss: 2.9577e-08300/450 [===================>..........] - ETA: 1s - loss: 2.9564e-08330/450 [=====================>........] - ETA: 0s - loss: 2.9550e-08360/450 [=======================>......] - ETA: 0s - loss: 2.9537e-08390/450 [=========================>....] - ETA: 0s - loss: 2.9525e-08420/450 [===========================>..] - ETA: 0s - loss: 2.9511e-08450/450 [==============================] - 3s - loss: 2.9497e-08 - val_loss: 2.9279e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.9290e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.9261e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.9243e-08120/450 [=======>......................] - ETA: 2s - loss: 2.9227e-08150/450 [=========>....................] - ETA: 2s - loss: 2.9212e-08180/450 [===========>..................] - ETA: 2s - loss: 2.9197e-08210/450 [=============>................] - ETA: 1s - loss: 2.9184e-08240/450 [===============>..............] - ETA: 1s - loss: 2.9170e-08270/450 [=================>............] - ETA: 1s - loss: 2.9156e-08300/450 [===================>..........] - ETA: 1s - loss: 2.9142e-08330/450 [=====================>........] - ETA: 0s - loss: 2.9129e-08360/450 [=======================>......] - ETA: 0s - loss: 2.9115e-08390/450 [=========================>....] - ETA: 0s - loss: 2.9102e-08420/450 [===========================>..] - ETA: 0s - loss: 2.9088e-08450/450 [==============================] - 3s - loss: 2.9075e-08 - val_loss: 2.8863e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.8868e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.8857e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.8844e-08120/450 [=======>......................] - ETA: 2s - loss: 2.8830e-08150/450 [=========>....................] - ETA: 2s - loss: 2.8817e-08180/450 [===========>..................] - ETA: 2s - loss: 2.8804e-08210/450 [=============>................] - ETA: 1s - loss: 2.8791e-08240/450 [===============>..............] - ETA: 1s - loss: 2.8778e-08270/450 [=================>............] - ETA: 1s - loss: 2.8766e-08300/450 [===================>..........] - ETA: 1s - loss: 2.8753e-08330/450 [=====================>........] - ETA: 0s - loss: 2.8739e-08360/450 [=======================>......] - ETA: 0s - loss: 2.8726e-08390/450 [=========================>....] - ETA: 0s - loss: 2.8713e-08420/450 [===========================>..] - ETA: 0s - loss: 2.8699e-08450/450 [==============================] - 3s - loss: 2.8686e-08 - val_loss: 2.8476e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.8477e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.8464e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.8450e-08120/450 [=======>......................] - ETA: 2s - loss: 2.8437e-08150/450 [=========>....................] - ETA: 2s - loss: 2.8424e-08180/450 [===========>..................] - ETA: 2s - loss: 2.8411e-08210/450 [=============>................] - ETA: 1s - loss: 2.8398e-08240/450 [===============>..............] - ETA: 1s - loss: 2.8385e-08270/450 [=================>............] - ETA: 1s - loss: 2.8373e-08300/450 [===================>..........] - ETA: 1s - loss: 2.8360e-08330/450 [=====================>........] - ETA: 0s - loss: 2.8347e-08360/450 [=======================>......] - ETA: 0s - loss: 2.8334e-08390/450 [=========================>....] - ETA: 0s - loss: 2.8320e-08420/450 [===========================>..] - ETA: 0s - loss: 2.8308e-08450/450 [==============================] - 3s - loss: 2.8294e-08 - val_loss: 2.8075e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.8079e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.8066e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.8053e-08120/450 [=======>......................] - ETA: 2s - loss: 2.8040e-08150/450 [=========>....................] - ETA: 2s - loss: 2.8027e-08180/450 [===========>..................] - ETA: 2s - loss: 2.8015e-08210/450 [=============>................] - ETA: 1s - loss: 2.8003e-08240/450 [===============>..............] - ETA: 1s - loss: 2.7990e-08270/450 [=================>............] - ETA: 1s - loss: 2.7977e-08300/450 [===================>..........] - ETA: 1s - loss: 2.7964e-08330/450 [=====================>........] - ETA: 0s - loss: 2.7952e-08360/450 [=======================>......] - ETA: 0s - loss: 2.7939e-08390/450 [=========================>....] - ETA: 0s - loss: 2.7926e-08420/450 [===========================>..] - ETA: 0s - loss: 2.7913e-08450/450 [==============================] - 3s - loss: 2.7900e-08 - val_loss: 2.7705e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.7696e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.7681e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.7669e-08120/450 [=======>......................] - ETA: 2s - loss: 2.7657e-08150/450 [=========>....................] - ETA: 2s - loss: 2.7645e-08180/450 [===========>..................] - ETA: 2s - loss: 2.7632e-08210/450 [=============>................] - ETA: 1s - loss: 2.7619e-08240/450 [===============>..............] - ETA: 1s - loss: 2.7607e-08270/450 [=================>............] - ETA: 1s - loss: 2.7595e-08300/450 [===================>..........] - ETA: 1s - loss: 2.7582e-08330/450 [=====================>........] - ETA: 0s - loss: 2.7570e-08360/450 [=======================>......] - ETA: 0s - loss: 2.7557e-08390/450 [=========================>....] - ETA: 0s - loss: 2.7545e-08420/450 [===========================>..] - ETA: 0s - loss: 2.7533e-08450/450 [==============================] - 3s - loss: 2.7520e-08 - val_loss: 2.7316e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.7322e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.7308e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.7297e-08120/450 [=======>......................] - ETA: 2s - loss: 2.7284e-08150/450 [=========>....................] - ETA: 2s - loss: 2.7271e-08180/450 [===========>..................] - ETA: 2s - loss: 2.7259e-08210/450 [=============>................] - ETA: 1s - loss: 2.7247e-08240/450 [===============>..............] - ETA: 1s - loss: 2.7234e-08270/450 [=================>............] - ETA: 1s - loss: 2.7221e-08300/450 [===================>..........] - ETA: 1s - loss: 2.7209e-08330/450 [=====================>........] - ETA: 0s - loss: 2.7197e-08360/450 [=======================>......] - ETA: 0s - loss: 2.7185e-08390/450 [=========================>....] - ETA: 0s - loss: 2.7172e-08420/450 [===========================>..] - ETA: 0s - loss: 2.7160e-08450/450 [==============================] - 3s - loss: 2.7148e-08 - val_loss: 2.6950e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.6963e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.6949e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.6938e-08120/450 [=======>......................] - ETA: 2s - loss: 2.6926e-08150/450 [=========>....................] - ETA: 2s - loss: 2.6915e-08180/450 [===========>..................] - ETA: 2s - loss: 2.6904e-08210/450 [=============>................] - ETA: 1s - loss: 2.6891e-08240/450 [===============>..............] - ETA: 1s - loss: 2.6878e-08270/450 [=================>............] - ETA: 1s - loss: 2.6868e-08300/450 [===================>..........] - ETA: 1s - loss: 2.6856e-08330/450 [=====================>........] - ETA: 0s - loss: 2.6844e-08360/450 [=======================>......] - ETA: 0s - loss: 2.6834e-08390/450 [=========================>....] - ETA: 0s - loss: 2.6822e-08420/450 [===========================>..] - ETA: 0s - loss: 2.6810e-08450/450 [==============================] - 3s - loss: 2.6797e-08 - val_loss: 2.6604e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.6583e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.6571e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.6559e-08120/450 [=======>......................] - ETA: 2s - loss: 2.6547e-08150/450 [=========>....................] - ETA: 2s - loss: 2.6535e-08180/450 [===========>..................] - ETA: 2s - loss: 2.6523e-08210/450 [=============>................] - ETA: 1s - loss: 2.6510e-08240/450 [===============>..............] - ETA: 1s - loss: 2.6499e-08270/450 [=================>............] - ETA: 1s - loss: 2.6487e-08300/450 [===================>..........] - ETA: 1s - loss: 2.6475e-08330/450 [=====================>........] - ETA: 0s - loss: 2.6463e-08360/450 [=======================>......] - ETA: 0s - loss: 2.6452e-08390/450 [=========================>....] - ETA: 0s - loss: 2.6440e-08420/450 [===========================>..] - ETA: 0s - loss: 2.6428e-08450/450 [==============================] - 3s - loss: 2.6417e-08 - val_loss: 2.6227e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.6229e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.6217e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.6205e-08120/450 [=======>......................] - ETA: 2s - loss: 2.6194e-08150/450 [=========>....................] - ETA: 2s - loss: 2.6182e-08180/450 [===========>..................] - ETA: 2s - loss: 2.6170e-08210/450 [=============>................] - ETA: 1s - loss: 2.6158e-08240/450 [===============>..............] - ETA: 1s - loss: 2.6147e-08270/450 [=================>............] - ETA: 1s - loss: 2.6135e-08300/450 [===================>..........] - ETA: 1s - loss: 2.6123e-08330/450 [=====================>........] - ETA: 0s - loss: 2.6111e-08360/450 [=======================>......] - ETA: 0s - loss: 2.6100e-08390/450 [=========================>....] - ETA: 0s - loss: 2.6088e-08420/450 [===========================>..] - ETA: 0s - loss: 2.6076e-08450/450 [==============================] - 3s - loss: 2.6065e-08 - val_loss: 2.5879e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.5878e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.5872e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.5860e-08120/450 [=======>......................] - ETA: 2s - loss: 2.5848e-08150/450 [=========>....................] - ETA: 2s - loss: 2.5838e-08180/450 [===========>..................] - ETA: 2s - loss: 2.5825e-08210/450 [=============>................] - ETA: 1s - loss: 2.5814e-08240/450 [===============>..............] - ETA: 1s - loss: 2.5802e-08270/450 [=================>............] - ETA: 1s - loss: 2.5790e-08300/450 [===================>..........] - ETA: 1s - loss: 2.5779e-08330/450 [=====================>........] - ETA: 0s - loss: 2.5768e-08360/450 [=======================>......] - ETA: 0s - loss: 2.5756e-08390/450 [=========================>....] - ETA: 0s - loss: 2.5744e-08420/450 [===========================>..] - ETA: 0s - loss: 2.5733e-08450/450 [==============================] - 3s - loss: 2.5722e-08 - val_loss: 2.5538e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.5531e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.5520e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.5509e-08120/450 [=======>......................] - ETA: 2s - loss: 2.5498e-08150/450 [=========>....................] - ETA: 2s - loss: 2.5487e-08180/450 [===========>..................] - ETA: 2s - loss: 2.5476e-08210/450 [=============>................] - ETA: 1s - loss: 2.5465e-08240/450 [===============>..............] - ETA: 1s - loss: 2.5453e-08270/450 [=================>............] - ETA: 1s - loss: 2.5442e-08300/450 [===================>..........] - ETA: 1s - loss: 2.5430e-08330/450 [=====================>........] - ETA: 0s - loss: 2.5419e-08360/450 [=======================>......] - ETA: 0s - loss: 2.5407e-08390/450 [=========================>....] - ETA: 0s - loss: 2.5396e-08420/450 [===========================>..] - ETA: 0s - loss: 2.5385e-08450/450 [==============================] - 3s - loss: 2.5374e-08 - val_loss: 2.5189e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.5193e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.5180e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.5169e-08120/450 [=======>......................] - ETA: 2s - loss: 2.5157e-08150/450 [=========>....................] - ETA: 2s - loss: 2.5146e-08180/450 [===========>..................] - ETA: 2s - loss: 2.5135e-08210/450 [=============>................] - ETA: 1s - loss: 2.5124e-08240/450 [===============>..............] - ETA: 1s - loss: 2.5113e-08270/450 [=================>............] - ETA: 1s - loss: 2.5101e-08300/450 [===================>..........] - ETA: 1s - loss: 2.5090e-08330/450 [=====================>........] - ETA: 0s - loss: 2.5079e-08360/450 [=======================>......] - ETA: 0s - loss: 2.5068e-08390/450 [=========================>....] - ETA: 0s - loss: 2.5057e-08420/450 [===========================>..] - ETA: 0s - loss: 2.5047e-08450/450 [==============================] - 3s - loss: 2.5035e-08 - val_loss: 2.4853e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.4854e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.4843e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.4833e-08120/450 [=======>......................] - ETA: 2s - loss: 2.4822e-08150/450 [=========>....................] - ETA: 2s - loss: 2.4811e-08180/450 [===========>..................] - ETA: 2s - loss: 2.4800e-08210/450 [=============>................] - ETA: 1s - loss: 2.4789e-08240/450 [===============>..............] - ETA: 1s - loss: 2.4778e-08270/450 [=================>............] - ETA: 1s - loss: 2.4767e-08300/450 [===================>..........] - ETA: 1s - loss: 2.4756e-08330/450 [=====================>........] - ETA: 0s - loss: 2.4745e-08360/450 [=======================>......] - ETA: 0s - loss: 2.4734e-08390/450 [=========================>....] - ETA: 0s - loss: 2.4723e-08420/450 [===========================>..] - ETA: 0s - loss: 2.4712e-08450/450 [==============================] - 3s - loss: 2.4701e-08 - val_loss: 2.4536e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.4541e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.4528e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.4516e-08120/450 [=======>......................] - ETA: 2s - loss: 2.4505e-08150/450 [=========>....................] - ETA: 2s - loss: 2.4495e-08180/450 [===========>..................] - ETA: 2s - loss: 2.4483e-08210/450 [=============>................] - ETA: 1s - loss: 2.4472e-08240/450 [===============>..............] - ETA: 1s - loss: 2.4461e-08270/450 [=================>............] - ETA: 1s - loss: 2.4451e-08300/450 [===================>..........] - ETA: 1s - loss: 2.4440e-08330/450 [=====================>........] - ETA: 0s - loss: 2.4429e-08360/450 [=======================>......] - ETA: 0s - loss: 2.4418e-08390/450 [=========================>....] - ETA: 0s - loss: 2.4407e-08420/450 [===========================>..] - ETA: 0s - loss: 2.4397e-08450/450 [==============================] - 3s - loss: 2.4386e-08 - val_loss: 2.4201e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.4201e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.4192e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.4181e-08120/450 [=======>......................] - ETA: 2s - loss: 2.4171e-08150/450 [=========>....................] - ETA: 2s - loss: 2.4160e-08180/450 [===========>..................] - ETA: 2s - loss: 2.4150e-08210/450 [=============>................] - ETA: 1s - loss: 2.4139e-08240/450 [===============>..............] - ETA: 1s - loss: 2.4128e-08270/450 [=================>............] - ETA: 1s - loss: 2.4117e-08300/450 [===================>..........] - ETA: 1s - loss: 2.4106e-08330/450 [=====================>........] - ETA: 0s - loss: 2.4096e-08360/450 [=======================>......] - ETA: 0s - loss: 2.4085e-08390/450 [=========================>....] - ETA: 0s - loss: 2.4075e-08420/450 [===========================>..] - ETA: 0s - loss: 2.4064e-08450/450 [==============================] - 3s - loss: 2.4053e-08 - val_loss: 2.3884e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.3899e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.4136e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.4043e-08120/450 [=======>......................] - ETA: 2s - loss: 2.3992e-08150/450 [=========>....................] - ETA: 2s - loss: 2.3956e-08180/450 [===========>..................] - ETA: 2s - loss: 2.3929e-08210/450 [=============>................] - ETA: 1s - loss: 2.3940e-08240/450 [===============>..............] - ETA: 1s - loss: 2.3917e-08270/450 [=================>............] - ETA: 1s - loss: 2.4168e-08300/450 [===================>..........] - ETA: 1s - loss: 2.4140e-08330/450 [=====================>........] - ETA: 0s - loss: 2.4120e-08360/450 [=======================>......] - ETA: 0s - loss: 2.4175e-08390/450 [=========================>....] - ETA: 0s - loss: 2.4163e-08420/450 [===========================>..] - ETA: 0s - loss: 2.4125e-08450/450 [==============================] - 3s - loss: 2.4127e-08 - val_loss: 2.3596e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.3594e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.3594e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.3580e-08120/450 [=======>......................] - ETA: 2s - loss: 2.3570e-08150/450 [=========>....................] - ETA: 2s - loss: 2.3558e-08180/450 [===========>..................] - ETA: 2s - loss: 2.3547e-08210/450 [=============>................] - ETA: 1s - loss: 2.3535e-08240/450 [===============>..............] - ETA: 1s - loss: 2.3525e-08270/450 [=================>............] - ETA: 1s - loss: 2.3515e-08300/450 [===================>..........] - ETA: 1s - loss: 2.3504e-08330/450 [=====================>........] - ETA: 0s - loss: 2.3493e-08360/450 [=======================>......] - ETA: 0s - loss: 2.3483e-08390/450 [=========================>....] - ETA: 0s - loss: 2.3472e-08420/450 [===========================>..] - ETA: 0s - loss: 2.3462e-08450/450 [==============================] - 3s - loss: 2.3452e-08 - val_loss: 2.3285e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.3279e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.3269e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.3260e-08120/450 [=======>......................] - ETA: 2s - loss: 2.3250e-08150/450 [=========>....................] - ETA: 2s - loss: 2.3240e-08180/450 [===========>..................] - ETA: 2s - loss: 2.3230e-08210/450 [=============>................] - ETA: 1s - loss: 2.3220e-08240/450 [===============>..............] - ETA: 1s - loss: 2.3210e-08270/450 [=================>............] - ETA: 1s - loss: 2.3199e-08300/450 [===================>..........] - ETA: 1s - loss: 2.3189e-08330/450 [=====================>........] - ETA: 0s - loss: 2.3180e-08360/450 [=======================>......] - ETA: 0s - loss: 2.3169e-08390/450 [=========================>....] - ETA: 0s - loss: 2.3159e-08420/450 [===========================>..] - ETA: 0s - loss: 2.3149e-08450/450 [==============================] - 3s - loss: 2.3139e-08 - val_loss: 2.2977e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2986e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.2985e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.2974e-08120/450 [=======>......................] - ETA: 2s - loss: 2.2968e-08150/450 [=========>....................] - ETA: 2s - loss: 2.2957e-08180/450 [===========>..................] - ETA: 2s - loss: 2.2946e-08210/450 [=============>................] - ETA: 1s - loss: 2.2936e-08240/450 [===============>..............] - ETA: 1s - loss: 2.2925e-08270/450 [=================>............] - ETA: 1s - loss: 2.2915e-08300/450 [===================>..........] - ETA: 1s - loss: 2.2905e-08330/450 [=====================>........] - ETA: 0s - loss: 2.2896e-08360/450 [=======================>......] - ETA: 0s - loss: 2.2885e-08390/450 [=========================>....] - ETA: 0s - loss: 2.2875e-08420/450 [===========================>..] - ETA: 0s - loss: 2.2865e-08450/450 [==============================] - 3s - loss: 2.2855e-08 - val_loss: 2.2701e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2695e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.2684e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.2679e-08120/450 [=======>......................] - ETA: 2s - loss: 2.2667e-08150/450 [=========>....................] - ETA: 2s - loss: 2.2658e-08180/450 [===========>..................] - ETA: 2s - loss: 2.2647e-08210/450 [=============>................] - ETA: 1s - loss: 2.2637e-08240/450 [===============>..............] - ETA: 1s - loss: 2.2627e-08270/450 [=================>............] - ETA: 1s - loss: 2.2617e-08300/450 [===================>..........] - ETA: 1s - loss: 2.2608e-08330/450 [=====================>........] - ETA: 0s - loss: 2.2598e-08360/450 [=======================>......] - ETA: 0s - loss: 2.2590e-08390/450 [=========================>....] - ETA: 0s - loss: 2.2580e-08420/450 [===========================>..] - ETA: 0s - loss: 2.2570e-08450/450 [==============================] - 3s - loss: 2.2560e-08 - val_loss: 2.2411e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2400e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.2387e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.2377e-08120/450 [=======>......................] - ETA: 2s - loss: 2.2366e-08150/450 [=========>....................] - ETA: 2s - loss: 2.2356e-08180/450 [===========>..................] - ETA: 2s - loss: 2.2346e-08210/450 [=============>................] - ETA: 1s - loss: 2.2336e-08240/450 [===============>..............] - ETA: 1s - loss: 2.2328e-08270/450 [=================>............] - ETA: 1s - loss: 2.2318e-08300/450 [===================>..........] - ETA: 1s - loss: 2.2307e-08330/450 [=====================>........] - ETA: 0s - loss: 2.2298e-08360/450 [=======================>......] - ETA: 0s - loss: 2.2288e-08390/450 [=========================>....] - ETA: 0s - loss: 2.2277e-08420/450 [===========================>..] - ETA: 0s - loss: 2.2267e-08450/450 [==============================] - 3s - loss: 2.2265e-08 - val_loss: 2.2094e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.2090e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.2080e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.2070e-08120/450 [=======>......................] - ETA: 2s - loss: 2.2061e-08150/450 [=========>....................] - ETA: 2s - loss: 2.2051e-08180/450 [===========>..................] - ETA: 2s - loss: 2.2042e-08210/450 [=============>................] - ETA: 1s - loss: 2.2032e-08240/450 [===============>..............] - ETA: 1s - loss: 2.2023e-08270/450 [=================>............] - ETA: 1s - loss: 2.2014e-08300/450 [===================>..........] - ETA: 1s - loss: 2.2004e-08330/450 [=====================>........] - ETA: 0s - loss: 2.1995e-08360/450 [=======================>......] - ETA: 0s - loss: 2.1985e-08390/450 [=========================>....] - ETA: 0s - loss: 2.1976e-08420/450 [===========================>..] - ETA: 0s - loss: 2.1966e-08450/450 [==============================] - 3s - loss: 2.1957e-08 - val_loss: 2.1798e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.1792e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.1783e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.1775e-08120/450 [=======>......................] - ETA: 2s - loss: 2.1766e-08150/450 [=========>....................] - ETA: 2s - loss: 2.1758e-08180/450 [===========>..................] - ETA: 2s - loss: 2.1748e-08210/450 [=============>................] - ETA: 1s - loss: 2.1738e-08240/450 [===============>..............] - ETA: 1s - loss: 2.1728e-08270/450 [=================>............] - ETA: 1s - loss: 2.1719e-08300/450 [===================>..........] - ETA: 1s - loss: 2.1710e-08330/450 [=====================>........] - ETA: 0s - loss: 2.1700e-08360/450 [=======================>......] - ETA: 0s - loss: 2.1691e-08390/450 [=========================>....] - ETA: 0s - loss: 2.1681e-08420/450 [===========================>..] - ETA: 0s - loss: 2.1672e-08450/450 [==============================] - 3s - loss: 2.1663e-08 - val_loss: 2.1516e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.1515e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.1507e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.1497e-08120/450 [=======>......................] - ETA: 2s - loss: 2.1487e-08150/450 [=========>....................] - ETA: 2s - loss: 2.1478e-08180/450 [===========>..................] - ETA: 2s - loss: 2.1469e-08210/450 [=============>................] - ETA: 1s - loss: 2.1459e-08240/450 [===============>..............] - ETA: 1s - loss: 2.1450e-08270/450 [=================>............] - ETA: 1s - loss: 2.1441e-08300/450 [===================>..........] - ETA: 1s - loss: 2.1432e-08330/450 [=====================>........] - ETA: 0s - loss: 2.1423e-08360/450 [=======================>......] - ETA: 0s - loss: 2.1413e-08390/450 [=========================>....] - ETA: 0s - loss: 2.1404e-08420/450 [===========================>..] - ETA: 0s - loss: 2.1395e-08450/450 [==============================] - 3s - loss: 2.1386e-08 - val_loss: 2.1236e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.1235e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.1226e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.1218e-08120/450 [=======>......................] - ETA: 2s - loss: 2.1209e-08150/450 [=========>....................] - ETA: 2s - loss: 2.1200e-08180/450 [===========>..................] - ETA: 2s - loss: 2.1190e-08210/450 [=============>................] - ETA: 1s - loss: 2.1182e-08240/450 [===============>..............] - ETA: 1s - loss: 2.1173e-08270/450 [=================>............] - ETA: 1s - loss: 2.1163e-08300/450 [===================>..........] - ETA: 1s - loss: 2.1155e-08330/450 [=====================>........] - ETA: 0s - loss: 2.1145e-08360/450 [=======================>......] - ETA: 0s - loss: 2.1136e-08390/450 [=========================>....] - ETA: 0s - loss: 2.1127e-08420/450 [===========================>..] - ETA: 0s - loss: 2.1119e-08450/450 [==============================] - 3s - loss: 2.1109e-08 - val_loss: 2.1000e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.1005e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.0995e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.0984e-08120/450 [=======>......................] - ETA: 2s - loss: 2.0975e-08150/450 [=========>....................] - ETA: 2s - loss: 2.0965e-08180/450 [===========>..................] - ETA: 2s - loss: 2.0956e-08210/450 [=============>................] - ETA: 1s - loss: 2.0949e-08240/450 [===============>..............] - ETA: 1s - loss: 2.0940e-08270/450 [=================>............] - ETA: 1s - loss: 2.0932e-08300/450 [===================>..........] - ETA: 1s - loss: 2.0924e-08330/450 [=====================>........] - ETA: 0s - loss: 2.0914e-08360/450 [=======================>......] - ETA: 0s - loss: 2.0905e-08390/450 [=========================>....] - ETA: 0s - loss: 2.0896e-08420/450 [===========================>..] - ETA: 0s - loss: 2.0887e-08450/450 [==============================] - 3s - loss: 2.0878e-08 - val_loss: 2.0717e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0706e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.0698e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.0690e-08120/450 [=======>......................] - ETA: 2s - loss: 2.0680e-08150/450 [=========>....................] - ETA: 2s - loss: 2.0672e-08180/450 [===========>..................] - ETA: 2s - loss: 2.0662e-08210/450 [=============>................] - ETA: 1s - loss: 2.0653e-08240/450 [===============>..............] - ETA: 1s - loss: 2.0645e-08270/450 [=================>............] - ETA: 1s - loss: 2.0636e-08300/450 [===================>..........] - ETA: 1s - loss: 2.0628e-08330/450 [=====================>........] - ETA: 0s - loss: 2.0619e-08360/450 [=======================>......] - ETA: 0s - loss: 2.0610e-08390/450 [=========================>....] - ETA: 0s - loss: 2.0601e-08420/450 [===========================>..] - ETA: 0s - loss: 2.0592e-08450/450 [==============================] - 3s - loss: 2.0583e-08 - val_loss: 2.0434e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0471e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.0461e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.0452e-08120/450 [=======>......................] - ETA: 2s - loss: 2.0445e-08150/450 [=========>....................] - ETA: 2s - loss: 2.0435e-08180/450 [===========>..................] - ETA: 2s - loss: 2.0427e-08210/450 [=============>................] - ETA: 1s - loss: 2.0417e-08240/450 [===============>..............] - ETA: 1s - loss: 2.0408e-08270/450 [=================>............] - ETA: 1s - loss: 2.0399e-08300/450 [===================>..........] - ETA: 1s - loss: 2.0392e-08330/450 [=====================>........] - ETA: 0s - loss: 2.0384e-08360/450 [=======================>......] - ETA: 0s - loss: 2.0376e-08390/450 [=========================>....] - ETA: 0s - loss: 2.0367e-08420/450 [===========================>..] - ETA: 0s - loss: 2.0359e-08450/450 [==============================] - 3s - loss: 2.0350e-08 - val_loss: 2.0250e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0242e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.0223e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.0220e-08120/450 [=======>......................] - ETA: 2s - loss: 2.0212e-08150/450 [=========>....................] - ETA: 2s - loss: 2.0203e-08180/450 [===========>..................] - ETA: 2s - loss: 2.0194e-08210/450 [=============>................] - ETA: 1s - loss: 2.0186e-08240/450 [===============>..............] - ETA: 1s - loss: 2.0177e-08270/450 [=================>............] - ETA: 1s - loss: 2.0168e-08300/450 [===================>..........] - ETA: 1s - loss: 2.0160e-08330/450 [=====================>........] - ETA: 0s - loss: 2.0152e-08360/450 [=======================>......] - ETA: 0s - loss: 2.0144e-08390/450 [=========================>....] - ETA: 0s - loss: 2.0136e-08420/450 [===========================>..] - ETA: 0s - loss: 2.0127e-08450/450 [==============================] - 3s - loss: 2.0118e-08 - val_loss: 1.9908e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9911e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.9904e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.9896e-08120/450 [=======>......................] - ETA: 2s - loss: 1.9890e-08150/450 [=========>....................] - ETA: 2s - loss: 1.9881e-08180/450 [===========>..................] - ETA: 2s - loss: 1.9872e-08210/450 [=============>................] - ETA: 1s - loss: 1.9863e-08240/450 [===============>..............] - ETA: 1s - loss: 1.9855e-08270/450 [=================>............] - ETA: 1s - loss: 1.9846e-08300/450 [===================>..........] - ETA: 1s - loss: 1.9838e-08330/450 [=====================>........] - ETA: 0s - loss: 1.9829e-08360/450 [=======================>......] - ETA: 0s - loss: 1.9821e-08390/450 [=========================>....] - ETA: 0s - loss: 1.9813e-08420/450 [===========================>..] - ETA: 0s - loss: 1.9804e-08450/450 [==============================] - 3s - loss: 1.9796e-08 - val_loss: 1.9660e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 2.0778e-08 60/450 [===>..........................] - ETA: 3s - loss: 2.0215e-08 90/450 [=====>........................] - ETA: 2s - loss: 2.0108e-08120/450 [=======>......................] - ETA: 2s - loss: 2.0146e-08150/450 [=========>....................] - ETA: 2s - loss: 2.0038e-08180/450 [===========>..................] - ETA: 2s - loss: 2.0013e-08210/450 [=============>................] - ETA: 1s - loss: 1.9950e-08240/450 [===============>..............] - ETA: 1s - loss: 2.0098e-08270/450 [=================>............] - ETA: 1s - loss: 2.0036e-08300/450 [===================>..........] - ETA: 1s - loss: 2.0078e-08330/450 [=====================>........] - ETA: 0s - loss: 2.0098e-08360/450 [=======================>......] - ETA: 0s - loss: 2.0103e-08390/450 [=========================>....] - ETA: 0s - loss: 2.0072e-08420/450 [===========================>..] - ETA: 0s - loss: 2.0028e-08450/450 [==============================] - 3s - loss: 2.0020e-08 - val_loss: 1.9408e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9411e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.9401e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.9393e-08120/450 [=======>......................] - ETA: 2s - loss: 1.9413e-08150/450 [=========>....................] - ETA: 2s - loss: 1.9399e-08180/450 [===========>..................] - ETA: 2s - loss: 1.9387e-08210/450 [=============>................] - ETA: 1s - loss: 1.9376e-08240/450 [===============>..............] - ETA: 1s - loss: 1.9454e-08270/450 [=================>............] - ETA: 1s - loss: 1.9434e-08300/450 [===================>..........] - ETA: 1s - loss: 1.9458e-08330/450 [=====================>........] - ETA: 0s - loss: 1.9439e-08360/450 [=======================>......] - ETA: 0s - loss: 1.9421e-08390/450 [=========================>....] - ETA: 0s - loss: 1.9405e-08420/450 [===========================>..] - ETA: 0s - loss: 1.9390e-08450/450 [==============================] - 3s - loss: 1.9377e-08 - val_loss: 1.9582e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.9178e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.9170e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.9161e-08120/450 [=======>......................] - ETA: 2s - loss: 1.9152e-08150/450 [=========>....................] - ETA: 2s - loss: 1.9143e-08180/450 [===========>..................] - ETA: 2s - loss: 1.9135e-08210/450 [=============>................] - ETA: 1s - loss: 1.9126e-08240/450 [===============>..............] - ETA: 1s - loss: 1.9119e-08270/450 [=================>............] - ETA: 1s - loss: 1.9111e-08300/450 [===================>..........] - ETA: 1s - loss: 1.9103e-08330/450 [=====================>........] - ETA: 0s - loss: 1.9095e-08360/450 [=======================>......] - ETA: 0s - loss: 1.9087e-08390/450 [=========================>....] - ETA: 0s - loss: 1.9079e-08420/450 [===========================>..] - ETA: 0s - loss: 1.9071e-08450/450 [==============================] - 3s - loss: 1.9063e-08 - val_loss: 1.8930e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8931e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.8923e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.8916e-08120/450 [=======>......................] - ETA: 2s - loss: 1.8908e-08150/450 [=========>....................] - ETA: 2s - loss: 1.8900e-08180/450 [===========>..................] - ETA: 2s - loss: 1.8892e-08210/450 [=============>................] - ETA: 1s - loss: 1.8884e-08240/450 [===============>..............] - ETA: 1s - loss: 1.8876e-08270/450 [=================>............] - ETA: 1s - loss: 1.8868e-08300/450 [===================>..........] - ETA: 1s - loss: 1.8860e-08330/450 [=====================>........] - ETA: 0s - loss: 1.8852e-08360/450 [=======================>......] - ETA: 0s - loss: 1.8844e-08390/450 [=========================>....] - ETA: 0s - loss: 1.8836e-08420/450 [===========================>..] - ETA: 0s - loss: 1.8828e-08450/450 [==============================] - 3s - loss: 1.8820e-08 - val_loss: 1.8686e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8689e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.8680e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.8672e-08120/450 [=======>......................] - ETA: 2s - loss: 1.8664e-08150/450 [=========>....................] - ETA: 2s - loss: 1.8657e-08180/450 [===========>..................] - ETA: 2s - loss: 1.8649e-08210/450 [=============>................] - ETA: 1s - loss: 1.8642e-08240/450 [===============>..............] - ETA: 1s - loss: 1.8634e-08270/450 [=================>............] - ETA: 1s - loss: 1.8626e-08300/450 [===================>..........] - ETA: 1s - loss: 1.8619e-08330/450 [=====================>........] - ETA: 0s - loss: 1.8611e-08360/450 [=======================>......] - ETA: 0s - loss: 1.8603e-08390/450 [=========================>....] - ETA: 0s - loss: 1.8595e-08420/450 [===========================>..] - ETA: 0s - loss: 1.8587e-08450/450 [==============================] - 3s - loss: 1.8579e-08 - val_loss: 1.8455e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8467e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.8459e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.8451e-08120/450 [=======>......................] - ETA: 2s - loss: 1.8443e-08150/450 [=========>....................] - ETA: 2s - loss: 1.8434e-08180/450 [===========>..................] - ETA: 2s - loss: 1.8426e-08210/450 [=============>................] - ETA: 1s - loss: 1.8420e-08240/450 [===============>..............] - ETA: 1s - loss: 1.8412e-08270/450 [=================>............] - ETA: 1s - loss: 1.8404e-08300/450 [===================>..........] - ETA: 1s - loss: 1.8396e-08330/450 [=====================>........] - ETA: 0s - loss: 1.8389e-08360/450 [=======================>......] - ETA: 0s - loss: 1.8381e-08390/450 [=========================>....] - ETA: 0s - loss: 1.8373e-08420/450 [===========================>..] - ETA: 0s - loss: 1.8365e-08450/450 [==============================] - 3s - loss: 1.8358e-08 - val_loss: 1.8239e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8242e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.8234e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.8226e-08120/450 [=======>......................] - ETA: 2s - loss: 1.8218e-08150/450 [=========>....................] - ETA: 2s - loss: 1.8211e-08180/450 [===========>..................] - ETA: 2s - loss: 1.8202e-08210/450 [=============>................] - ETA: 1s - loss: 1.8195e-08240/450 [===============>..............] - ETA: 1s - loss: 1.8187e-08270/450 [=================>............] - ETA: 1s - loss: 1.8179e-08300/450 [===================>..........] - ETA: 1s - loss: 1.8172e-08330/450 [=====================>........] - ETA: 0s - loss: 1.8164e-08360/450 [=======================>......] - ETA: 0s - loss: 1.8157e-08390/450 [=========================>....] - ETA: 0s - loss: 1.8149e-08420/450 [===========================>..] - ETA: 0s - loss: 1.8142e-08450/450 [==============================] - 3s - loss: 1.8134e-08 - val_loss: 1.8022e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.8009e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.8003e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.7990e-08120/450 [=======>......................] - ETA: 2s - loss: 1.7981e-08150/450 [=========>....................] - ETA: 2s - loss: 1.7972e-08180/450 [===========>..................] - ETA: 2s - loss: 1.7965e-08210/450 [=============>................] - ETA: 1s - loss: 1.7957e-08240/450 [===============>..............] - ETA: 1s - loss: 1.7949e-08270/450 [=================>............] - ETA: 1s - loss: 1.7941e-08300/450 [===================>..........] - ETA: 1s - loss: 1.7934e-08330/450 [=====================>........] - ETA: 0s - loss: 1.7927e-08360/450 [=======================>......] - ETA: 0s - loss: 1.7918e-08390/450 [=========================>....] - ETA: 0s - loss: 1.7911e-08420/450 [===========================>..] - ETA: 0s - loss: 1.7903e-08450/450 [==============================] - 3s - loss: 1.7896e-08 - val_loss: 1.7775e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7775e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.7769e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.7761e-08120/450 [=======>......................] - ETA: 2s - loss: 1.7753e-08150/450 [=========>....................] - ETA: 2s - loss: 1.7746e-08180/450 [===========>..................] - ETA: 2s - loss: 1.7738e-08210/450 [=============>................] - ETA: 1s - loss: 1.7731e-08240/450 [===============>..............] - ETA: 1s - loss: 1.7723e-08270/450 [=================>............] - ETA: 1s - loss: 1.7716e-08300/450 [===================>..........] - ETA: 1s - loss: 1.7709e-08330/450 [=====================>........] - ETA: 0s - loss: 1.7701e-08360/450 [=======================>......] - ETA: 0s - loss: 1.7694e-08390/450 [=========================>....] - ETA: 0s - loss: 1.7687e-08420/450 [===========================>..] - ETA: 0s - loss: 1.7679e-08450/450 [==============================] - 3s - loss: 1.7672e-08 - val_loss: 1.7546e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7547e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.7541e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.7533e-08120/450 [=======>......................] - ETA: 2s - loss: 1.7526e-08150/450 [=========>....................] - ETA: 2s - loss: 1.7520e-08180/450 [===========>..................] - ETA: 2s - loss: 1.7514e-08210/450 [=============>................] - ETA: 1s - loss: 1.7506e-08240/450 [===============>..............] - ETA: 1s - loss: 1.7499e-08270/450 [=================>............] - ETA: 1s - loss: 1.7491e-08300/450 [===================>..........] - ETA: 1s - loss: 1.7483e-08330/450 [=====================>........] - ETA: 0s - loss: 1.7476e-08360/450 [=======================>......] - ETA: 0s - loss: 1.7469e-08390/450 [=========================>....] - ETA: 0s - loss: 1.7461e-08420/450 [===========================>..] - ETA: 0s - loss: 1.7454e-08450/450 [==============================] - 3s - loss: 1.7447e-08 - val_loss: 1.7330e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7334e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.7325e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.7318e-08120/450 [=======>......................] - ETA: 2s - loss: 1.7310e-08150/450 [=========>....................] - ETA: 2s - loss: 1.7336e-08180/450 [===========>..................] - ETA: 2s - loss: 1.7324e-08210/450 [=============>................] - ETA: 1s - loss: 1.7313e-08240/450 [===============>..............] - ETA: 1s - loss: 1.7303e-08270/450 [=================>............] - ETA: 1s - loss: 1.7294e-08300/450 [===================>..........] - ETA: 1s - loss: 1.7285e-08330/450 [=====================>........] - ETA: 0s - loss: 1.7276e-08360/450 [=======================>......] - ETA: 0s - loss: 1.7268e-08390/450 [=========================>....] - ETA: 0s - loss: 1.7259e-08420/450 [===========================>..] - ETA: 0s - loss: 1.7251e-08450/450 [==============================] - 3s - loss: 1.7243e-08 - val_loss: 1.7118e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.7905e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.7501e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.7627e-08120/450 [=======>......................] - ETA: 2s - loss: 1.7488e-08150/450 [=========>....................] - ETA: 2s - loss: 1.7495e-08180/450 [===========>..................] - ETA: 2s - loss: 1.7568e-08210/450 [=============>................] - ETA: 1s - loss: 1.7493e-08240/450 [===============>..............] - ETA: 1s - loss: 1.7495e-08270/450 [=================>............] - ETA: 1s - loss: 1.7486e-08300/450 [===================>..........] - ETA: 1s - loss: 1.7437e-08330/450 [=====================>........] - ETA: 0s - loss: 1.7447e-08360/450 [=======================>......] - ETA: 0s - loss: 1.7406e-08390/450 [=========================>....] - ETA: 0s - loss: 1.7390e-08420/450 [===========================>..] - ETA: 0s - loss: 1.7358e-08450/450 [==============================] - 3s - loss: 1.7359e-08 - val_loss: 1.6901e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6903e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.6896e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.6889e-08120/450 [=======>......................] - ETA: 2s - loss: 1.6883e-08150/450 [=========>....................] - ETA: 2s - loss: 1.6875e-08180/450 [===========>..................] - ETA: 2s - loss: 1.6868e-08210/450 [=============>................] - ETA: 1s - loss: 1.6862e-08240/450 [===============>..............] - ETA: 1s - loss: 1.6856e-08270/450 [=================>............] - ETA: 1s - loss: 1.6849e-08300/450 [===================>..........] - ETA: 1s - loss: 1.6842e-08330/450 [=====================>........] - ETA: 0s - loss: 1.6835e-08360/450 [=======================>......] - ETA: 0s - loss: 1.6827e-08390/450 [=========================>....] - ETA: 0s - loss: 1.6820e-08420/450 [===========================>..] - ETA: 0s - loss: 1.6813e-08450/450 [==============================] - 3s - loss: 1.6806e-08 - val_loss: 1.6699e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6699e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.6691e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.6685e-08120/450 [=======>......................] - ETA: 2s - loss: 1.6678e-08150/450 [=========>....................] - ETA: 2s - loss: 1.6672e-08180/450 [===========>..................] - ETA: 2s - loss: 1.6665e-08210/450 [=============>................] - ETA: 1s - loss: 1.6658e-08240/450 [===============>..............] - ETA: 1s - loss: 1.6651e-08270/450 [=================>............] - ETA: 1s - loss: 1.6644e-08300/450 [===================>..........] - ETA: 1s - loss: 1.6638e-08330/450 [=====================>........] - ETA: 0s - loss: 1.6631e-08360/450 [=======================>......] - ETA: 0s - loss: 1.6624e-08390/450 [=========================>....] - ETA: 0s - loss: 1.6617e-08420/450 [===========================>..] - ETA: 0s - loss: 1.6610e-08450/450 [==============================] - 3s - loss: 1.6603e-08 - val_loss: 1.6497e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6493e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.6485e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.6480e-08120/450 [=======>......................] - ETA: 2s - loss: 1.6472e-08150/450 [=========>....................] - ETA: 2s - loss: 1.6465e-08180/450 [===========>..................] - ETA: 2s - loss: 1.6458e-08210/450 [=============>................] - ETA: 1s - loss: 1.6450e-08240/450 [===============>..............] - ETA: 1s - loss: 1.6444e-08270/450 [=================>............] - ETA: 1s - loss: 1.6437e-08300/450 [===================>..........] - ETA: 1s - loss: 1.6430e-08330/450 [=====================>........] - ETA: 0s - loss: 1.6423e-08360/450 [=======================>......] - ETA: 0s - loss: 1.6417e-08390/450 [=========================>....] - ETA: 0s - loss: 1.6410e-08420/450 [===========================>..] - ETA: 0s - loss: 1.6403e-08450/450 [==============================] - 3s - loss: 1.6397e-08 - val_loss: 1.6288e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6301e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.6297e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.6289e-08120/450 [=======>......................] - ETA: 2s - loss: 1.6282e-08150/450 [=========>....................] - ETA: 2s - loss: 1.6277e-08180/450 [===========>..................] - ETA: 2s - loss: 1.6271e-08210/450 [=============>................] - ETA: 1s - loss: 1.6264e-08240/450 [===============>..............] - ETA: 1s - loss: 1.6258e-08270/450 [=================>............] - ETA: 1s - loss: 1.6251e-08300/450 [===================>..........] - ETA: 1s - loss: 1.6244e-08330/450 [=====================>........] - ETA: 0s - loss: 1.6237e-08360/450 [=======================>......] - ETA: 0s - loss: 1.6231e-08390/450 [=========================>....] - ETA: 0s - loss: 1.6224e-08420/450 [===========================>..] - ETA: 0s - loss: 1.6217e-08450/450 [==============================] - 3s - loss: 1.6211e-08 - val_loss: 1.6116e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.6091e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.6082e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.6076e-08120/450 [=======>......................] - ETA: 2s - loss: 1.6069e-08150/450 [=========>....................] - ETA: 2s - loss: 1.6062e-08180/450 [===========>..................] - ETA: 2s - loss: 1.6056e-08210/450 [=============>................] - ETA: 1s - loss: 1.6049e-08240/450 [===============>..............] - ETA: 1s - loss: 1.6042e-08270/450 [=================>............] - ETA: 1s - loss: 1.6036e-08300/450 [===================>..........] - ETA: 1s - loss: 1.6029e-08330/450 [=====================>........] - ETA: 0s - loss: 1.6023e-08360/450 [=======================>......] - ETA: 0s - loss: 1.6016e-08390/450 [=========================>....] - ETA: 0s - loss: 1.6010e-08420/450 [===========================>..] - ETA: 0s - loss: 1.6003e-08450/450 [==============================] - 3s - loss: 1.5996e-08 - val_loss: 1.5892e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5891e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.5886e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.5879e-08120/450 [=======>......................] - ETA: 2s - loss: 1.5873e-08150/450 [=========>....................] - ETA: 2s - loss: 1.5867e-08180/450 [===========>..................] - ETA: 2s - loss: 1.5860e-08210/450 [=============>................] - ETA: 1s - loss: 1.5854e-08240/450 [===============>..............] - ETA: 1s - loss: 1.5848e-08270/450 [=================>............] - ETA: 1s - loss: 1.5841e-08300/450 [===================>..........] - ETA: 1s - loss: 1.5835e-08330/450 [=====================>........] - ETA: 0s - loss: 1.5829e-08360/450 [=======================>......] - ETA: 0s - loss: 1.5822e-08390/450 [=========================>....] - ETA: 0s - loss: 1.5816e-08420/450 [===========================>..] - ETA: 0s - loss: 1.5809e-08450/450 [==============================] - 3s - loss: 1.5802e-08 - val_loss: 1.5700e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5700e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.5694e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.5688e-08120/450 [=======>......................] - ETA: 2s - loss: 1.5681e-08150/450 [=========>....................] - ETA: 2s - loss: 1.5675e-08180/450 [===========>..................] - ETA: 2s - loss: 1.5668e-08210/450 [=============>................] - ETA: 1s - loss: 1.5662e-08240/450 [===============>..............] - ETA: 1s - loss: 1.5656e-08270/450 [=================>............] - ETA: 1s - loss: 1.5649e-08300/450 [===================>..........] - ETA: 1s - loss: 1.5643e-08330/450 [=====================>........] - ETA: 0s - loss: 1.5636e-08360/450 [=======================>......] - ETA: 0s - loss: 1.5630e-08390/450 [=========================>....] - ETA: 0s - loss: 1.5624e-08420/450 [===========================>..] - ETA: 0s - loss: 1.5617e-08450/450 [==============================] - 3s - loss: 1.5611e-08 - val_loss: 1.5519e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5522e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.5517e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.5511e-08120/450 [=======>......................] - ETA: 2s - loss: 1.5506e-08150/450 [=========>....................] - ETA: 2s - loss: 1.5500e-08180/450 [===========>..................] - ETA: 2s - loss: 1.5493e-08210/450 [=============>................] - ETA: 1s - loss: 1.5487e-08240/450 [===============>..............] - ETA: 1s - loss: 1.5480e-08270/450 [=================>............] - ETA: 1s - loss: 1.5474e-08300/450 [===================>..........] - ETA: 1s - loss: 1.5467e-08330/450 [=====================>........] - ETA: 0s - loss: 1.5461e-08360/450 [=======================>......] - ETA: 0s - loss: 1.5455e-08390/450 [=========================>....] - ETA: 0s - loss: 1.5448e-08420/450 [===========================>..] - ETA: 0s - loss: 1.5442e-08450/450 [==============================] - 3s - loss: 1.5436e-08 - val_loss: 1.5340e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.5349e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.5343e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.5338e-08120/450 [=======>......................] - ETA: 2s - loss: 1.5332e-08150/450 [=========>....................] - ETA: 2s - loss: 1.5326e-08180/450 [===========>..................] - ETA: 2s - loss: 1.5320e-08210/450 [=============>................] - ETA: 1s - loss: 1.5315e-08240/450 [===============>..............] - ETA: 1s - loss: 1.5308e-08270/450 [=================>............] - ETA: 1s - loss: 1.5302e-08300/450 [===================>..........] - ETA: 1s - loss: 1.5296e-08330/450 [=====================>........] - ETA: 0s - loss: 1.5290e-08360/450 [=======================>......] - ETA: 0s - loss: 1.5284e-08390/450 [=========================>....] - ETA: 0s - loss: 1.5278e-08420/450 [===========================>..] - ETA: 0s - loss: 1.5271e-08450/450 [==============================] - 3s - loss: 1.5265e-08 - val_loss: 1.5169e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 2s - loss: 1.5154e-08 60/450 [===>..........................] - ETA: 2s - loss: 1.5148e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.5140e-08120/450 [=======>......................] - ETA: 2s - loss: 1.5134e-08150/450 [=========>....................] - ETA: 2s - loss: 1.5129e-08180/450 [===========>..................] - ETA: 2s - loss: 1.5122e-08210/450 [=============>................] - ETA: 1s - loss: 1.5116e-08240/450 [===============>..............] - ETA: 1s - loss: 1.5110e-08270/450 [=================>............] - ETA: 1s - loss: 1.5104e-08300/450 [===================>..........] - ETA: 1s - loss: 1.5098e-08330/450 [=====================>........] - ETA: 0s - loss: 1.5092e-08360/450 [=======================>......] - ETA: 0s - loss: 1.5086e-08390/450 [=========================>....] - ETA: 0s - loss: 1.5079e-08420/450 [===========================>..] - ETA: 0s - loss: 1.5075e-08450/450 [==============================] - 3s - loss: 1.5069e-08 - val_loss: 1.4975e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4982e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.4982e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.4974e-08120/450 [=======>......................] - ETA: 2s - loss: 1.4965e-08150/450 [=========>....................] - ETA: 2s - loss: 1.4957e-08180/450 [===========>..................] - ETA: 2s - loss: 1.4952e-08210/450 [=============>................] - ETA: 1s - loss: 1.4946e-08240/450 [===============>..............] - ETA: 1s - loss: 1.4940e-08270/450 [=================>............] - ETA: 1s - loss: 1.4933e-08300/450 [===================>..........] - ETA: 1s - loss: 1.4927e-08330/450 [=====================>........] - ETA: 0s - loss: 1.4920e-08360/450 [=======================>......] - ETA: 0s - loss: 1.4914e-08390/450 [=========================>....] - ETA: 0s - loss: 1.4908e-08420/450 [===========================>..] - ETA: 0s - loss: 1.4902e-08450/450 [==============================] - 3s - loss: 1.4896e-08 - val_loss: 1.4821e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4807e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.4804e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.4795e-08120/450 [=======>......................] - ETA: 2s - loss: 1.4789e-08150/450 [=========>....................] - ETA: 2s - loss: 1.4783e-08180/450 [===========>..................] - ETA: 2s - loss: 1.4777e-08210/450 [=============>................] - ETA: 1s - loss: 1.4770e-08240/450 [===============>..............] - ETA: 1s - loss: 1.4765e-08270/450 [=================>............] - ETA: 1s - loss: 1.4760e-08300/450 [===================>..........] - ETA: 1s - loss: 1.4754e-08330/450 [=====================>........] - ETA: 0s - loss: 1.4748e-08360/450 [=======================>......] - ETA: 0s - loss: 1.4742e-08390/450 [=========================>....] - ETA: 0s - loss: 1.4736e-08420/450 [===========================>..] - ETA: 0s - loss: 1.4730e-08450/450 [==============================] - 3s - loss: 1.4724e-08 - val_loss: 1.4607e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4607e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.4602e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.4596e-08120/450 [=======>......................] - ETA: 2s - loss: 1.4588e-08150/450 [=========>....................] - ETA: 2s - loss: 1.4582e-08180/450 [===========>..................] - ETA: 2s - loss: 1.4576e-08210/450 [=============>................] - ETA: 1s - loss: 1.4570e-08240/450 [===============>..............] - ETA: 1s - loss: 1.4564e-08270/450 [=================>............] - ETA: 1s - loss: 1.4558e-08300/450 [===================>..........] - ETA: 1s - loss: 1.4552e-08330/450 [=====================>........] - ETA: 0s - loss: 1.4546e-08360/450 [=======================>......] - ETA: 0s - loss: 1.4540e-08390/450 [=========================>....] - ETA: 0s - loss: 1.4534e-08420/450 [===========================>..] - ETA: 0s - loss: 1.4528e-08450/450 [==============================] - 3s - loss: 1.4523e-08 - val_loss: 1.4427e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4434e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.4432e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.4425e-08120/450 [=======>......................] - ETA: 2s - loss: 1.4418e-08150/450 [=========>....................] - ETA: 2s - loss: 1.4412e-08180/450 [===========>..................] - ETA: 2s - loss: 1.4406e-08210/450 [=============>................] - ETA: 1s - loss: 1.4400e-08240/450 [===============>..............] - ETA: 1s - loss: 1.4395e-08270/450 [=================>............] - ETA: 1s - loss: 1.4388e-08300/450 [===================>..........] - ETA: 1s - loss: 1.4383e-08330/450 [=====================>........] - ETA: 0s - loss: 1.4377e-08360/450 [=======================>......] - ETA: 0s - loss: 1.4371e-08390/450 [=========================>....] - ETA: 0s - loss: 1.4365e-08420/450 [===========================>..] - ETA: 0s - loss: 1.4359e-08450/450 [==============================] - 3s - loss: 1.4353e-08 - val_loss: 1.4272e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4259e-08 60/450 [===>..........................] - ETA: 2s - loss: 1.4249e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.4243e-08120/450 [=======>......................] - ETA: 2s - loss: 1.4237e-08150/450 [=========>....................] - ETA: 2s - loss: 1.4230e-08180/450 [===========>..................] - ETA: 2s - loss: 1.4224e-08210/450 [=============>................] - ETA: 1s - loss: 1.4218e-08240/450 [===============>..............] - ETA: 1s - loss: 1.4212e-08270/450 [=================>............] - ETA: 1s - loss: 1.4207e-08300/450 [===================>..........] - ETA: 1s - loss: 1.4201e-08330/450 [=====================>........] - ETA: 0s - loss: 1.4195e-08360/450 [=======================>......] - ETA: 0s - loss: 1.4189e-08390/450 [=========================>....] - ETA: 0s - loss: 1.4183e-08420/450 [===========================>..] - ETA: 0s - loss: 1.4178e-08450/450 [==============================] - 3s - loss: 1.4172e-08 - val_loss: 1.4112e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.4131e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.4123e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.4117e-08120/450 [=======>......................] - ETA: 2s - loss: 1.4112e-08150/450 [=========>....................] - ETA: 2s - loss: 1.4105e-08180/450 [===========>..................] - ETA: 2s - loss: 1.4099e-08210/450 [=============>................] - ETA: 1s - loss: 1.4093e-08240/450 [===============>..............] - ETA: 1s - loss: 1.4088e-08270/450 [=================>............] - ETA: 1s - loss: 1.4082e-08300/450 [===================>..........] - ETA: 1s - loss: 1.4077e-08330/450 [=====================>........] - ETA: 0s - loss: 1.4071e-08360/450 [=======================>......] - ETA: 0s - loss: 1.4066e-08390/450 [=========================>....] - ETA: 0s - loss: 1.4060e-08420/450 [===========================>..] - ETA: 0s - loss: 1.4054e-08450/450 [==============================] - 3s - loss: 1.4049e-08 - val_loss: 1.3955e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3961e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3956e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3951e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3949e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3943e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3937e-08210/450 [=============>................] - ETA: 1s - loss: 1.3931e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3925e-08270/450 [=================>............] - ETA: 1s - loss: 1.3920e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3914e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3908e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3903e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3897e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3891e-08450/450 [==============================] - 3s - loss: 1.3886e-08 - val_loss: 1.3757e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3753e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3748e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3742e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3736e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3731e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3725e-08210/450 [=============>................] - ETA: 1s - loss: 1.3720e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3715e-08270/450 [=================>............] - ETA: 1s - loss: 1.3709e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3704e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3698e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3693e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3687e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3682e-08450/450 [==============================] - 3s - loss: 1.3676e-08 - val_loss: 1.3588e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3585e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3580e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3575e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3570e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3564e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3559e-08210/450 [=============>................] - ETA: 1s - loss: 1.3553e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3548e-08270/450 [=================>............] - ETA: 1s - loss: 1.3542e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3537e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3532e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3526e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3521e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3516e-08450/450 [==============================] - 3s - loss: 1.3510e-08 - val_loss: 1.3425e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3426e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3422e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3416e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3411e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3405e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3400e-08210/450 [=============>................] - ETA: 1s - loss: 1.3395e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3390e-08270/450 [=================>............] - ETA: 1s - loss: 1.3385e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3379e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3374e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3368e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3363e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3358e-08450/450 [==============================] - 3s - loss: 1.3352e-08 - val_loss: 1.3272e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3272e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3267e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3262e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3256e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3251e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3246e-08210/450 [=============>................] - ETA: 1s - loss: 1.3240e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3235e-08270/450 [=================>............] - ETA: 1s - loss: 1.3229e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3224e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3219e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3214e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3209e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3203e-08450/450 [==============================] - 3s - loss: 1.3198e-08 - val_loss: 1.3116e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3137e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3133e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3126e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3121e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3116e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3111e-08210/450 [=============>................] - ETA: 1s - loss: 1.3107e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3101e-08270/450 [=================>............] - ETA: 1s - loss: 1.3096e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3091e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3086e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3081e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3076e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3070e-08450/450 [==============================] - 3s - loss: 1.3065e-08 - val_loss: 1.2989e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.3894e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.3421e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.3706e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3631e-08150/450 [=========>....................] - ETA: 2s - loss: 1.3489e-08180/450 [===========>..................] - ETA: 2s - loss: 1.3392e-08210/450 [=============>................] - ETA: 1s - loss: 1.3358e-08240/450 [===============>..............] - ETA: 1s - loss: 1.3329e-08270/450 [=================>............] - ETA: 1s - loss: 1.3385e-08300/450 [===================>..........] - ETA: 1s - loss: 1.3334e-08330/450 [=====================>........] - ETA: 0s - loss: 1.3423e-08360/450 [=======================>......] - ETA: 0s - loss: 1.3427e-08390/450 [=========================>....] - ETA: 0s - loss: 1.3382e-08420/450 [===========================>..] - ETA: 0s - loss: 1.3343e-08450/450 [==============================] - 3s - loss: 1.3359e-08 - val_loss: 1.2808e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2810e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.2806e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.2907e-08120/450 [=======>......................] - ETA: 2s - loss: 1.3041e-08150/450 [=========>....................] - ETA: 2s - loss: 1.2987e-08180/450 [===========>..................] - ETA: 2s - loss: 1.2955e-08210/450 [=============>................] - ETA: 1s - loss: 1.2981e-08240/450 [===============>..............] - ETA: 1s - loss: 1.2951e-08270/450 [=================>............] - ETA: 1s - loss: 1.2940e-08300/450 [===================>..........] - ETA: 1s - loss: 1.2918e-08330/450 [=====================>........] - ETA: 0s - loss: 1.2899e-08360/450 [=======================>......] - ETA: 0s - loss: 1.2883e-08390/450 [=========================>....] - ETA: 0s - loss: 1.2968e-08420/450 [===========================>..] - ETA: 0s - loss: 1.2948e-08450/450 [==============================] - 3s - loss: 1.2962e-08 - val_loss: 1.2669e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2671e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.2667e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.2665e-08120/450 [=======>......................] - ETA: 2s - loss: 1.2659e-08150/450 [=========>....................] - ETA: 2s - loss: 1.2653e-08180/450 [===========>..................] - ETA: 2s - loss: 1.2648e-08210/450 [=============>................] - ETA: 1s - loss: 1.2643e-08240/450 [===============>..............] - ETA: 1s - loss: 1.2638e-08270/450 [=================>............] - ETA: 1s - loss: 1.2633e-08300/450 [===================>..........] - ETA: 1s - loss: 1.2628e-08330/450 [=====================>........] - ETA: 0s - loss: 1.2623e-08360/450 [=======================>......] - ETA: 0s - loss: 1.2626e-08390/450 [=========================>....] - ETA: 0s - loss: 1.2621e-08420/450 [===========================>..] - ETA: 0s - loss: 1.2616e-08450/450 [==============================] - 3s - loss: 1.2611e-08 - val_loss: 1.2525e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2519e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.2515e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.2510e-08120/450 [=======>......................] - ETA: 2s - loss: 1.2504e-08150/450 [=========>....................] - ETA: 2s - loss: 1.2499e-08180/450 [===========>..................] - ETA: 2s - loss: 1.2495e-08210/450 [=============>................] - ETA: 1s - loss: 1.2490e-08240/450 [===============>..............] - ETA: 1s - loss: 1.2485e-08270/450 [=================>............] - ETA: 1s - loss: 1.2480e-08300/450 [===================>..........] - ETA: 1s - loss: 1.2475e-08330/450 [=====================>........] - ETA: 0s - loss: 1.2470e-08360/450 [=======================>......] - ETA: 0s - loss: 1.2465e-08390/450 [=========================>....] - ETA: 0s - loss: 1.2460e-08420/450 [===========================>..] - ETA: 0s - loss: 1.2455e-08450/450 [==============================] - 3s - loss: 1.2450e-08 - val_loss: 1.2370e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2371e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.2367e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.2362e-08120/450 [=======>......................] - ETA: 2s - loss: 1.2357e-08150/450 [=========>....................] - ETA: 2s - loss: 1.2352e-08180/450 [===========>..................] - ETA: 2s - loss: 1.2348e-08210/450 [=============>................] - ETA: 1s - loss: 1.2343e-08240/450 [===============>..............] - ETA: 1s - loss: 1.2338e-08270/450 [=================>............] - ETA: 1s - loss: 1.2333e-08300/450 [===================>..........] - ETA: 1s - loss: 1.2329e-08330/450 [=====================>........] - ETA: 0s - loss: 1.2324e-08360/450 [=======================>......] - ETA: 0s - loss: 1.2319e-08390/450 [=========================>....] - ETA: 0s - loss: 1.2315e-08420/450 [===========================>..] - ETA: 0s - loss: 1.2310e-08450/450 [==============================] - 3s - loss: 1.2305e-08 - val_loss: 1.2238e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2226e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.2222e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.2216e-08120/450 [=======>......................] - ETA: 2s - loss: 1.2211e-08150/450 [=========>....................] - ETA: 2s - loss: 1.2206e-08180/450 [===========>..................] - ETA: 2s - loss: 1.2201e-08210/450 [=============>................] - ETA: 1s - loss: 1.2197e-08240/450 [===============>..............] - ETA: 1s - loss: 1.2191e-08270/450 [=================>............] - ETA: 1s - loss: 1.2187e-08300/450 [===================>..........] - ETA: 1s - loss: 1.2182e-08330/450 [=====================>........] - ETA: 0s - loss: 1.2177e-08360/450 [=======================>......] - ETA: 0s - loss: 1.2172e-08390/450 [=========================>....] - ETA: 0s - loss: 1.2168e-08420/450 [===========================>..] - ETA: 0s - loss: 1.2163e-08450/450 [==============================] - 3s - loss: 1.2159e-08 - val_loss: 1.2074e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.2076e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.2071e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.2068e-08120/450 [=======>......................] - ETA: 2s - loss: 1.2064e-08150/450 [=========>....................] - ETA: 2s - loss: 1.2059e-08180/450 [===========>..................] - ETA: 2s - loss: 1.2054e-08210/450 [=============>................] - ETA: 1s - loss: 1.2050e-08240/450 [===============>..............] - ETA: 1s - loss: 1.2045e-08270/450 [=================>............] - ETA: 1s - loss: 1.2041e-08300/450 [===================>..........] - ETA: 1s - loss: 1.2036e-08330/450 [=====================>........] - ETA: 0s - loss: 1.2031e-08360/450 [=======================>......] - ETA: 0s - loss: 1.2026e-08390/450 [=========================>....] - ETA: 0s - loss: 1.2022e-08420/450 [===========================>..] - ETA: 0s - loss: 1.2017e-08450/450 [==============================] - 3s - loss: 1.2012e-08 - val_loss: 1.1941e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1940e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1934e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1930e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1925e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1921e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1916e-08210/450 [=============>................] - ETA: 1s - loss: 1.1911e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1906e-08270/450 [=================>............] - ETA: 1s - loss: 1.1902e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1897e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1893e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1888e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1884e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1879e-08450/450 [==============================] - 3s - loss: 1.1875e-08 - val_loss: 1.1837e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1807e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1801e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1796e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1791e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1786e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1782e-08210/450 [=============>................] - ETA: 1s - loss: 1.1777e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1772e-08270/450 [=================>............] - ETA: 1s - loss: 1.1768e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1763e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1758e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1754e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1749e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1745e-08450/450 [==============================] - 3s - loss: 1.1741e-08 - val_loss: 1.1688e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1686e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1679e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1674e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1669e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1664e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1660e-08210/450 [=============>................] - ETA: 1s - loss: 1.1655e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1651e-08270/450 [=================>............] - ETA: 1s - loss: 1.1647e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1642e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1638e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1633e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1629e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1625e-08450/450 [==============================] - 3s - loss: 1.1620e-08 - val_loss: 1.1553e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1550e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1543e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1543e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1535e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1535e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1529e-08210/450 [=============>................] - ETA: 1s - loss: 1.1525e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1520e-08270/450 [=================>............] - ETA: 1s - loss: 1.1515e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1510e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1505e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1500e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1496e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1491e-08450/450 [==============================] - 3s - loss: 1.1486e-08 - val_loss: 1.1400e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1410e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1405e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1401e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1397e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1392e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1388e-08210/450 [=============>................] - ETA: 1s - loss: 1.1384e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1379e-08270/450 [=================>............] - ETA: 1s - loss: 1.1375e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1371e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1366e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1362e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1358e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1353e-08450/450 [==============================] - 3s - loss: 1.1349e-08 - val_loss: 1.1273e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1272e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1267e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1263e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1258e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1254e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1250e-08210/450 [=============>................] - ETA: 1s - loss: 1.1246e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1241e-08270/450 [=================>............] - ETA: 1s - loss: 1.1237e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1233e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1229e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1225e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1220e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1216e-08450/450 [==============================] - 3s - loss: 1.1212e-08 - val_loss: 1.1148e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1143e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1141e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1136e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1235e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1298e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1342e-08210/450 [=============>................] - ETA: 1s - loss: 1.1307e-08240/450 [===============>..............] - ETA: 1s - loss: 1.1279e-08270/450 [=================>............] - ETA: 1s - loss: 1.1283e-08300/450 [===================>..........] - ETA: 1s - loss: 1.1312e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1403e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1477e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1463e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1432e-08450/450 [==============================] - 3s - loss: 1.1427e-08 - val_loss: 1.1012e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.1009e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1006e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1001e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0997e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0993e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0988e-08210/450 [=============>................] - ETA: 1s - loss: 1.0984e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0980e-08270/450 [=================>............] - ETA: 1s - loss: 1.0976e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0972e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0967e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0963e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0959e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0955e-08450/450 [==============================] - 3s - loss: 1.0951e-08 - val_loss: 1.0885e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0902e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0895e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0891e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0889e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0884e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0879e-08210/450 [=============>................] - ETA: 1s - loss: 1.0875e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0870e-08270/450 [=================>............] - ETA: 1s - loss: 1.0866e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0862e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0858e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0853e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0849e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0844e-08450/450 [==============================] - 3s - loss: 1.0841e-08 - val_loss: 1.0798e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0764e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0761e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0761e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0758e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0754e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0749e-08210/450 [=============>................] - ETA: 1s - loss: 1.0744e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0740e-08270/450 [=================>............] - ETA: 1s - loss: 1.0736e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0731e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0727e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0723e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0719e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0715e-08450/450 [==============================] - 3s - loss: 1.0711e-08 - val_loss: 1.0657e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0658e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.1335e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.1105e-08120/450 [=======>......................] - ETA: 2s - loss: 1.1172e-08150/450 [=========>....................] - ETA: 2s - loss: 1.1138e-08180/450 [===========>..................] - ETA: 2s - loss: 1.1092e-08210/450 [=============>................] - ETA: 1s - loss: 1.1023e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0972e-08270/450 [=================>............] - ETA: 1s - loss: 1.0992e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0997e-08330/450 [=====================>........] - ETA: 0s - loss: 1.1066e-08360/450 [=======================>......] - ETA: 0s - loss: 1.1024e-08390/450 [=========================>....] - ETA: 0s - loss: 1.1021e-08420/450 [===========================>..] - ETA: 0s - loss: 1.1014e-08450/450 [==============================] - 3s - loss: 1.0983e-08 - val_loss: 1.0525e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0522e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0517e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0514e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0510e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0506e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0502e-08210/450 [=============>................] - ETA: 1s - loss: 1.0498e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0494e-08270/450 [=================>............] - ETA: 1s - loss: 1.0490e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0486e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0482e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0478e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0474e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0470e-08450/450 [==============================] - 3s - loss: 1.0466e-08 - val_loss: 1.0402e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0403e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0402e-08 90/450 [=====>........................] - ETA: 3s - loss: 1.0397e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0393e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0389e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0388e-08210/450 [=============>................] - ETA: 1s - loss: 1.0385e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0380e-08270/450 [=================>............] - ETA: 1s - loss: 1.0376e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0373e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0369e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0364e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0360e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0356e-08450/450 [==============================] - 3s - loss: 1.0353e-08 - val_loss: 1.0289e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0283e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0282e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0278e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0273e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0269e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0265e-08210/450 [=============>................] - ETA: 1s - loss: 1.0261e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0257e-08270/450 [=================>............] - ETA: 1s - loss: 1.0253e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0249e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0245e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0241e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0237e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0233e-08450/450 [==============================] - 3s - loss: 1.0230e-08 - val_loss: 1.0167e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0168e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0165e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0161e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0157e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0153e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0149e-08210/450 [=============>................] - ETA: 1s - loss: 1.0146e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0142e-08270/450 [=================>............] - ETA: 1s - loss: 1.0138e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0134e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0130e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0127e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0123e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0120e-08450/450 [==============================] - 3s - loss: 1.0116e-08 - val_loss: 1.0063e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0079e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0073e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0072e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0070e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0065e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0063e-08210/450 [=============>................] - ETA: 1s - loss: 1.0059e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0054e-08270/450 [=================>............] - ETA: 1s - loss: 1.0051e-08300/450 [===================>..........] - ETA: 1s - loss: 1.0048e-08330/450 [=====================>........] - ETA: 0s - loss: 1.0043e-08360/450 [=======================>......] - ETA: 0s - loss: 1.0040e-08390/450 [=========================>....] - ETA: 0s - loss: 1.0038e-08420/450 [===========================>..] - ETA: 0s - loss: 1.0034e-08450/450 [==============================] - 3s - loss: 1.0030e-08 - val_loss: 1.0030e-08
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 1.0031e-08 60/450 [===>..........................] - ETA: 3s - loss: 1.0026e-08 90/450 [=====>........................] - ETA: 2s - loss: 1.0022e-08120/450 [=======>......................] - ETA: 2s - loss: 1.0017e-08150/450 [=========>....................] - ETA: 2s - loss: 1.0012e-08180/450 [===========>..................] - ETA: 2s - loss: 1.0009e-08210/450 [=============>................] - ETA: 1s - loss: 1.0006e-08240/450 [===============>..............] - ETA: 1s - loss: 1.0002e-08270/450 [=================>............] - ETA: 1s - loss: 9.9989e-09300/450 [===================>..........] - ETA: 1s - loss: 9.9958e-09330/450 [=====================>........] - ETA: 0s - loss: 9.9925e-09360/450 [=======================>......] - ETA: 0s - loss: 9.9887e-09390/450 [=========================>....] - ETA: 0s - loss: 9.9848e-09420/450 [===========================>..] - ETA: 0s - loss: 9.9810e-09450/450 [==============================] - 3s - loss: 9.9772e-09 - val_loss: 9.8647e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.8553e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.8516e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.8473e-09120/450 [=======>......................] - ETA: 2s - loss: 9.8443e-09150/450 [=========>....................] - ETA: 2s - loss: 9.8408e-09180/450 [===========>..................] - ETA: 2s - loss: 9.8370e-09210/450 [=============>................] - ETA: 1s - loss: 9.8336e-09240/450 [===============>..............] - ETA: 1s - loss: 9.8297e-09270/450 [=================>............] - ETA: 1s - loss: 9.8260e-09300/450 [===================>..........] - ETA: 1s - loss: 9.8224e-09330/450 [=====================>........] - ETA: 0s - loss: 9.8188e-09360/450 [=======================>......] - ETA: 0s - loss: 9.8150e-09390/450 [=========================>....] - ETA: 0s - loss: 9.8112e-09420/450 [===========================>..] - ETA: 0s - loss: 9.8075e-09450/450 [==============================] - 3s - loss: 9.8039e-09 - val_loss: 9.7522e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.7540e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.7441e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.7389e-09120/450 [=======>......................] - ETA: 2s - loss: 9.7345e-09150/450 [=========>....................] - ETA: 2s - loss: 9.7300e-09180/450 [===========>..................] - ETA: 2s - loss: 9.7256e-09210/450 [=============>................] - ETA: 1s - loss: 9.7218e-09240/450 [===============>..............] - ETA: 1s - loss: 9.7177e-09270/450 [=================>............] - ETA: 1s - loss: 9.7139e-09300/450 [===================>..........] - ETA: 1s - loss: 9.7103e-09330/450 [=====================>........] - ETA: 0s - loss: 9.7064e-09360/450 [=======================>......] - ETA: 0s - loss: 9.7028e-09390/450 [=========================>....] - ETA: 0s - loss: 9.6990e-09420/450 [===========================>..] - ETA: 0s - loss: 9.6954e-09450/450 [==============================] - 3s - loss: 9.6916e-09 - val_loss: 9.6305e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.6392e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.6320e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.6265e-09120/450 [=======>......................] - ETA: 2s - loss: 9.6232e-09150/450 [=========>....................] - ETA: 2s - loss: 9.6190e-09180/450 [===========>..................] - ETA: 2s - loss: 9.6148e-09210/450 [=============>................] - ETA: 1s - loss: 9.6111e-09240/450 [===============>..............] - ETA: 1s - loss: 9.6074e-09270/450 [=================>............] - ETA: 1s - loss: 9.6037e-09300/450 [===================>..........] - ETA: 1s - loss: 9.5999e-09330/450 [=====================>........] - ETA: 0s - loss: 9.5963e-09360/450 [=======================>......] - ETA: 0s - loss: 9.5926e-09390/450 [=========================>....] - ETA: 0s - loss: 9.5892e-09420/450 [===========================>..] - ETA: 0s - loss: 9.5866e-09450/450 [==============================] - 3s - loss: 9.5830e-09 - val_loss: 9.5111e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.5081e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.5037e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.5005e-09120/450 [=======>......................] - ETA: 2s - loss: 9.4971e-09150/450 [=========>....................] - ETA: 2s - loss: 9.4939e-09180/450 [===========>..................] - ETA: 2s - loss: 9.4904e-09210/450 [=============>................] - ETA: 1s - loss: 9.4869e-09240/450 [===============>..............] - ETA: 1s - loss: 9.4835e-09270/450 [=================>............] - ETA: 1s - loss: 9.4800e-09300/450 [===================>..........] - ETA: 1s - loss: 9.4767e-09330/450 [=====================>........] - ETA: 0s - loss: 9.4736e-09360/450 [=======================>......] - ETA: 0s - loss: 9.4702e-09390/450 [=========================>....] - ETA: 0s - loss: 9.4669e-09420/450 [===========================>..] - ETA: 0s - loss: 9.4637e-09450/450 [==============================] - 3s - loss: 9.4602e-09 - val_loss: 9.4005e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.4212e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.4192e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.4149e-09120/450 [=======>......................] - ETA: 2s - loss: 9.4117e-09150/450 [=========>....................] - ETA: 2s - loss: 9.4085e-09180/450 [===========>..................] - ETA: 2s - loss: 9.4063e-09210/450 [=============>................] - ETA: 1s - loss: 9.4027e-09240/450 [===============>..............] - ETA: 1s - loss: 9.3991e-09270/450 [=================>............] - ETA: 1s - loss: 9.3952e-09300/450 [===================>..........] - ETA: 1s - loss: 9.3919e-09330/450 [=====================>........] - ETA: 0s - loss: 9.3883e-09360/450 [=======================>......] - ETA: 0s - loss: 9.3845e-09390/450 [=========================>....] - ETA: 0s - loss: 9.3812e-09420/450 [===========================>..] - ETA: 0s - loss: 9.3775e-09450/450 [==============================] - 3s - loss: 9.3743e-09 - val_loss: 9.3132e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.3138e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.3094e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.3060e-09120/450 [=======>......................] - ETA: 2s - loss: 9.3028e-09150/450 [=========>....................] - ETA: 2s - loss: 9.2992e-09180/450 [===========>..................] - ETA: 2s - loss: 9.2962e-09210/450 [=============>................] - ETA: 1s - loss: 9.2924e-09240/450 [===============>..............] - ETA: 1s - loss: 9.2883e-09270/450 [=================>............] - ETA: 1s - loss: 9.2847e-09300/450 [===================>..........] - ETA: 1s - loss: 9.2809e-09330/450 [=====================>........] - ETA: 0s - loss: 9.2774e-09360/450 [=======================>......] - ETA: 0s - loss: 9.2737e-09390/450 [=========================>....] - ETA: 0s - loss: 9.2704e-09420/450 [===========================>..] - ETA: 0s - loss: 9.2678e-09450/450 [==============================] - 3s - loss: 9.2643e-09 - val_loss: 9.1947e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.2051e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.1994e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.1942e-09120/450 [=======>......................] - ETA: 2s - loss: 9.1927e-09150/450 [=========>....................] - ETA: 2s - loss: 9.1901e-09180/450 [===========>..................] - ETA: 2s - loss: 9.1860e-09210/450 [=============>................] - ETA: 1s - loss: 9.1829e-09240/450 [===============>..............] - ETA: 1s - loss: 9.1798e-09270/450 [=================>............] - ETA: 1s - loss: 9.1768e-09300/450 [===================>..........] - ETA: 1s - loss: 9.1733e-09330/450 [=====================>........] - ETA: 0s - loss: 9.1703e-09360/450 [=======================>......] - ETA: 0s - loss: 9.1666e-09390/450 [=========================>....] - ETA: 0s - loss: 9.1629e-09420/450 [===========================>..] - ETA: 0s - loss: 9.1597e-09450/450 [==============================] - 3s - loss: 9.1563e-09 - val_loss: 9.0952e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.0971e-09 60/450 [===>..........................] - ETA: 3s - loss: 9.0931e-09 90/450 [=====>........................] - ETA: 2s - loss: 9.0907e-09120/450 [=======>......................] - ETA: 2s - loss: 9.0874e-09150/450 [=========>....................] - ETA: 2s - loss: 9.0840e-09180/450 [===========>..................] - ETA: 2s - loss: 9.0809e-09210/450 [=============>................] - ETA: 1s - loss: 9.0773e-09240/450 [===============>..............] - ETA: 1s - loss: 9.0739e-09270/450 [=================>............] - ETA: 1s - loss: 9.0707e-09300/450 [===================>..........] - ETA: 1s - loss: 9.0673e-09330/450 [=====================>........] - ETA: 0s - loss: 9.0640e-09360/450 [=======================>......] - ETA: 0s - loss: 9.0606e-09390/450 [=========================>....] - ETA: 0s - loss: 9.0575e-09420/450 [===========================>..] - ETA: 0s - loss: 9.0542e-09450/450 [==============================] - 3s - loss: 9.0509e-09 - val_loss: 8.9987e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 9.0041e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.9992e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.9951e-09120/450 [=======>......................] - ETA: 2s - loss: 8.9916e-09150/450 [=========>....................] - ETA: 2s - loss: 8.9886e-09180/450 [===========>..................] - ETA: 2s - loss: 8.9853e-09210/450 [=============>................] - ETA: 1s - loss: 8.9822e-09240/450 [===============>..............] - ETA: 1s - loss: 8.9788e-09270/450 [=================>............] - ETA: 1s - loss: 8.9755e-09300/450 [===================>..........] - ETA: 1s - loss: 8.9718e-09330/450 [=====================>........] - ETA: 0s - loss: 8.9685e-09360/450 [=======================>......] - ETA: 0s - loss: 8.9652e-09390/450 [=========================>....] - ETA: 0s - loss: 8.9619e-09420/450 [===========================>..] - ETA: 0s - loss: 8.9587e-09450/450 [==============================] - 3s - loss: 8.9552e-09 - val_loss: 8.9117e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.9085e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.9002e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.8970e-09120/450 [=======>......................] - ETA: 2s - loss: 8.8936e-09150/450 [=========>....................] - ETA: 2s - loss: 8.8911e-09180/450 [===========>..................] - ETA: 2s - loss: 8.8873e-09210/450 [=============>................] - ETA: 1s - loss: 8.8849e-09240/450 [===============>..............] - ETA: 1s - loss: 8.8810e-09270/450 [=================>............] - ETA: 1s - loss: 8.8767e-09300/450 [===================>..........] - ETA: 1s - loss: 8.8729e-09330/450 [=====================>........] - ETA: 0s - loss: 8.8688e-09360/450 [=======================>......] - ETA: 0s - loss: 8.8651e-09390/450 [=========================>....] - ETA: 0s - loss: 8.8617e-09420/450 [===========================>..] - ETA: 0s - loss: 8.8580e-09450/450 [==============================] - 3s - loss: 8.8546e-09 - val_loss: 8.7963e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.8252e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.8187e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.8157e-09120/450 [=======>......................] - ETA: 2s - loss: 8.8133e-09150/450 [=========>....................] - ETA: 2s - loss: 8.8105e-09180/450 [===========>..................] - ETA: 2s - loss: 8.8074e-09210/450 [=============>................] - ETA: 1s - loss: 8.8041e-09240/450 [===============>..............] - ETA: 1s - loss: 8.8011e-09270/450 [=================>............] - ETA: 1s - loss: 8.7981e-09300/450 [===================>..........] - ETA: 1s - loss: 8.7949e-09330/450 [=====================>........] - ETA: 0s - loss: 8.7916e-09360/450 [=======================>......] - ETA: 0s - loss: 8.7884e-09390/450 [=========================>....] - ETA: 0s - loss: 8.7854e-09420/450 [===========================>..] - ETA: 0s - loss: 8.7822e-09450/450 [==============================] - 3s - loss: 8.7789e-09 - val_loss: 8.7218e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.7083e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.7060e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.7033e-09120/450 [=======>......................] - ETA: 2s - loss: 8.6998e-09150/450 [=========>....................] - ETA: 2s - loss: 8.6964e-09180/450 [===========>..................] - ETA: 2s - loss: 8.6932e-09210/450 [=============>................] - ETA: 1s - loss: 8.6946e-09240/450 [===============>..............] - ETA: 1s - loss: 8.6910e-09270/450 [=================>............] - ETA: 1s - loss: 8.6873e-09300/450 [===================>..........] - ETA: 1s - loss: 8.6837e-09330/450 [=====================>........] - ETA: 0s - loss: 8.6804e-09360/450 [=======================>......] - ETA: 0s - loss: 8.6771e-09390/450 [=========================>....] - ETA: 0s - loss: 8.6739e-09420/450 [===========================>..] - ETA: 0s - loss: 8.6704e-09450/450 [==============================] - 3s - loss: 8.6672e-09 - val_loss: 8.6086e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.6093e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.6109e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.6063e-09120/450 [=======>......................] - ETA: 2s - loss: 8.6024e-09150/450 [=========>....................] - ETA: 2s - loss: 8.5994e-09180/450 [===========>..................] - ETA: 2s - loss: 8.5960e-09210/450 [=============>................] - ETA: 1s - loss: 8.5922e-09240/450 [===============>..............] - ETA: 1s - loss: 8.5893e-09270/450 [=================>............] - ETA: 1s - loss: 8.5857e-09300/450 [===================>..........] - ETA: 1s - loss: 8.5825e-09330/450 [=====================>........] - ETA: 0s - loss: 8.5792e-09360/450 [=======================>......] - ETA: 0s - loss: 8.5759e-09390/450 [=========================>....] - ETA: 0s - loss: 8.5727e-09420/450 [===========================>..] - ETA: 0s - loss: 8.5695e-09450/450 [==============================] - 3s - loss: 8.5663e-09 - val_loss: 8.5118e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.5349e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.5267e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.5220e-09120/450 [=======>......................] - ETA: 2s - loss: 8.5190e-09150/450 [=========>....................] - ETA: 2s - loss: 8.5159e-09180/450 [===========>..................] - ETA: 2s - loss: 8.5123e-09210/450 [=============>................] - ETA: 1s - loss: 8.5093e-09240/450 [===============>..............] - ETA: 1s - loss: 8.5068e-09270/450 [=================>............] - ETA: 1s - loss: 8.5036e-09300/450 [===================>..........] - ETA: 1s - loss: 8.5005e-09330/450 [=====================>........] - ETA: 0s - loss: 8.4974e-09360/450 [=======================>......] - ETA: 0s - loss: 8.4945e-09390/450 [=========================>....] - ETA: 0s - loss: 8.4910e-09420/450 [===========================>..] - ETA: 0s - loss: 8.4885e-09450/450 [==============================] - 3s - loss: 8.4855e-09 - val_loss: 8.4459e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.4460e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.4387e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.4362e-09120/450 [=======>......................] - ETA: 2s - loss: 8.4318e-09150/450 [=========>....................] - ETA: 2s - loss: 8.4278e-09180/450 [===========>..................] - ETA: 2s - loss: 8.4256e-09210/450 [=============>................] - ETA: 1s - loss: 8.4231e-09240/450 [===============>..............] - ETA: 1s - loss: 8.4201e-09270/450 [=================>............] - ETA: 1s - loss: 8.4170e-09300/450 [===================>..........] - ETA: 1s - loss: 8.4139e-09330/450 [=====================>........] - ETA: 0s - loss: 8.4110e-09360/450 [=======================>......] - ETA: 0s - loss: 8.4077e-09390/450 [=========================>....] - ETA: 0s - loss: 8.4048e-09420/450 [===========================>..] - ETA: 0s - loss: 8.4018e-09450/450 [==============================] - 3s - loss: 8.3988e-09 - val_loss: 8.3245e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.3251e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.3227e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.3195e-09120/450 [=======>......................] - ETA: 2s - loss: 8.3166e-09150/450 [=========>....................] - ETA: 2s - loss: 8.3137e-09180/450 [===========>..................] - ETA: 2s - loss: 8.3106e-09210/450 [=============>................] - ETA: 1s - loss: 8.3077e-09240/450 [===============>..............] - ETA: 1s - loss: 8.3046e-09270/450 [=================>............] - ETA: 1s - loss: 8.3017e-09300/450 [===================>..........] - ETA: 1s - loss: 8.2987e-09330/450 [=====================>........] - ETA: 0s - loss: 8.2956e-09360/450 [=======================>......] - ETA: 0s - loss: 8.2926e-09390/450 [=========================>....] - ETA: 0s - loss: 8.2896e-09420/450 [===========================>..] - ETA: 0s - loss: 8.2867e-09450/450 [==============================] - 3s - loss: 8.2836e-09 - val_loss: 8.2666e-09
Train on 450 samples, validate on 150 samples
Epoch 1/1
 30/450 [=>............................] - ETA: 3s - loss: 8.2857e-09 60/450 [===>..........................] - ETA: 3s - loss: 8.2829e-09 90/450 [=====>........................] - ETA: 2s - loss: 8.2776e-09120/450 [=======>......................] - ETA: 2s - loss: 8.2757e-09150/450 [=========>....................] - ETA: 2s - loss: 8.2716e-09Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
Starting...
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
Initializing environment
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
===================================
===================================
===================================
===================================
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM
/afs/crc.nd.edu/user/n/ndev/DQM_ML/Anomaly-Detection-for-ECAL-DQM/test
===================================
===================================
Done!
